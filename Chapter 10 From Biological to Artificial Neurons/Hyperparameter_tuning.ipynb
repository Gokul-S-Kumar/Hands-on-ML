{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring different methods of hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scipy.stats import reciprocal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(housing.data, columns = housing.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['target'] = pd.Series(housing.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will be splitting the data into train, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df_data.drop(columns = 'target', axis = 1))\n",
    "y = np.array(df_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full, x_test, y_train_full, y_test = train_test_split(x, y, random_state = 42)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_full, y_train_full, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scaling the data using Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_valid = scaler.transform(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_layers = 1, n_units = 30, input_shape = [8], learning_rate = 3e-3):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape = input_shape))\n",
    "    for i in range(n_layers):\n",
    "        model.add(keras.layers.Dense(n_units, activation = 'relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(loss = 'mse', optimizer = keras.optimizers.SGD(lr = learning_rate))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above func creates a NN model given a set of hyperparameters.\n",
    "- It creates a simple Sequential model for univariate-regression, given the no. of hidden layers, no. of units in each layer, the input shape and also the learning rate of the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The KerasRegressor object is a thin wrapper around the Keras model buit using teh func. \n",
    "- Now we can use this object like a regular scikit-learn regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1622 - val_loss: 1.3006\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 831us/step - loss: 0.6166 - val_loss: 0.9012\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 774us/step - loss: 0.5362 - val_loss: 0.4949\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 772us/step - loss: 0.4826 - val_loss: 0.4840\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 797us/step - loss: 0.4579 - val_loss: 0.4476\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 817us/step - loss: 0.4365 - val_loss: 0.4388\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.4245 - val_loss: 0.4001\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 807us/step - loss: 0.4163 - val_loss: 0.4170\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 828us/step - loss: 0.4101 - val_loss: 0.3885\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 825us/step - loss: 0.4046 - val_loss: 0.4260\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.3999 - val_loss: 0.3863\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 830us/step - loss: 0.3968 - val_loss: 0.4602\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 808us/step - loss: 0.3926 - val_loss: 0.4036\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 821us/step - loss: 0.3902 - val_loss: 0.3969\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 826us/step - loss: 0.3877 - val_loss: 0.3926\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 815us/step - loss: 0.3850 - val_loss: 0.3617\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 820us/step - loss: 0.3827 - val_loss: 0.4931\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 818us/step - loss: 0.3809 - val_loss: 0.7322\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 809us/step - loss: 0.3835 - val_loss: 0.5861\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 833us/step - loss: 0.3784 - val_loss: 1.0900\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 800us/step - loss: 0.3808 - val_loss: 1.3177\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 778us/step - loss: 0.3802 - val_loss: 1.4146\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 831us/step - loss: 0.3832 - val_loss: 1.6100\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 818us/step - loss: 0.3775 - val_loss: 1.0116\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 831us/step - loss: 0.3757 - val_loss: 1.2154\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 823us/step - loss: 0.3750 - val_loss: 1.0441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd4a84dbe80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(x_train, y_train, epochs = 100, validation_data = (x_valid, y_valid), callbacks = [keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 558us/step - loss: 0.3815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.3815077245235443"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The point to be noted here is that the score will be opposite of the MSE because scikit-learn wants scores, not losses(therefore higher should be better). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since there are may hyperparameters it is preferrable to use randomized search rather than grid search ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_layers' : [0, 1, 2, 3], 'n_units' : np.arange(1, 100), 'learning_rate' : reciprocal(3e-4, 3e-2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_search_cv = RandomizedSearchCV(keras_reg, params, n_iter = 10, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0074 - val_loss: 299.8259\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 705us/step - loss: 0.8854\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6740 - val_loss: 10.1866\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4316 - val_loss: 0.3992\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3998 - val_loss: 0.4014\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.3843 - val_loss: 0.3699\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.3826 - val_loss: 0.4309\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.4277 - val_loss: 0.3961\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.3744 - val_loss: 0.4578\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.3678 - val_loss: 0.3493\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.3663 - val_loss: 0.3488\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.3654 - val_loss: 0.3475\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3608 - val_loss: 0.6457\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3575 - val_loss: 0.3626\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3562 - val_loss: 0.7106\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.4172\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3538 - val_loss: 0.3804\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3519 - val_loss: 0.3311\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.3483 - val_loss: 0.3636\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3549 - val_loss: 0.4159\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.3472 - val_loss: 0.5397\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3437 - val_loss: 0.4835\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3401 - val_loss: 0.8543\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3380 - val_loss: 0.4240\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3918\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.3352 - val_loss: 0.5746\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.3343 - val_loss: 0.4020\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3320 - val_loss: 0.8623\n",
      "121/121 [==============================] - 0s 700us/step - loss: 0.3586\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6374 - val_loss: 0.3952\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.5625 - val_loss: 26.5916\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.4531 - val_loss: 0.6217\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.4297 - val_loss: 2.0655\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 958us/step - loss: 0.4842 - val_loss: 0.3648\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3904 - val_loss: 6.9357\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4439 - val_loss: 0.3490\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.3731 - val_loss: 0.3473\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.3654 - val_loss: 0.3391\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3637 - val_loss: 0.3559\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.3613 - val_loss: 0.3412\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.3354\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3587 - val_loss: 0.3450\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3599 - val_loss: 0.3285\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3543 - val_loss: 0.3302\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3525 - val_loss: 0.3789\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.3512 - val_loss: 0.3554\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 0.3316\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3520 - val_loss: 0.3257\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3440 - val_loss: 0.3239\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3247\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.3406 - val_loss: 0.3192\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.3384 - val_loss: 0.3192\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.3193\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.3349 - val_loss: 0.3197\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3333 - val_loss: 0.3232\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.3329 - val_loss: 0.3227\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.3315 - val_loss: 0.3151\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3285 - val_loss: 0.3277\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.3303 - val_loss: 0.3114\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.3301 - val_loss: 0.3096\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3255 - val_loss: 0.3240\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.3260 - val_loss: 0.3123\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.3259 - val_loss: 0.3167\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3245 - val_loss: 0.3116\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3234 - val_loss: 0.3207\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.3223 - val_loss: 0.3195\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3218 - val_loss: 0.3933\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.3316 - val_loss: 0.3544\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.3331 - val_loss: 0.3175\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3232 - val_loss: 0.3152\n",
      "121/121 [==============================] - 0s 614us/step - loss: 0.3197\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1502 - val_loss: 2.4752\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7429 - val_loss: 0.6364\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6372 - val_loss: 0.6143\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6002 - val_loss: 0.5419\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5661 - val_loss: 0.5211\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5376 - val_loss: 0.4988\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.5120 - val_loss: 0.4715\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.4887 - val_loss: 0.4507\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4687 - val_loss: 0.4360\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4523 - val_loss: 0.4145\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.4383 - val_loss: 0.4001\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.4262 - val_loss: 0.4118\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.4163 - val_loss: 0.3842\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.4085 - val_loss: 0.3773\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.4010 - val_loss: 0.3821\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3945 - val_loss: 0.3877\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3893 - val_loss: 0.3865\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.3834 - val_loss: 0.3682\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.3798 - val_loss: 0.4039\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.3751 - val_loss: 0.3709\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.3717 - val_loss: 0.3525\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3678 - val_loss: 0.3769\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3652 - val_loss: 0.3442\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3618 - val_loss: 0.3408\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.3596 - val_loss: 0.3452\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.3566 - val_loss: 0.4305\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.3562 - val_loss: 0.3357\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.3520 - val_loss: 0.3671\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3514 - val_loss: 0.4092\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.3489 - val_loss: 0.3870\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3494 - val_loss: 0.4498\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3466 - val_loss: 0.4306\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3459 - val_loss: 0.3539\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3435 - val_loss: 0.4243\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.3435 - val_loss: 0.3332\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.3404 - val_loss: 0.3551\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3402 - val_loss: 0.3712\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.3385 - val_loss: 0.4419\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.3397 - val_loss: 0.3361\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.3368 - val_loss: 0.3232\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.3349 - val_loss: 0.3493\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.3348 - val_loss: 0.4095\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.3337 - val_loss: 0.4238\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3353 - val_loss: 0.3540\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3321 - val_loss: 0.3982\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.3338 - val_loss: 0.3784\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.3301 - val_loss: 0.3213\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3298 - val_loss: 0.3857\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.3287 - val_loss: 0.4560\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.3306 - val_loss: 0.5285\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3286 - val_loss: 0.6010\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3300 - val_loss: 0.3827\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3259 - val_loss: 0.4348\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.3273 - val_loss: 0.5152\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3270 - val_loss: 0.5493\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.3265 - val_loss: 0.5194\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.3241 - val_loss: 0.3560\n",
      "121/121 [==============================] - 0s 531us/step - loss: 0.3524\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7962 - val_loss: 3.6431\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.7068 - val_loss: 1.7769\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.6173 - val_loss: 1.0035\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.5666 - val_loss: 0.6202\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.5293 - val_loss: 0.4944\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.5009 - val_loss: 0.4790\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.4775 - val_loss: 0.4856\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.4593 - val_loss: 0.5037\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.4441 - val_loss: 0.5141\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.4316 - val_loss: 0.5295\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.4216 - val_loss: 0.5173\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.4129 - val_loss: 0.5043\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.4053 - val_loss: 0.4859\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.3981 - val_loss: 0.4610\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3927 - val_loss: 0.4444\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3879 - val_loss: 0.4190\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3833 - val_loss: 0.3983\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3789 - val_loss: 0.3830\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.3755 - val_loss: 0.3696\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3721 - val_loss: 0.3605\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3691 - val_loss: 0.3543\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.3664 - val_loss: 0.3507\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.3638 - val_loss: 0.3495\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.3613 - val_loss: 0.3525\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.3591 - val_loss: 0.3669\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.3573 - val_loss: 0.3617\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.3552 - val_loss: 0.3688\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3537 - val_loss: 0.3885\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3520 - val_loss: 0.4072\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3510 - val_loss: 0.4085\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3494 - val_loss: 0.4243\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.3480 - val_loss: 0.4368\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3468 - val_loss: 0.4532\n",
      "121/121 [==============================] - 0s 523us/step - loss: 0.3723\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9107 - val_loss: 2.3305\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.7531 - val_loss: 0.6947\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.6506 - val_loss: 0.6057\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.6111 - val_loss: 0.5696\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.5786 - val_loss: 0.5373\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.5504 - val_loss: 0.5120\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.5256 - val_loss: 0.4947\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.5021 - val_loss: 0.4772\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4820 - val_loss: 0.4679\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.4658 - val_loss: 0.4534\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.4508 - val_loss: 0.4574\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.4390 - val_loss: 0.4398\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.4281 - val_loss: 0.4526\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.4195 - val_loss: 0.4131\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.4119 - val_loss: 0.4222\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.4053 - val_loss: 0.4182\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3994 - val_loss: 0.4123\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.3938 - val_loss: 0.3994\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.3897 - val_loss: 0.4038\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3849 - val_loss: 0.4616\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.3819 - val_loss: 0.4102\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.3779 - val_loss: 0.3719\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.3749 - val_loss: 0.3927\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.3719 - val_loss: 0.4157\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.3689 - val_loss: 0.3780\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.3663 - val_loss: 0.4095\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.3640 - val_loss: 0.3846\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.3614 - val_loss: 0.4083\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.3601 - val_loss: 0.4203\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3582 - val_loss: 0.4564\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.3567 - val_loss: 0.3828\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.3548 - val_loss: 0.4462\n",
      "121/121 [==============================] - 0s 569us/step - loss: 0.3765\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8809 - val_loss: 2.5837\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 1.2951 - val_loss: 1.3682\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.9169 - val_loss: 0.8915\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.7758 - val_loss: 0.7354\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.7146 - val_loss: 0.6787\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.6794 - val_loss: 0.6466\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.6533 - val_loss: 0.6225\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.6331 - val_loss: 0.6030\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.6159 - val_loss: 0.5898\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.6012 - val_loss: 0.5771\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.5883 - val_loss: 0.5670\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.5767 - val_loss: 0.5574\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.5663 - val_loss: 0.5486\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.5565 - val_loss: 0.5397\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.5474 - val_loss: 0.5373\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.5390 - val_loss: 0.5268\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.5312 - val_loss: 0.5266\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.5243 - val_loss: 0.5200\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 806us/step - loss: 0.5179 - val_loss: 0.5158\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 0.5116 - val_loss: 0.5080\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.5059 - val_loss: 0.5043\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.5003 - val_loss: 0.4985\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.4950 - val_loss: 0.4991\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.4896 - val_loss: 0.4939\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.4849 - val_loss: 0.4867\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.4804 - val_loss: 0.4864\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.4758 - val_loss: 0.4836\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.4716 - val_loss: 0.4791\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.4676 - val_loss: 0.4827\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.4638 - val_loss: 0.4780\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 806us/step - loss: 0.4600 - val_loss: 0.4764\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.4563 - val_loss: 0.4752\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.4527 - val_loss: 0.4642\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.4492 - val_loss: 0.4654\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.4462 - val_loss: 0.4661\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.4431 - val_loss: 0.4559\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4401 - val_loss: 0.4553\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4373 - val_loss: 0.4553\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4349 - val_loss: 0.4541\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.4326 - val_loss: 0.4500\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.4303 - val_loss: 0.4478\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.4283 - val_loss: 0.4432\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.4265 - val_loss: 0.4398\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.4248 - val_loss: 0.4378\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.4232 - val_loss: 0.4395\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 738us/step - loss: 0.4217 - val_loss: 0.4335\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.4204 - val_loss: 0.4406\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.4191 - val_loss: 0.4380\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.4178 - val_loss: 0.4423\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.4168 - val_loss: 0.4440\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.4157 - val_loss: 0.4417\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.4146 - val_loss: 0.4449\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.4138 - val_loss: 0.4366\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.4129 - val_loss: 0.4317\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.4122 - val_loss: 0.4401\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.4115 - val_loss: 0.4407\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.4108 - val_loss: 0.4411\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 826us/step - loss: 0.4102 - val_loss: 0.4409\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 826us/step - loss: 0.4094 - val_loss: 0.4464\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.4089 - val_loss: 0.4390\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.4083 - val_loss: 0.4371\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.4077 - val_loss: 0.4423\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.4072 - val_loss: 0.4314\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.4068 - val_loss: 0.4339\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.4063 - val_loss: 0.4398\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.4057 - val_loss: 0.4357\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.4051 - val_loss: 0.4295\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.4047 - val_loss: 0.4374\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.4042 - val_loss: 0.4319\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.4038 - val_loss: 0.4276\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.4032 - val_loss: 0.4360\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.4029 - val_loss: 0.4273\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.4023 - val_loss: 0.4290\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.4019 - val_loss: 0.4286\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.4016 - val_loss: 0.4319\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.4011 - val_loss: 0.4280\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.4008 - val_loss: 0.4250\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.4003 - val_loss: 0.4268\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.3999 - val_loss: 0.4288\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.3994 - val_loss: 0.4201\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3991 - val_loss: 0.4211\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3986 - val_loss: 0.4186\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.3983 - val_loss: 0.4230\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.3979 - val_loss: 0.4252\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.3975 - val_loss: 0.4160\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.3968 - val_loss: 0.4277\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.3968 - val_loss: 0.4237\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3964 - val_loss: 0.4243\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3960 - val_loss: 0.4245\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 0.3955 - val_loss: 0.4104\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.3952 - val_loss: 0.4180\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.3947 - val_loss: 0.4103\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3945 - val_loss: 0.4197\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3939 - val_loss: 0.4097\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.3936 - val_loss: 0.4237\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 806us/step - loss: 0.3934 - val_loss: 0.4126\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.3931 - val_loss: 0.4131\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.3927 - val_loss: 0.4111\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.3922 - val_loss: 0.4072\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.3920 - val_loss: 0.4018\n",
      "121/121 [==============================] - 0s 550us/step - loss: 0.3989\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2603 - val_loss: 3.5573\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 2.1810 - val_loss: 1.9144\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 1.4145 - val_loss: 1.6590\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 1.0899 - val_loss: 1.8696\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.9335 - val_loss: 2.1772\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.8435 - val_loss: 2.4483\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.7842 - val_loss: 2.5561\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.7416 - val_loss: 2.5815\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.7089 - val_loss: 2.4884\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.6813 - val_loss: 2.3926\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.6578 - val_loss: 2.2869\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.6369 - val_loss: 2.1247\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.6193 - val_loss: 2.0492\n",
      "121/121 [==============================] - 0s 547us/step - loss: 1.2190\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0367 - val_loss: 1.4163\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 1.0230 - val_loss: 0.8170\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.7691 - val_loss: 0.6917\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.6991 - val_loss: 0.6451\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.6603 - val_loss: 0.6036\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.6294 - val_loss: 0.5817\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.6027 - val_loss: 0.5586\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.5796 - val_loss: 0.5486\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.5608 - val_loss: 0.5231\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.5460 - val_loss: 0.5158\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.5331 - val_loss: 0.4971\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.5225 - val_loss: 0.4904\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.5131 - val_loss: 0.4796\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.5050 - val_loss: 0.4757\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.4979 - val_loss: 0.4711\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.4914 - val_loss: 0.4661\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.4857 - val_loss: 0.4652\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.4807 - val_loss: 0.4600\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.4763 - val_loss: 0.4529\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 826us/step - loss: 0.4722 - val_loss: 0.4548\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.4689 - val_loss: 0.4400\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.4657 - val_loss: 0.4514\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.4628 - val_loss: 0.4499\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.4602 - val_loss: 0.4350\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.4579 - val_loss: 0.4423\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.4556 - val_loss: 0.4331\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.4535 - val_loss: 0.4306\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.4517 - val_loss: 0.4365\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.4497 - val_loss: 0.4286\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.4480 - val_loss: 0.4311\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.4463 - val_loss: 0.4334\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.4447 - val_loss: 0.4229\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 748us/step - loss: 0.4429 - val_loss: 0.4291\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.4417 - val_loss: 0.4219\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.4404 - val_loss: 0.4277\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.4389 - val_loss: 0.4334\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.4378 - val_loss: 0.4256\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.4365 - val_loss: 0.4238\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.4352 - val_loss: 0.4167\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.4342 - val_loss: 0.4162\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.4332 - val_loss: 0.4167\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.4321 - val_loss: 0.4133\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.4312 - val_loss: 0.4178\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.4303 - val_loss: 0.4102\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.4295 - val_loss: 0.4186\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.4285 - val_loss: 0.4227\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.4278 - val_loss: 0.4129\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.4269 - val_loss: 0.4229\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.4260 - val_loss: 0.4079\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.4255 - val_loss: 0.4078\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.4246 - val_loss: 0.4036\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.4240 - val_loss: 0.4087\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.4233 - val_loss: 0.4166\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.4225 - val_loss: 0.4055\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.4220 - val_loss: 0.4029\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.4214 - val_loss: 0.4188\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.4209 - val_loss: 0.3992\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.4203 - val_loss: 0.4194\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.4198 - val_loss: 0.4047\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.4193 - val_loss: 0.4050\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.4187 - val_loss: 0.3973\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.4183 - val_loss: 0.4008\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.4178 - val_loss: 0.4014\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.4172 - val_loss: 0.4057\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.4170 - val_loss: 0.4110\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.4164 - val_loss: 0.3965\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.4157 - val_loss: 0.4089\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.4153 - val_loss: 0.4166\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.4149 - val_loss: 0.3965\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.4143 - val_loss: 0.4017\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.4137 - val_loss: 0.4109\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.4131 - val_loss: 0.4177\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.4127 - val_loss: 0.4006\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.4121 - val_loss: 0.4110\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.4115 - val_loss: 0.4067\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.4114 - val_loss: 0.3933\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.4108 - val_loss: 0.3896\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.4102 - val_loss: 0.3898\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.4097 - val_loss: 0.4060\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.4092 - val_loss: 0.4111\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.4088 - val_loss: 0.3930\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4082 - val_loss: 0.4095\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.4077 - val_loss: 0.3961\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.4073 - val_loss: 0.3952\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.4066 - val_loss: 0.3941\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.4064 - val_loss: 0.4021\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.4060 - val_loss: 0.3838\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.4055 - val_loss: 0.4041\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.4052 - val_loss: 0.3875\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.4047 - val_loss: 0.3904\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.4045 - val_loss: 0.4018\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.4039 - val_loss: 0.4055\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.4036 - val_loss: 0.3997\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.4035 - val_loss: 0.3955\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 820us/step - loss: 0.4029 - val_loss: 0.3982\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.4026 - val_loss: 0.4033\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.4022 - val_loss: 0.3797\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.4017 - val_loss: 0.4014\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.4014 - val_loss: 0.3988\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.4010 - val_loss: 0.4026\n",
      "121/121 [==============================] - 0s 534us/step - loss: 0.3920\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1536 - val_loss: 16.1025\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 1.7640 - val_loss: 6.8635\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 1.2510 - val_loss: 4.1927\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 1.0323 - val_loss: 2.7496\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.9201 - val_loss: 1.7795\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.8476 - val_loss: 1.2711\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.7992 - val_loss: 1.0131\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.7660 - val_loss: 0.8507\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.7406 - val_loss: 0.7627\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.7201 - val_loss: 0.7050\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.7026 - val_loss: 0.6733\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.6876 - val_loss: 0.6459\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.6740 - val_loss: 0.6273\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.6612 - val_loss: 0.6127\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.6495 - val_loss: 0.6017\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.6383 - val_loss: 0.5926\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.6276 - val_loss: 0.5853\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.6175 - val_loss: 0.5780\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.6079 - val_loss: 0.5712\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.5988 - val_loss: 0.5653\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5899 - val_loss: 0.5565\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.5816 - val_loss: 0.5508\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.5735 - val_loss: 0.5433\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.5652 - val_loss: 0.5384\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.5582 - val_loss: 0.5298\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.5506 - val_loss: 0.5241\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.5434 - val_loss: 0.5173\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.5366 - val_loss: 0.5122\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.5299 - val_loss: 0.5045\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.5235 - val_loss: 0.4981\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5172 - val_loss: 0.4909\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.5112 - val_loss: 0.4830\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.5051 - val_loss: 0.4798\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.4997 - val_loss: 0.4727\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.4942 - val_loss: 0.4653\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.4889 - val_loss: 0.4589\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.4838 - val_loss: 0.4535\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.4789 - val_loss: 0.4489\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.4742 - val_loss: 0.4451\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.4696 - val_loss: 0.4384\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.4654 - val_loss: 0.4337\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4612 - val_loss: 0.4298\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.4570 - val_loss: 0.4280\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.4534 - val_loss: 0.4220\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.4498 - val_loss: 0.4178\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.4463 - val_loss: 0.4142\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.4429 - val_loss: 0.4117\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.4397 - val_loss: 0.4090\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.4365 - val_loss: 0.4055\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.4339 - val_loss: 0.4031\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4311 - val_loss: 0.4004\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.4286 - val_loss: 0.3978\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.4261 - val_loss: 0.3957\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.4236 - val_loss: 0.3935\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.4214 - val_loss: 0.3912\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.4192 - val_loss: 0.3894\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.4171 - val_loss: 0.3874\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.4151 - val_loss: 0.3858\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.4131 - val_loss: 0.3843\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.4114 - val_loss: 0.3828\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.4097 - val_loss: 0.3812\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.4080 - val_loss: 0.3805\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.4063 - val_loss: 0.3787\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.4047 - val_loss: 0.3777\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.4033 - val_loss: 0.3777\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.4017 - val_loss: 0.3782\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.4002 - val_loss: 0.3773\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.3990 - val_loss: 0.3749\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3976 - val_loss: 0.3768\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3965 - val_loss: 0.3757\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3952 - val_loss: 0.3742\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.3940 - val_loss: 0.3757\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3928 - val_loss: 0.3750\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3918 - val_loss: 0.3745\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.3907 - val_loss: 0.3767\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.3895 - val_loss: 0.3800\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3887 - val_loss: 0.3784\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.3877 - val_loss: 0.3777\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.3868 - val_loss: 0.3781\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.3858 - val_loss: 0.3754\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.3849 - val_loss: 0.3732\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3841 - val_loss: 0.3751\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3832 - val_loss: 0.3777\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.3824 - val_loss: 0.3782\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.3815 - val_loss: 0.3783\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3806 - val_loss: 0.3805\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.3798 - val_loss: 0.3757\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.3789 - val_loss: 0.3750\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 765us/step - loss: 0.3784 - val_loss: 0.3790\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.3776 - val_loss: 0.3813\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.3767 - val_loss: 0.3834\n",
      "121/121 [==============================] - 0s 573us/step - loss: 0.3985\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.7584 - val_loss: 3.7017\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 1.9824 - val_loss: 3.9958\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 1.2994 - val_loss: 3.7895\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 1.0177 - val_loss: 3.1603\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.8688 - val_loss: 2.4976\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.7802 - val_loss: 1.9664\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.7239 - val_loss: 1.6137\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.6860 - val_loss: 1.3398\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.6587 - val_loss: 1.1427\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.6375 - val_loss: 0.9834\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.6202 - val_loss: 0.8635\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.6054 - val_loss: 0.7893\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.5924 - val_loss: 0.7531\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.5805 - val_loss: 0.7176\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.5698 - val_loss: 0.6921\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.5599 - val_loss: 0.6642\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.5507 - val_loss: 0.6441\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.5419 - val_loss: 0.6273\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.5337 - val_loss: 0.6121\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.5259 - val_loss: 0.5994\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.5184 - val_loss: 0.5869\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.5114 - val_loss: 0.5760\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.5046 - val_loss: 0.5648\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.4980 - val_loss: 0.5554\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.4917 - val_loss: 0.5456\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.4857 - val_loss: 0.5379\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.4798 - val_loss: 0.5296\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.4745 - val_loss: 0.5222\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.4693 - val_loss: 0.5159\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.4645 - val_loss: 0.5112\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.4603 - val_loss: 0.5032\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.4561 - val_loss: 0.4983\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.4522 - val_loss: 0.4932\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.4486 - val_loss: 0.4896\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.4451 - val_loss: 0.4853\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.4419 - val_loss: 0.4830\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.4388 - val_loss: 0.4807\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.4360 - val_loss: 0.4794\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.4332 - val_loss: 0.4778\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.4305 - val_loss: 0.4781\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.4283 - val_loss: 0.4763\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.4259 - val_loss: 0.4757\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.4237 - val_loss: 0.4752\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.4215 - val_loss: 0.4749\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.4194 - val_loss: 0.4747\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.4175 - val_loss: 0.4751\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.4156 - val_loss: 0.4767\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.4139 - val_loss: 0.4777\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.4122 - val_loss: 0.4790\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.4106 - val_loss: 0.4808\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.4090 - val_loss: 0.4821\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.4075 - val_loss: 0.4850\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.4061 - val_loss: 0.4876\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.4047 - val_loss: 0.4886\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.4033 - val_loss: 0.4910\n",
      "121/121 [==============================] - 0s 518us/step - loss: 0.4261\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5649 - val_loss: 2.8185\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 1.9552 - val_loss: 3.2461\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 1.2709 - val_loss: 1.6874\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.9485 - val_loss: 1.0478\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.7971 - val_loss: 0.8043\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.7222 - val_loss: 0.6945\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.6817 - val_loss: 0.6401\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.6543 - val_loss: 0.6106\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.6326 - val_loss: 0.5894\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.6152 - val_loss: 0.5735\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.5994 - val_loss: 0.5591\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.5847 - val_loss: 0.5452\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.5719 - val_loss: 0.5384\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.5601 - val_loss: 0.5243\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.5489 - val_loss: 0.5139\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.5386 - val_loss: 0.5065\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.5287 - val_loss: 0.4999\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.5194 - val_loss: 0.4884\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.5113 - val_loss: 0.4877\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.5033 - val_loss: 0.4816\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.4959 - val_loss: 0.4807\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.4893 - val_loss: 0.4755\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.4831 - val_loss: 0.4758\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4773 - val_loss: 0.4700\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.4720 - val_loss: 0.4642\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.4670 - val_loss: 0.4654\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.4624 - val_loss: 0.4638\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.4582 - val_loss: 0.4632\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.4543 - val_loss: 0.4592\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.4507 - val_loss: 0.4582\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.4471 - val_loss: 0.4516\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.4442 - val_loss: 0.4564\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.4412 - val_loss: 0.4583\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.4384 - val_loss: 0.4637\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.4359 - val_loss: 0.4517\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.4338 - val_loss: 0.4550\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.4314 - val_loss: 0.4623\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.4294 - val_loss: 0.4575\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.4274 - val_loss: 0.4471\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 806us/step - loss: 0.4252 - val_loss: 0.4649\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.4238 - val_loss: 0.4577\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.4220 - val_loss: 0.4583\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.4203 - val_loss: 0.4568\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.4187 - val_loss: 0.4533\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.4172 - val_loss: 0.4576\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.4155 - val_loss: 0.4472\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.4145 - val_loss: 0.4580\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.4130 - val_loss: 0.4654\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.4118 - val_loss: 0.4583\n",
      "121/121 [==============================] - 0s 539us/step - loss: 0.4294\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3258 - val_loss: 5.4241\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.9035 - val_loss: 1.2329\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.7336 - val_loss: 0.7443\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.6826 - val_loss: 0.6573\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.6481 - val_loss: 0.6126\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.6198 - val_loss: 0.5865\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.5950 - val_loss: 0.5647\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.5730 - val_loss: 0.5494\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.5535 - val_loss: 0.5301\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.5358 - val_loss: 0.5179\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.5195 - val_loss: 0.5033\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.5049 - val_loss: 0.4878\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.4919 - val_loss: 0.4793\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.4804 - val_loss: 0.4782\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.4699 - val_loss: 0.4784\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.4608 - val_loss: 0.4560\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.4524 - val_loss: 0.4477\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.4452 - val_loss: 0.4488\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.4385 - val_loss: 0.4526\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.4325 - val_loss: 0.4510\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.4271 - val_loss: 0.4695\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.4225 - val_loss: 0.4561\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.4179 - val_loss: 0.4431\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.4138 - val_loss: 0.4357\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.4097 - val_loss: 0.4330\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.4066 - val_loss: 0.4380\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.4032 - val_loss: 0.4543\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.4003 - val_loss: 0.4599\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.3976 - val_loss: 0.4347\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.3947 - val_loss: 0.4226\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.3925 - val_loss: 0.4210\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.3899 - val_loss: 0.4386\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3880 - val_loss: 0.4310\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.3856 - val_loss: 0.4354\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3837 - val_loss: 0.4289\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.3819 - val_loss: 0.4416\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.3801 - val_loss: 0.4214\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.3783 - val_loss: 0.4459\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.3767 - val_loss: 0.4202\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.3751 - val_loss: 0.4195\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.3736 - val_loss: 0.4227\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.3722 - val_loss: 0.4105\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.3709 - val_loss: 0.4140\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.3695 - val_loss: 0.4050\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.3683 - val_loss: 0.4245\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.3673 - val_loss: 0.4032\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3658 - val_loss: 0.4278\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.3650 - val_loss: 0.4054\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 803us/step - loss: 0.3638 - val_loss: 0.4302\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 0.3627 - val_loss: 0.4111\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.3617 - val_loss: 0.4049\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.3605 - val_loss: 0.4218\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.3598 - val_loss: 0.4260\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.3587 - val_loss: 0.4087\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3578 - val_loss: 0.4200\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3569 - val_loss: 0.4318\n",
      "121/121 [==============================] - 0s 515us/step - loss: 0.3813\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2155 - val_loss: 17.6470\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.8393 - val_loss: 9.2002\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.7163 - val_loss: 5.0378\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.6621 - val_loss: 2.5633\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.6214 - val_loss: 1.2739\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.5877 - val_loss: 0.6697\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.5604 - val_loss: 0.5288\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5376 - val_loss: 0.6019\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.5184 - val_loss: 0.8029\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.5022 - val_loss: 1.0148\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.4886 - val_loss: 1.1963\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.4772 - val_loss: 1.3442\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.4674 - val_loss: 1.5101\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 804us/step - loss: 0.4592 - val_loss: 1.5931\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.4521 - val_loss: 1.6796\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.4462 - val_loss: 1.5887\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.4408 - val_loss: 1.6645\n",
      "121/121 [==============================] - 0s 543us/step - loss: 0.5451\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8956 - val_loss: 1.0747\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.8019 - val_loss: 0.7313\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.7103 - val_loss: 0.7120\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.6606 - val_loss: 0.6185\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.6234 - val_loss: 0.5896\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.5921 - val_loss: 0.5639\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.5653 - val_loss: 0.5429\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.5425 - val_loss: 0.5131\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.5228 - val_loss: 0.5161\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.5050 - val_loss: 0.5098\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.4900 - val_loss: 0.4896\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.4768 - val_loss: 0.4713\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.4649 - val_loss: 0.4742\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.4547 - val_loss: 0.4747\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.4462 - val_loss: 0.4527\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.4379 - val_loss: 0.4479\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 821us/step - loss: 0.4320 - val_loss: 0.4727\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.4262 - val_loss: 0.4172\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.4208 - val_loss: 0.4533\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.4168 - val_loss: 0.4425\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.4134 - val_loss: 0.4145\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.4098 - val_loss: 0.4303\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.4069 - val_loss: 0.4136\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 806us/step - loss: 0.4038 - val_loss: 0.4369\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4013 - val_loss: 0.4594\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.3992 - val_loss: 0.4646\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.3970 - val_loss: 0.4748\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.3952 - val_loss: 0.4542\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.3937 - val_loss: 0.3968\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.3917 - val_loss: 0.4620\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.3902 - val_loss: 0.4767\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.3891 - val_loss: 0.4041\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3871 - val_loss: 0.3798\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.3859 - val_loss: 0.4568\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.3852 - val_loss: 0.3822\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.3835 - val_loss: 0.4795\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.3831 - val_loss: 0.4052\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3815 - val_loss: 0.4457\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3810 - val_loss: 0.3840\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.3792 - val_loss: 0.4748\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.3790 - val_loss: 0.3610\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.3778 - val_loss: 0.3828\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.3765 - val_loss: 0.4052\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.3754 - val_loss: 0.4675\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3751 - val_loss: 0.4113\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.3742 - val_loss: 0.3885\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.3732 - val_loss: 0.4330\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.3725 - val_loss: 0.3801\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.3720 - val_loss: 0.3513\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.3707 - val_loss: 0.4870\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.3709 - val_loss: 0.4303\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.3698 - val_loss: 0.3587\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.3686 - val_loss: 0.4695\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3688 - val_loss: 0.3483\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.3674 - val_loss: 0.3613\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.3666 - val_loss: 0.4191\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 806us/step - loss: 0.3663 - val_loss: 0.4521\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.3660 - val_loss: 0.3525\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.3648 - val_loss: 0.4442\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.3646 - val_loss: 0.4042\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.3641 - val_loss: 0.3601\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3633 - val_loss: 0.3718\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.3628 - val_loss: 0.3472\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.3618 - val_loss: 0.4199\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3621 - val_loss: 0.3492\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.3608 - val_loss: 0.4109\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.3607 - val_loss: 0.3627\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.3596 - val_loss: 0.4559\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.3597 - val_loss: 0.4298\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3592 - val_loss: 0.3508\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.3584 - val_loss: 0.3497\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.3576 - val_loss: 0.4068\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.3576 - val_loss: 0.3369\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3566 - val_loss: 0.4924\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3571 - val_loss: 0.3453\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.3557 - val_loss: 0.3885\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.3554 - val_loss: 0.4032\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.3552 - val_loss: 0.3352\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.3546 - val_loss: 0.3516\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.3541 - val_loss: 0.3355\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 797us/step - loss: 0.3533 - val_loss: 0.4124\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.3535 - val_loss: 0.3348\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3525 - val_loss: 0.3838\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.3524 - val_loss: 0.3900\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.3519 - val_loss: 0.3508\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.3513 - val_loss: 0.4296\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.3515 - val_loss: 0.3324\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.3505 - val_loss: 0.4866\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.3506 - val_loss: 0.3426\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.3500 - val_loss: 0.5102\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.3501 - val_loss: 0.3837\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 794us/step - loss: 0.3489 - val_loss: 0.4207\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.3492 - val_loss: 0.3325\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.3480 - val_loss: 0.4467\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.3482 - val_loss: 0.3770\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.3476 - val_loss: 0.4171\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.3474 - val_loss: 0.3641\n",
      "121/121 [==============================] - 0s 471us/step - loss: 0.3525\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9603 - val_loss: 2.0342\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 1.0954 - val_loss: 0.8733\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.8104 - val_loss: 0.7631\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.7250 - val_loss: 0.7361\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.6759 - val_loss: 0.6297\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.6438 - val_loss: 0.7199\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.6154 - val_loss: 0.5975\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.5887 - val_loss: 0.5803\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 734us/step - loss: 0.5702 - val_loss: 0.9088\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.5454 - val_loss: 0.4973\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.5261 - val_loss: 0.5769\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.5074 - val_loss: 0.4826\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.4909 - val_loss: 0.4612\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.4774 - val_loss: 0.4414\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.4641 - val_loss: 0.4754\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 0.4539 - val_loss: 0.4209\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.4447 - val_loss: 0.4252\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.4370 - val_loss: 0.4121\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 778us/step - loss: 0.4303 - val_loss: 0.4567\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.4244 - val_loss: 0.4484\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.4193 - val_loss: 0.4074\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 0.4148 - val_loss: 0.4384\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 724us/step - loss: 0.4105 - val_loss: 0.4390\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.4076 - val_loss: 0.4062\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.4048 - val_loss: 0.4478\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 0.4019 - val_loss: 0.4340\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.3992 - val_loss: 0.4068\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.3967 - val_loss: 0.4550\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3943 - val_loss: 0.4188\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.3928 - val_loss: 0.4791\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.3913 - val_loss: 0.4282\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.3895 - val_loss: 0.3832\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.3883 - val_loss: 0.4645\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3862 - val_loss: 0.3973\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 731us/step - loss: 0.3855 - val_loss: 0.5324\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3842 - val_loss: 0.4018\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.3830 - val_loss: 0.4967\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.3815 - val_loss: 0.4232\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.3806 - val_loss: 0.4853\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 754us/step - loss: 0.3794 - val_loss: 0.4369\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.3784 - val_loss: 0.4282\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.3774 - val_loss: 0.4259\n",
      "121/121 [==============================] - 0s 524us/step - loss: 0.4143\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5111 - val_loss: 0.9398\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.6781 - val_loss: 0.6568\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.6191 - val_loss: 0.5786\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.5878 - val_loss: 0.5514\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 0.5635 - val_loss: 0.5379\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.5435 - val_loss: 0.5340\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.5256 - val_loss: 0.5187\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.5107 - val_loss: 0.4895\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.4976 - val_loss: 0.4747\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.4864 - val_loss: 0.4587\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.4775 - val_loss: 0.4448\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.4701 - val_loss: 0.4355\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.4639 - val_loss: 0.4312\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.4580 - val_loss: 0.4341\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.4532 - val_loss: 0.4379\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.4493 - val_loss: 0.4508\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.4456 - val_loss: 0.4607\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.4423 - val_loss: 0.4792\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.4391 - val_loss: 0.4954\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 784us/step - loss: 0.4371 - val_loss: 0.5181\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 750us/step - loss: 0.4346 - val_loss: 0.5418\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.4325 - val_loss: 0.5751\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.4305 - val_loss: 0.5872\n",
      "121/121 [==============================] - 0s 486us/step - loss: 0.4683\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9543 - val_loss: 2.1086\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 1.0086 - val_loss: 0.8700\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.7921 - val_loss: 0.7537\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 798us/step - loss: 0.7076 - val_loss: 0.7773\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.6783 - val_loss: 1.4097\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.6438 - val_loss: 0.7534\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.6315 - val_loss: 1.7974\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.6059 - val_loss: 2.1399\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.6307 - val_loss: 1.5117\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.5774 - val_loss: 1.7113\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.5912 - val_loss: 0.5818\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.5561 - val_loss: 0.8628\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.5447 - val_loss: 0.5148\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.5378 - val_loss: 0.6866\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.5233 - val_loss: 0.8997\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.5300 - val_loss: 0.5484\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 784us/step - loss: 0.5061 - val_loss: 1.1751\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.5220 - val_loss: 1.0299\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.5021 - val_loss: 0.5263\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.4981 - val_loss: 0.5319\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.4883 - val_loss: 0.4610\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.4806 - val_loss: 0.6073\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.4805 - val_loss: 0.4512\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 818us/step - loss: 0.4739 - val_loss: 0.7782\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.4669 - val_loss: 0.5607\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.4662 - val_loss: 0.6739\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.4569 - val_loss: 0.4772\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.4538 - val_loss: 0.4239\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.4468 - val_loss: 0.4211\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.4436 - val_loss: 0.4511\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.4374 - val_loss: 0.6141\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 762us/step - loss: 0.4384 - val_loss: 0.4428\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.4311 - val_loss: 0.4055\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.4273 - val_loss: 0.4012\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.4241 - val_loss: 0.3961\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.4213 - val_loss: 0.3952\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.4191 - val_loss: 0.3911\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.4171 - val_loss: 0.4004\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.4144 - val_loss: 0.4130\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.4132 - val_loss: 0.3961\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.4113 - val_loss: 0.3983\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 727us/step - loss: 0.4100 - val_loss: 0.3899\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.4081 - val_loss: 0.4122\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.4072 - val_loss: 0.4029\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.4059 - val_loss: 0.4042\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 726us/step - loss: 0.4046 - val_loss: 0.3920\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.4035 - val_loss: 0.3963\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.4027 - val_loss: 0.3870\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.4023 - val_loss: 0.3926\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.4011 - val_loss: 0.3969\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.4004 - val_loss: 0.4026\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.3995 - val_loss: 0.3975\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 729us/step - loss: 0.3989 - val_loss: 0.3862\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.3984 - val_loss: 0.3842\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.3977 - val_loss: 0.3862\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.3967 - val_loss: 0.3903\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3970 - val_loss: 0.3790\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3962 - val_loss: 0.4059\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.3952 - val_loss: 0.3895\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 0.3950 - val_loss: 0.3780\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.3946 - val_loss: 0.3818\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.4026\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.3936 - val_loss: 0.3840\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.3931 - val_loss: 0.4039\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.3932 - val_loss: 0.3781\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.3923 - val_loss: 0.3846\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.3920 - val_loss: 0.3813\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.3919 - val_loss: 0.3915\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.3913 - val_loss: 0.3975\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.3909 - val_loss: 0.3864\n",
      "121/121 [==============================] - 0s 477us/step - loss: 0.3859\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6946 - val_loss: 6.9304\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 1.7159 - val_loss: 10.0970\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 1.2439 - val_loss: 4.0896\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.9691 - val_loss: 2.6309\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.8394 - val_loss: 1.8262\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.7692 - val_loss: 1.2754\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.7264 - val_loss: 0.9806\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.6971 - val_loss: 0.8059\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.6750 - val_loss: 0.7060\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.6570 - val_loss: 0.6487\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.6414 - val_loss: 0.6155\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.6274 - val_loss: 0.5933\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.6144 - val_loss: 0.5755\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.6023 - val_loss: 0.5635\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.5909 - val_loss: 0.5521\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.5799 - val_loss: 0.5415\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.5699 - val_loss: 0.5321\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.5600 - val_loss: 0.5235\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.5509 - val_loss: 0.5151\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.5421 - val_loss: 0.5072\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.5338 - val_loss: 0.5000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.5259 - val_loss: 0.4925\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.5185 - val_loss: 0.4853\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.5112 - val_loss: 0.4783\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.5043 - val_loss: 0.4718\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.4978 - val_loss: 0.4655\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4915 - val_loss: 0.4595\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.4856 - val_loss: 0.4536\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.4797 - val_loss: 0.4480\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4743 - val_loss: 0.4428\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.4692 - val_loss: 0.4380\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.4642 - val_loss: 0.4332\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.4595 - val_loss: 0.4299\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.4552 - val_loss: 0.4255\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.4510 - val_loss: 0.4216\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.4469 - val_loss: 0.4184\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.4432 - val_loss: 0.4161\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.4396 - val_loss: 0.4132\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4360 - val_loss: 0.4108\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.4328 - val_loss: 0.4085\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.4296 - val_loss: 0.4069\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.4267 - val_loss: 0.4044\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.4237 - val_loss: 0.4035\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.4210 - val_loss: 0.4007\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.4186 - val_loss: 0.4004\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.4161 - val_loss: 0.3982\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.4137 - val_loss: 0.3993\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4116 - val_loss: 0.3973\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.4094 - val_loss: 0.3970\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.4074 - val_loss: 0.3960\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.4054 - val_loss: 0.3968\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.4036 - val_loss: 0.3949\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.4015 - val_loss: 0.3951\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4000 - val_loss: 0.3953\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.3983 - val_loss: 0.3940\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.3966 - val_loss: 0.3941\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.3950 - val_loss: 0.3935\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.3935 - val_loss: 0.3948\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.3919 - val_loss: 0.3928\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3906 - val_loss: 0.3926\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.3891 - val_loss: 0.3929\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3877 - val_loss: 0.3933\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.3865 - val_loss: 0.3906\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.3852 - val_loss: 0.3902\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.3838 - val_loss: 0.3894\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3827 - val_loss: 0.3911\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.3813 - val_loss: 0.3887\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3803 - val_loss: 0.3894\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.3791 - val_loss: 0.3892\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.3780 - val_loss: 0.3877\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.3769 - val_loss: 0.3877\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.3758 - val_loss: 0.3883\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.3747 - val_loss: 0.3823\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.3738 - val_loss: 0.3806\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.3728 - val_loss: 0.3825\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.3717 - val_loss: 0.3788\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.3708 - val_loss: 0.3857\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 841us/step - loss: 0.3701 - val_loss: 0.3801\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.3691 - val_loss: 0.3773\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.3682 - val_loss: 0.3752\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.3673 - val_loss: 0.3760\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.3664 - val_loss: 0.3765\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.3657 - val_loss: 0.3754\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.3649 - val_loss: 0.3736\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.3640 - val_loss: 0.3734\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.3748\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.3625 - val_loss: 0.3718\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3619 - val_loss: 0.3720\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3612 - val_loss: 0.3700\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.3604 - val_loss: 0.3708\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.3598 - val_loss: 0.3673\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.3591 - val_loss: 0.3640\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3584 - val_loss: 0.3652\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3577 - val_loss: 0.3652\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3571 - val_loss: 0.3619\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.3566 - val_loss: 0.3645\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3560 - val_loss: 0.3696\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3551 - val_loss: 0.3613\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.3548 - val_loss: 0.3604\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3542 - val_loss: 0.3562\n",
      "121/121 [==============================] - 0s 586us/step - loss: 0.3705\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.7260 - val_loss: 3.3705\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 1.5862 - val_loss: 4.7891\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 1.0648 - val_loss: 4.9460\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.9243 - val_loss: 4.3092\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.8451 - val_loss: 3.6737\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.7917 - val_loss: 3.1391\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7525 - val_loss: 2.6849\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.7221 - val_loss: 2.2921\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6975 - val_loss: 1.9862\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.6768 - val_loss: 1.7121\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.6587 - val_loss: 1.4932\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.6425 - val_loss: 1.3080\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.6279 - val_loss: 1.1811\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.6142 - val_loss: 1.0482\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6015 - val_loss: 0.9206\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.5893 - val_loss: 0.8284\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.5777 - val_loss: 0.7445\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.5667 - val_loss: 0.6818\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.5564 - val_loss: 0.6249\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.5466 - val_loss: 0.5793\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.5372 - val_loss: 0.5498\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.5286 - val_loss: 0.5185\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.5202 - val_loss: 0.4985\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.5124 - val_loss: 0.4858\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.5051 - val_loss: 0.4778\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.4982 - val_loss: 0.4718\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.4916 - val_loss: 0.4682\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.4855 - val_loss: 0.4663\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.4797 - val_loss: 0.4639\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.4743 - val_loss: 0.4628\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.4691 - val_loss: 0.4618\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.4642 - val_loss: 0.4600\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.4598 - val_loss: 0.4610\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.4555 - val_loss: 0.4588\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.4513 - val_loss: 0.4552\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.4474 - val_loss: 0.4512\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.4436 - val_loss: 0.4492\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.4401 - val_loss: 0.4425\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.4367 - val_loss: 0.4372\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.4335 - val_loss: 0.4328\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.4303 - val_loss: 0.4263\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.4275 - val_loss: 0.4202\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.4245 - val_loss: 0.4128\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.4217 - val_loss: 0.4065\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.4193 - val_loss: 0.4023\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.4167 - val_loss: 0.3970\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.4143 - val_loss: 0.3932\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.4118 - val_loss: 0.3901\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.4097 - val_loss: 0.3874\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.4074 - val_loss: 0.3853\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.4053 - val_loss: 0.3847\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4034 - val_loss: 0.3851\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.4014 - val_loss: 0.3858\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3995 - val_loss: 0.3882\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.3976 - val_loss: 0.3899\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3959 - val_loss: 0.3954\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3941 - val_loss: 0.3992\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.3924 - val_loss: 0.4073\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.3909 - val_loss: 0.4153\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3893 - val_loss: 0.4203\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3879 - val_loss: 0.4313\n",
      "121/121 [==============================] - 0s 802us/step - loss: 0.4136\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6427 - val_loss: 4.1916\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 1.5715 - val_loss: 3.9695\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.9970 - val_loss: 2.8414\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.7993 - val_loss: 1.7307\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.7099 - val_loss: 1.1539\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6627 - val_loss: 0.8633\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.6344 - val_loss: 0.7163\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.6140 - val_loss: 0.6293\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.5979 - val_loss: 0.5851\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.5843 - val_loss: 0.5603\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.5719 - val_loss: 0.5455\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.5607 - val_loss: 0.5336\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5503 - val_loss: 0.5249\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.5404 - val_loss: 0.5169\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.5311 - val_loss: 0.5080\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.5226 - val_loss: 0.4996\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.5142 - val_loss: 0.4916\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.5064 - val_loss: 0.4848\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.4988 - val_loss: 0.4763\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.4916 - val_loss: 0.4685\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.4846 - val_loss: 0.4618\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4780 - val_loss: 0.4551\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4716 - val_loss: 0.4491\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 0.4656 - val_loss: 0.4427\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.4600 - val_loss: 0.4373\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.4548 - val_loss: 0.4325\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.4497 - val_loss: 0.4285\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.4447 - val_loss: 0.4260\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.4403 - val_loss: 0.4213\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.4361 - val_loss: 0.4172\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4322 - val_loss: 0.4168\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4155\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 0.4138\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4216 - val_loss: 0.4132\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4186 - val_loss: 0.4127\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.4157 - val_loss: 0.4126\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.4131 - val_loss: 0.4078\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4107 - val_loss: 0.4103\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.4084 - val_loss: 0.4097\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.4062 - val_loss: 0.4074\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.4041 - val_loss: 0.4094\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.4021 - val_loss: 0.4053\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 0.4002 - val_loss: 0.4105\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.3986 - val_loss: 0.4073\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3969 - val_loss: 0.4080\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3954 - val_loss: 0.4086\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.3938 - val_loss: 0.4074\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.3925 - val_loss: 0.4075\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.3910 - val_loss: 0.4076\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.3896 - val_loss: 0.4061\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3884 - val_loss: 0.4030\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.3872 - val_loss: 0.4023\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.3860 - val_loss: 0.4079\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.4037\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3836 - val_loss: 0.4083\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.4027\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.4027\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.3805 - val_loss: 0.4056\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.3795 - val_loss: 0.3996\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.3784 - val_loss: 0.4109\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.3776 - val_loss: 0.4041\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.3767 - val_loss: 0.4073\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3758 - val_loss: 0.4067\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.3748 - val_loss: 0.4097\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3741 - val_loss: 0.4018\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3732 - val_loss: 0.4007\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3724 - val_loss: 0.4110\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.3716 - val_loss: 0.3992\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.3709 - val_loss: 0.4022\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3701 - val_loss: 0.4047\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.3694 - val_loss: 0.3958\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.3688 - val_loss: 0.3992\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.3680 - val_loss: 0.3998\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.3674 - val_loss: 0.3966\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3665 - val_loss: 0.3986\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.3657 - val_loss: 0.3900\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3653 - val_loss: 0.3971\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 0.3646 - val_loss: 0.3977\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 0.3983\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.3993\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3629 - val_loss: 0.3994\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.3947\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3616 - val_loss: 0.3980\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.4006\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.4036\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.3599 - val_loss: 0.3972\n",
      "121/121 [==============================] - 0s 827us/step - loss: 0.3682\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1683 - val_loss: 3.3504\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5250 - val_loss: 2.3723\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4637 - val_loss: 0.4026\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4159 - val_loss: 0.4059\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.3932\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.3830\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3851 - val_loss: 0.3946\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.3844\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3727 - val_loss: 0.3646\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.4108\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3674 - val_loss: 0.3513\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 0.3575\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3591 - val_loss: 0.3564\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.3543 - val_loss: 0.3424\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3521 - val_loss: 0.3664\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3508 - val_loss: 0.3463\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.3493 - val_loss: 0.3490\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.3440\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.3461 - val_loss: 0.3497\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3448 - val_loss: 0.3585\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3448 - val_loss: 0.3516\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.3405 - val_loss: 0.3351\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.3379 - val_loss: 0.3431\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.3371 - val_loss: 0.3358\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 0.3571\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.3339 - val_loss: 0.3424\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3344 - val_loss: 0.3674\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.3345 - val_loss: 0.3450\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.3316 - val_loss: 0.3232\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3297 - val_loss: 0.3718\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3287 - val_loss: 0.3212\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.3273 - val_loss: 0.3494\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.3272 - val_loss: 0.3742\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3273 - val_loss: 0.4485\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.3265 - val_loss: 0.3269\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3248 - val_loss: 0.3486\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.3235 - val_loss: 0.3225\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.3217 - val_loss: 0.3184\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.3205 - val_loss: 0.3214\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3196 - val_loss: 0.3186\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.3196 - val_loss: 0.3857\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3191 - val_loss: 0.3216\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3169 - val_loss: 0.3180\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.3179 - val_loss: 0.3281\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3147 - val_loss: 0.3806\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3143 - val_loss: 0.3166\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3138 - val_loss: 0.6139\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.3263 - val_loss: 0.5722\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.3220 - val_loss: 0.4559\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.3162 - val_loss: 0.3088\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3149 - val_loss: 0.3447\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.3129 - val_loss: 0.3380\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.3125 - val_loss: 0.3311\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3109 - val_loss: 0.3306\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3113 - val_loss: 0.3145\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3106 - val_loss: 0.3115\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3080 - val_loss: 0.3454\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.3080 - val_loss: 0.3290\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.3073 - val_loss: 0.3029\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.3078 - val_loss: 0.3072\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.3060 - val_loss: 0.3465\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.3059 - val_loss: 0.3092\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3049 - val_loss: 0.3404\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 0.3048 - val_loss: 0.2983\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 827us/step - loss: 0.3046 - val_loss: 0.3001\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3042 - val_loss: 0.3533\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.3026 - val_loss: 0.3065\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3018 - val_loss: 0.3441\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.3025 - val_loss: 0.3004\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3024 - val_loss: 0.3078\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3000 - val_loss: 0.3295\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.3012 - val_loss: 0.3260\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3003 - val_loss: 0.2959\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3002 - val_loss: 0.3336\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2993 - val_loss: 0.2975\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2998 - val_loss: 0.3001\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2993 - val_loss: 0.3073\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2985 - val_loss: 0.3105\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2986 - val_loss: 0.3437\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.2968 - val_loss: 0.3115\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.2954 - val_loss: 0.3234\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.2967 - val_loss: 0.3332\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.2964 - val_loss: 0.2916\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.2964 - val_loss: 0.2977\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.2948 - val_loss: 0.3919\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.2965 - val_loss: 0.3268\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2939 - val_loss: 0.5403\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.2964 - val_loss: 0.3452\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2957 - val_loss: 0.3848\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2943 - val_loss: 0.3175\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2929 - val_loss: 0.2938\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2936 - val_loss: 0.3031\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.2933 - val_loss: 0.3532\n",
      "121/121 [==============================] - 0s 553us/step - loss: 0.3259\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0075 - val_loss: 1.2080\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5897 - val_loss: 0.5967\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5108 - val_loss: 0.4777\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4588 - val_loss: 0.4816\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4273 - val_loss: 0.4657\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.4096 - val_loss: 0.4472\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.3989 - val_loss: 0.4103\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.3929 - val_loss: 0.3887\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3853 - val_loss: 0.3718\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.3811 - val_loss: 0.3576\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3777 - val_loss: 0.3520\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3739 - val_loss: 0.3551\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3701 - val_loss: 0.3704\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3684 - val_loss: 0.3683\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3652 - val_loss: 0.4142\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 0.3652 - val_loss: 0.3564\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.3621 - val_loss: 0.3627\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.3603 - val_loss: 0.3928\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 829us/step - loss: 0.3580 - val_loss: 0.3635\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3572 - val_loss: 0.3656\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3540 - val_loss: 0.3784\n",
      "121/121 [==============================] - 0s 623us/step - loss: 0.3824\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9741 - val_loss: 2.6502\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.5725 - val_loss: 8.8002\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.5573 - val_loss: 2.7851\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.4796 - val_loss: 0.4167\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.4335 - val_loss: 0.4433\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.4178 - val_loss: 0.4255\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.4568\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.4023 - val_loss: 0.3818\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.3955 - val_loss: 0.4641\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.3973\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3862 - val_loss: 0.3688\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.4553\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.4015\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3752 - val_loss: 0.3554\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.4287\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3694 - val_loss: 0.3586\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.3666 - val_loss: 0.4174\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.3668 - val_loss: 0.3640\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 850us/step - loss: 0.3645 - val_loss: 0.3474\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3598 - val_loss: 0.3479\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.3560 - val_loss: 0.3614\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3537 - val_loss: 0.3471\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.3350\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.3645\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3476 - val_loss: 0.3296\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.3464 - val_loss: 0.3470\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.3438 - val_loss: 0.3308\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3426 - val_loss: 0.3488\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3412 - val_loss: 0.3310\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.3401 - val_loss: 0.3521\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3400 - val_loss: 0.3275\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3385 - val_loss: 0.3453\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3368 - val_loss: 0.3406\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.3357 - val_loss: 0.3514\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3347 - val_loss: 0.3358\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.3320 - val_loss: 0.3494\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 810us/step - loss: 0.3316 - val_loss: 0.3271\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.3327 - val_loss: 0.3319\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.3303 - val_loss: 0.3399\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 0.3281 - val_loss: 0.3602\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3278 - val_loss: 0.3449\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.3266 - val_loss: 0.3221\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3260 - val_loss: 0.3550\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.3253 - val_loss: 0.3573\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.3237 - val_loss: 0.3581\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.3247 - val_loss: 0.3186\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.3236 - val_loss: 0.3274\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.3215 - val_loss: 0.3338\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.3213 - val_loss: 0.3260\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 905us/step - loss: 0.3196 - val_loss: 0.3359\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.3191 - val_loss: 0.3457\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.3192 - val_loss: 0.3165\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 871us/step - loss: 0.3187 - val_loss: 0.3170\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.3188 - val_loss: 0.3117\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3171 - val_loss: 0.3206\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.3157 - val_loss: 0.3163\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.3139 - val_loss: 0.3129\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.3137 - val_loss: 0.3292\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.3147 - val_loss: 0.3406\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.3132 - val_loss: 0.3000\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3122 - val_loss: 0.3134\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.3103 - val_loss: 0.3070\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.3104 - val_loss: 0.3309\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.3102 - val_loss: 0.3135\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.3098 - val_loss: 0.2985\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.3073 - val_loss: 0.3131\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.3073 - val_loss: 0.3000\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.3074 - val_loss: 0.3212\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.3074 - val_loss: 0.2955\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.3044 - val_loss: 0.3197\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.3056 - val_loss: 0.3096\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.3043 - val_loss: 0.3042\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3043 - val_loss: 0.3283\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.3044 - val_loss: 0.3168\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.3039 - val_loss: 0.3059\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.3049 - val_loss: 0.3282\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 942us/step - loss: 0.3028 - val_loss: 0.3054\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.3023 - val_loss: 0.3171\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.3023\n",
      "121/121 [==============================] - 0s 528us/step - loss: 0.3080\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8952 - val_loss: 14.3001\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.8816 - val_loss: 2.6381\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.6412 - val_loss: 0.6392\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 0.5777 - val_loss: 0.5350\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.5414 - val_loss: 0.5037\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.5152 - val_loss: 0.5098\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.4937 - val_loss: 0.4624\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 771us/step - loss: 0.4769 - val_loss: 0.4808\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.4631 - val_loss: 0.4460\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 759us/step - loss: 0.4516 - val_loss: 0.4491\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.4427 - val_loss: 0.4187\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.4356 - val_loss: 0.4407\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.4292 - val_loss: 0.4068\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.4239 - val_loss: 0.4514\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 0.4199 - val_loss: 0.3961\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.4157 - val_loss: 0.4574\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.4124 - val_loss: 0.4250\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.4090 - val_loss: 0.4332\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.4068 - val_loss: 0.3854\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.4039 - val_loss: 0.4771\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.4022 - val_loss: 0.3858\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 803us/step - loss: 0.3994 - val_loss: 0.4220\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 894us/step - loss: 0.3973 - val_loss: 0.3818\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.3952 - val_loss: 0.3813\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.3928 - val_loss: 0.3850\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3922 - val_loss: 0.4097\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.3901 - val_loss: 0.4024\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.3881 - val_loss: 0.3679\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.3868 - val_loss: 0.3825\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 756us/step - loss: 0.3844 - val_loss: 0.3990\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.3838 - val_loss: 0.3674\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 0.3813 - val_loss: 0.4589\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3811 - val_loss: 0.3883\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3790 - val_loss: 0.3876\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3778 - val_loss: 0.4499\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.3769 - val_loss: 0.3962\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3755 - val_loss: 0.3575\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3739 - val_loss: 0.4388\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.3905\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 782us/step - loss: 0.3721 - val_loss: 0.3741\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 0.3704 - val_loss: 0.4313\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.3706 - val_loss: 0.3898\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.3690 - val_loss: 0.4014\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.3687 - val_loss: 0.3548\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3667 - val_loss: 0.3670\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.3662 - val_loss: 0.3824\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.3656 - val_loss: 0.3785\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.3645 - val_loss: 0.3820\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3644 - val_loss: 0.3510\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.3621 - val_loss: 0.5206\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.3642 - val_loss: 0.3696\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.3613 - val_loss: 0.4148\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.3613 - val_loss: 0.3542\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 854us/step - loss: 0.3602 - val_loss: 0.3673\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.3596 - val_loss: 0.3849\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.3588 - val_loss: 0.3921\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 733us/step - loss: 0.3583 - val_loss: 0.4071\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 784us/step - loss: 0.3579 - val_loss: 0.3822\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.3573 - val_loss: 0.3461\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.3557 - val_loss: 0.4235\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.3563 - val_loss: 0.3608\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 0.3548 - val_loss: 0.3454\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 789us/step - loss: 0.3549 - val_loss: 0.3421\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 802us/step - loss: 0.3535 - val_loss: 0.4876\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 741us/step - loss: 0.3555 - val_loss: 0.3746\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 823us/step - loss: 0.3552 - val_loss: 0.5477\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 749us/step - loss: 0.3548 - val_loss: 0.3606\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.3525 - val_loss: 0.3679\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.3519 - val_loss: 0.3964\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.3506 - val_loss: 0.3506\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 826us/step - loss: 0.3507 - val_loss: 0.3921\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3507 - val_loss: 0.3421\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 834us/step - loss: 0.3491 - val_loss: 0.4098\n",
      "121/121 [==============================] - 0s 537us/step - loss: 0.3755\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5718 - val_loss: 0.9368\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.6887 - val_loss: 0.6267\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.6199 - val_loss: 0.6770\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.5738 - val_loss: 0.7811\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.5381 - val_loss: 0.9202\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.5100 - val_loss: 0.9518\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.4871 - val_loss: 0.9048\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.4691 - val_loss: 0.9518\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.4550 - val_loss: 0.8793\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.4445 - val_loss: 0.7486\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.4354 - val_loss: 0.6439\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.4281 - val_loss: 0.5202\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 917us/step - loss: 0.4220 - val_loss: 0.4706\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.4173 - val_loss: 0.4056\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 838us/step - loss: 0.4132 - val_loss: 0.3841\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.4097 - val_loss: 0.3775\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.4064 - val_loss: 0.3875\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 806us/step - loss: 0.4038 - val_loss: 0.4179\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.4011 - val_loss: 0.4642\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.3995 - val_loss: 0.4692\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.3974 - val_loss: 0.5146\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.3955 - val_loss: 0.5169\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.3938 - val_loss: 0.5800\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3923 - val_loss: 0.6225\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.3908 - val_loss: 0.6559\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.3897 - val_loss: 0.6971\n",
      "121/121 [==============================] - 0s 565us/step - loss: 0.4184\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1563 - val_loss: 31.8545\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 766us/step - loss: 1.0436 - val_loss: 5.8648\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.6998 - val_loss: 0.6306\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.6005 - val_loss: 0.5499\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.5607 - val_loss: 0.5214\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.5329 - val_loss: 0.4923\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.5108 - val_loss: 0.4695\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 855us/step - loss: 0.4943 - val_loss: 0.4535\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 843us/step - loss: 0.4804 - val_loss: 0.4643\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.4706 - val_loss: 0.4375\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.4615 - val_loss: 0.4439\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.4546 - val_loss: 0.4424\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.4483 - val_loss: 0.4150\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 783us/step - loss: 0.4437 - val_loss: 0.4141\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.4391 - val_loss: 0.4220\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 797us/step - loss: 0.4354 - val_loss: 0.4350\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 0.4318 - val_loss: 0.4081\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.4290 - val_loss: 0.4072\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.4257 - val_loss: 0.4204\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 0.4230 - val_loss: 0.4221\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.4209 - val_loss: 0.3983\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.4185 - val_loss: 0.4355\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.4166 - val_loss: 0.4255\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.4145 - val_loss: 0.4344\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.4129 - val_loss: 0.4123\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.4109 - val_loss: 0.4095\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 815us/step - loss: 0.4091 - val_loss: 0.4139\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.4078 - val_loss: 0.4335\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.4064 - val_loss: 0.3809\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.4050 - val_loss: 0.3878\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.4038 - val_loss: 0.4167\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.4025 - val_loss: 0.4122\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 757us/step - loss: 0.4008 - val_loss: 0.4370\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.4000 - val_loss: 0.3924\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.3989 - val_loss: 0.3816\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3983 - val_loss: 0.3845\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.3969 - val_loss: 0.3793\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3961 - val_loss: 0.4542\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.3954 - val_loss: 0.3894\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3943 - val_loss: 0.3994\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.3933 - val_loss: 0.3718\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 845us/step - loss: 0.3926 - val_loss: 0.3787\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 723us/step - loss: 0.3918 - val_loss: 0.3840\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.3905 - val_loss: 0.4272\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3905 - val_loss: 0.3622\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.3888 - val_loss: 0.4188\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 784us/step - loss: 0.3888 - val_loss: 0.4188\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.3879 - val_loss: 0.3593\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.3873 - val_loss: 0.3828\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.3861 - val_loss: 0.4262\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 814us/step - loss: 0.3857 - val_loss: 0.3573\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 736us/step - loss: 0.3853 - val_loss: 0.3727\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.3840 - val_loss: 0.4472\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 769us/step - loss: 0.3839 - val_loss: 0.3917\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 878us/step - loss: 0.3829 - val_loss: 0.4313\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 0.3827 - val_loss: 0.3936\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3818 - val_loss: 0.3918\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 805us/step - loss: 0.3807 - val_loss: 0.3612\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3807 - val_loss: 0.3569\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 811us/step - loss: 0.3797 - val_loss: 0.3793\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3795 - val_loss: 0.3528\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 862us/step - loss: 0.3788 - val_loss: 0.4662\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 788us/step - loss: 0.3791 - val_loss: 0.3522\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.3783 - val_loss: 0.3870\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3774 - val_loss: 0.3688\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.3771 - val_loss: 0.3679\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.3766 - val_loss: 0.3963\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.3762 - val_loss: 0.3910\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.3753 - val_loss: 0.4492\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 775us/step - loss: 0.3754 - val_loss: 0.3879\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.3748 - val_loss: 0.3509\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 792us/step - loss: 0.3746 - val_loss: 0.3994\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.3741 - val_loss: 0.3474\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.3735 - val_loss: 0.3726\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3728 - val_loss: 0.3483\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3721 - val_loss: 0.4941\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.3731 - val_loss: 0.3498\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.3724\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.3713 - val_loss: 0.4290\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 737us/step - loss: 0.3715 - val_loss: 0.3467\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.3706 - val_loss: 0.4054\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 872us/step - loss: 0.3706 - val_loss: 0.3449\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 795us/step - loss: 0.3707 - val_loss: 0.3576\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.3694 - val_loss: 0.5002\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3704 - val_loss: 0.3567\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.3688 - val_loss: 0.3633\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3686 - val_loss: 0.3453\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.3684 - val_loss: 0.3532\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.3673 - val_loss: 0.4849\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.3688 - val_loss: 0.3535\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.3677 - val_loss: 0.5466\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.3693 - val_loss: 0.3468\n",
      "121/121 [==============================] - 0s 521us/step - loss: 0.3671\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3889 - val_loss: 1.0135\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.8385 - val_loss: 0.6986\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6701 - val_loss: 0.6078\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.6176 - val_loss: 0.5710\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.5807 - val_loss: 0.5323\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.5522 - val_loss: 0.5239\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.5261 - val_loss: 0.4821\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.5038 - val_loss: 0.5005\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.4844 - val_loss: 0.4658\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.4682 - val_loss: 0.4451\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.4546 - val_loss: 0.4665\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.4427 - val_loss: 0.4229\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4327 - val_loss: 0.4242\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.4238 - val_loss: 0.4812\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.4173 - val_loss: 0.4209\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.4103 - val_loss: 0.4622\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4051 - val_loss: 0.3911\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.3998 - val_loss: 0.4386\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.3953 - val_loss: 0.4194\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3908 - val_loss: 0.4734\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.3875 - val_loss: 0.4522\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3838 - val_loss: 0.4378\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3808 - val_loss: 0.3910\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.3776 - val_loss: 0.3965\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 856us/step - loss: 0.3747 - val_loss: 0.3995\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.3721 - val_loss: 0.4052\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.3694 - val_loss: 0.4858\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.3678 - val_loss: 0.4145\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.3653 - val_loss: 0.4876\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 0.3522\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.3613 - val_loss: 0.3800\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.3600 - val_loss: 0.3978\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.3581 - val_loss: 0.3648\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.3566 - val_loss: 0.3842\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.3550 - val_loss: 0.3655\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.3536 - val_loss: 0.4800\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.3532 - val_loss: 0.3764\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.3511 - val_loss: 0.4067\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.3497 - val_loss: 0.3633\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.3484 - val_loss: 0.4652\n",
      "121/121 [==============================] - 0s 535us/step - loss: 0.3800\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4926 - val_loss: 14.6381\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 831us/step - loss: 0.9087 - val_loss: 3.8103\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6558 - val_loss: 0.8353\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.5752 - val_loss: 0.5374\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.5362 - val_loss: 0.7617\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.5095 - val_loss: 1.0450\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4888 - val_loss: 1.2301\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4732 - val_loss: 1.5074\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.4600 - val_loss: 1.5039\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.4489 - val_loss: 1.3887\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4393 - val_loss: 1.3470\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.4309 - val_loss: 1.2513\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.4226 - val_loss: 0.9676\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.4173 - val_loss: 0.9038\n",
      "121/121 [==============================] - 0s 551us/step - loss: 0.5512\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5663 - val_loss: 1.5726\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.8072 - val_loss: 0.7342\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7008 - val_loss: 0.6632\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.6544 - val_loss: 0.6181\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.6174 - val_loss: 0.5953\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.5864 - val_loss: 0.5529\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.5596 - val_loss: 0.5311\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5359 - val_loss: 0.5088\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.5142 - val_loss: 0.5009\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.4959 - val_loss: 0.4681\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.4789 - val_loss: 0.4637\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.4645 - val_loss: 0.4469\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4517 - val_loss: 0.4374\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.4307\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.4310 - val_loss: 0.4267\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.4233 - val_loss: 0.4281\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.4157 - val_loss: 0.4159\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4102 - val_loss: 0.4131\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.4045 - val_loss: 0.4097\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 874us/step - loss: 0.4001 - val_loss: 0.4222\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 958us/step - loss: 0.3958 - val_loss: 0.4192\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.3924 - val_loss: 0.4060\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.4341\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.3864 - val_loss: 0.4197\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 867us/step - loss: 0.3834 - val_loss: 0.4328\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.3810 - val_loss: 0.4003\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.3786 - val_loss: 0.4230\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.3767 - val_loss: 0.3922\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.3748 - val_loss: 0.3857\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.3728 - val_loss: 0.3870\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3709 - val_loss: 0.4315\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 887us/step - loss: 0.3694 - val_loss: 0.4306\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.3683 - val_loss: 0.3978\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 883us/step - loss: 0.3665 - val_loss: 0.3858\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.3915\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.3641 - val_loss: 0.3824\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3627 - val_loss: 0.3771\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.3614 - val_loss: 0.4166\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.3606 - val_loss: 0.4222\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 912us/step - loss: 0.3597 - val_loss: 0.4136\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3585 - val_loss: 0.4104\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.3577 - val_loss: 0.3864\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3566 - val_loss: 0.3823\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.3552 - val_loss: 0.3615\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3549 - val_loss: 0.3992\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 895us/step - loss: 0.3538 - val_loss: 0.4113\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.4190\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3521 - val_loss: 0.4209\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.3514 - val_loss: 0.3857\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3506 - val_loss: 0.3997\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.3496 - val_loss: 0.4111\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.3491 - val_loss: 0.3692\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 0.3480 - val_loss: 0.4008\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 842us/step - loss: 0.3475 - val_loss: 0.3710\n",
      "121/121 [==============================] - 0s 584us/step - loss: 0.3512\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fd490221550>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a5de9283a47e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrand_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# we clone again after setting params in case some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[1;32m    762\u001b[0m                 **self.best_params_))\n\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[1;32m     97\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                (estimator, name))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fd490221550>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "rand_search_cv.fit(x_train, y_train, epochs = 100, validation_data = (x_valid, y_valid), callbacks = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0053800236651201615, 'n_layers': 3, 'n_units': 18}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3387649754683177"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
