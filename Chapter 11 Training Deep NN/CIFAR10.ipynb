{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a NN and training it using the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, x_train = x_train_full[:5000], x_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = keras.activations.relu, kernel_initializer = keras.initializers.he_normal()))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we need to find an optimal learning rate. To do this we will use a Nadam optimizer and train the model for 10 epochs with different learning rates.\n",
    "- We will be setting up a tensorboard environment using a tensorboard callback and check the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'optimal_lr_model', 'lr = {}'.format(learning_rate))\n",
    "tb_callback = keras.callbacks.TensorBoard(run_logdir)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('CIFAR10_model.h5', save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(learning_rate = learning_rate), metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/1407 [..............................] - ETA: 0s - loss: 165.7273 - accuracy: 0.0625WARNING:tensorflow:From /home/gokul/.local/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1407 [..............................] - ETA: 1:03 - loss: 129.1794 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0227s vs `on_train_batch_end` time: 0.0674s). Check your callbacks.\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.7819 - accuracy: 0.1722 - val_loss: 2.0820 - val_accuracy: 0.2038\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.9937 - accuracy: 0.2514 - val_loss: 2.1159 - val_accuracy: 0.2318\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.9164 - accuracy: 0.2812 - val_loss: 1.9130 - val_accuracy: 0.2824\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.8650 - accuracy: 0.3061 - val_loss: 1.8742 - val_accuracy: 0.3116\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8361 - accuracy: 0.3218 - val_loss: 1.9204 - val_accuracy: 0.2920\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7965 - accuracy: 0.3409 - val_loss: 1.8150 - val_accuracy: 0.3338\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7458 - accuracy: 0.3650 - val_loss: 1.7359 - val_accuracy: 0.3738\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7039 - accuracy: 0.3815 - val_loss: 1.6928 - val_accuracy: 0.3882\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.6794 - accuracy: 0.3924 - val_loss: 1.6576 - val_accuracy: 0.4050\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.6503 - accuracy: 0.4036 - val_loss: 1.6520 - val_accuracy: 0.4004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4b90612250>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 10, validation_data = (x_valid, y_valid), callbacks = [tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From multiple trial and error values for learning rate, it was found that the model performed the best at a learning rate of 0.00025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = keras.activations.relu, kernel_initializer = keras.initializers.he_normal()))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lr = 0.00025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(learning_rate = optimal_lr), metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('CIFAR10_model', save_best_only=True, save_weights_only = True)\n",
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'optimal_lr_model')\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1407 [..............................] - ETA: 2:46 - loss: 129.1794 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.2298s). Check your callbacks.\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.7819 - accuracy: 0.1722 - val_loss: 2.0820 - val_accuracy: 0.2038\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.9937 - accuracy: 0.2514 - val_loss: 2.1159 - val_accuracy: 0.2318\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.9164 - accuracy: 0.2812 - val_loss: 1.9130 - val_accuracy: 0.2824\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.8650 - accuracy: 0.3061 - val_loss: 1.8742 - val_accuracy: 0.3116\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.8361 - accuracy: 0.3218 - val_loss: 1.9204 - val_accuracy: 0.2920\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.7965 - accuracy: 0.3409 - val_loss: 1.8150 - val_accuracy: 0.3338\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.7458 - accuracy: 0.3650 - val_loss: 1.7359 - val_accuracy: 0.3738\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7039 - accuracy: 0.3815 - val_loss: 1.6928 - val_accuracy: 0.3882\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6794 - accuracy: 0.3924 - val_loss: 1.6576 - val_accuracy: 0.4050\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6503 - accuracy: 0.4036 - val_loss: 1.6520 - val_accuracy: 0.4004\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.6255 - accuracy: 0.4115 - val_loss: 1.6933 - val_accuracy: 0.3872\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.6121 - accuracy: 0.4191 - val_loss: 1.6392 - val_accuracy: 0.4160\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5878 - accuracy: 0.4299 - val_loss: 1.6281 - val_accuracy: 0.4120\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5719 - accuracy: 0.4362 - val_loss: 1.5983 - val_accuracy: 0.4252\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5594 - accuracy: 0.4389 - val_loss: 1.5984 - val_accuracy: 0.4212\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5420 - accuracy: 0.4448 - val_loss: 1.6114 - val_accuracy: 0.4276\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5275 - accuracy: 0.4523 - val_loss: 1.6050 - val_accuracy: 0.4242\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.5154 - accuracy: 0.4550 - val_loss: 1.5782 - val_accuracy: 0.4350\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.5056 - accuracy: 0.4588 - val_loss: 1.6181 - val_accuracy: 0.4234\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4939 - accuracy: 0.4629 - val_loss: 1.5991 - val_accuracy: 0.4358\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4822 - accuracy: 0.4701 - val_loss: 1.5511 - val_accuracy: 0.4512\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4749 - accuracy: 0.4714 - val_loss: 1.5564 - val_accuracy: 0.4450\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4591 - accuracy: 0.4788 - val_loss: 1.5605 - val_accuracy: 0.4428\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4525 - accuracy: 0.4805 - val_loss: 1.5362 - val_accuracy: 0.4546\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4420 - accuracy: 0.4823 - val_loss: 1.5810 - val_accuracy: 0.4422\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4386 - accuracy: 0.4849 - val_loss: 1.5680 - val_accuracy: 0.4388\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4274 - accuracy: 0.4871 - val_loss: 1.5378 - val_accuracy: 0.4570\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4211 - accuracy: 0.4888 - val_loss: 1.5360 - val_accuracy: 0.4530\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4097 - accuracy: 0.4954 - val_loss: 1.5543 - val_accuracy: 0.4536\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4060 - accuracy: 0.4972 - val_loss: 1.5355 - val_accuracy: 0.4644\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3957 - accuracy: 0.4988 - val_loss: 1.5489 - val_accuracy: 0.4530\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3849 - accuracy: 0.5055 - val_loss: 1.5574 - val_accuracy: 0.4596\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3828 - accuracy: 0.5036 - val_loss: 1.5846 - val_accuracy: 0.4484\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3707 - accuracy: 0.5095 - val_loss: 1.5558 - val_accuracy: 0.4634\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3609 - accuracy: 0.5108 - val_loss: 1.5805 - val_accuracy: 0.4476\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3571 - accuracy: 0.5157 - val_loss: 1.5809 - val_accuracy: 0.4542\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3471 - accuracy: 0.5163 - val_loss: 1.5970 - val_accuracy: 0.4514\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3367 - accuracy: 0.5228 - val_loss: 1.5556 - val_accuracy: 0.4662\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3314 - accuracy: 0.5247 - val_loss: 1.5809 - val_accuracy: 0.4452\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3198 - accuracy: 0.5281 - val_loss: 1.5258 - val_accuracy: 0.4720\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3164 - accuracy: 0.5303 - val_loss: 1.5828 - val_accuracy: 0.4620\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3079 - accuracy: 0.5340 - val_loss: 1.5581 - val_accuracy: 0.4528\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3023 - accuracy: 0.5316 - val_loss: 1.5584 - val_accuracy: 0.4596\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2967 - accuracy: 0.5346 - val_loss: 1.5677 - val_accuracy: 0.4580\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2894 - accuracy: 0.5360 - val_loss: 1.5443 - val_accuracy: 0.4726\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2842 - accuracy: 0.5389 - val_loss: 1.5458 - val_accuracy: 0.4612\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2735 - accuracy: 0.5455 - val_loss: 1.5767 - val_accuracy: 0.4582\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2651 - accuracy: 0.5465 - val_loss: 1.5355 - val_accuracy: 0.4732\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2556 - accuracy: 0.5521 - val_loss: 1.5536 - val_accuracy: 0.4640\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2556 - accuracy: 0.5488 - val_loss: 1.5992 - val_accuracy: 0.4658\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2410 - accuracy: 0.5552 - val_loss: 1.6099 - val_accuracy: 0.4656\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2386 - accuracy: 0.5579 - val_loss: 1.5442 - val_accuracy: 0.4644\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2362 - accuracy: 0.5585 - val_loss: 1.5767 - val_accuracy: 0.4710\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2257 - accuracy: 0.5603 - val_loss: 1.6144 - val_accuracy: 0.4570\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2226 - accuracy: 0.5596 - val_loss: 1.5958 - val_accuracy: 0.4748\n",
      "Epoch 56/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2129 - accuracy: 0.5658 - val_loss: 1.5730 - val_accuracy: 0.4708\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2076 - accuracy: 0.5651 - val_loss: 1.5680 - val_accuracy: 0.4716\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.2068 - accuracy: 0.5685 - val_loss: 1.5710 - val_accuracy: 0.4674\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1984 - accuracy: 0.5688 - val_loss: 1.6206 - val_accuracy: 0.4676\n",
      "Epoch 60/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.1861 - accuracy: 0.5761 - val_loss: 1.5790 - val_accuracy: 0.4686\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 100, validation_data = (x_valid, y_valid), callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5790 - accuracy: 0.4686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5790321826934814, 0.46860000491142273]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5602 - accuracy: 0.4689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5602147579193115, 0.46889999508857727]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4b604919d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('CIFAR10_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5258 - accuracy: 0.4720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5257840156555176, 0.47200000286102295]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5075 - accuracy: 0.4742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5074900388717651, 0.4742000102996826]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that the model with the least validation_loss gives us am accuracy of 47% on the validation and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will be adding the batvh normalization layers in the net and check its performance variations.\n",
    "- Again as we changed the model architecture, we need to find the optimal learning rate by trial and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer = keras.initializers.he_normal()))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('elu'))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 520,498\n",
      "Trainable params: 510,354\n",
      "Non-trainable params: 10,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(lr = learning_rate), metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'BN', 'lr = {}'.format(learning_rate))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   2/1407 [..............................] - ETA: 7:51 - loss: 2.9251 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0200s vs `on_train_batch_end` time: 0.6498s). Check your callbacks.\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.8626 - accuracy: 0.3325 - val_loss: 1.6442 - val_accuracy: 0.4080\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.6722 - accuracy: 0.4036 - val_loss: 1.5677 - val_accuracy: 0.4384\n",
      "Epoch 3/10\n",
      " 663/1407 [=============>................] - ETA: 7s - loss: 1.6170 - accuracy: 0.4260"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-b9aaad086d63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensorboard_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 20, validation_data = (x_valid, y_valid), callbacks = [tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
