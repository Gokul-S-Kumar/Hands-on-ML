{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a NN and training it using the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_notification():\n",
    "    return Javascript(\"new Notification('Cell Execution has finished')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "new Notification('Cell Execution has finished')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_notification()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, x_train = x_train_full[:5000], x_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = keras.activations.relu, kernel_initializer = keras.initializers.he_normal()))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we need to find an optimal learning rate. To do this we will use a Nadam optimizer and train the model for 10 epochs with different learning rates.\n",
    "- We will be setting up a tensorboard environment using a tensorboard callback and check the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'optimal_lr_model', 'lr = {}'.format(learning_rate))\n",
    "tb_callback = keras.callbacks.TensorBoard(run_logdir)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('CIFAR10_model.h5', save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(learning_rate = learning_rate), metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/1407 [..............................] - ETA: 0s - loss: 165.7273 - accuracy: 0.0625WARNING:tensorflow:From /home/gokul/.local/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1407 [..............................] - ETA: 1:02 - loss: 129.1794 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0241s vs `on_train_batch_end` time: 0.0637s). Check your callbacks.\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.7819 - accuracy: 0.1722 - val_loss: 2.0820 - val_accuracy: 0.2038\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.9937 - accuracy: 0.2514 - val_loss: 2.1159 - val_accuracy: 0.2318\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.9164 - accuracy: 0.2812 - val_loss: 1.9130 - val_accuracy: 0.2824\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.8650 - accuracy: 0.3061 - val_loss: 1.8742 - val_accuracy: 0.3116\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.8361 - accuracy: 0.3218 - val_loss: 1.9204 - val_accuracy: 0.2920\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7965 - accuracy: 0.3409 - val_loss: 1.8150 - val_accuracy: 0.3338\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7458 - accuracy: 0.3650 - val_loss: 1.7359 - val_accuracy: 0.3738\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7039 - accuracy: 0.3815 - val_loss: 1.6928 - val_accuracy: 0.3882\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6794 - accuracy: 0.3924 - val_loss: 1.6576 - val_accuracy: 0.4050\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.6503 - accuracy: 0.4036 - val_loss: 1.6520 - val_accuracy: 0.4004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd0205f71f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 10, validation_data = (x_valid, y_valid), callbacks = [tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From multiple trial and error values for learning rate, it was found that the model performed the best at a learning rate of 0.00025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = keras.activations.relu, kernel_initializer = keras.initializers.he_normal()))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lr = 0.00025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(learning_rate = optimal_lr), metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('CIFAR10_model', save_best_only=True, save_weights_only = True)\n",
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'optimal_lr_model')\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1407 [..............................] - ETA: 3:01 - loss: 129.1794 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0084s vs `on_train_batch_end` time: 0.2490s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 2.7819 - accuracy: 0.1722 - val_loss: 2.0820 - val_accuracy: 0.2038\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9937 - accuracy: 0.2514 - val_loss: 2.1159 - val_accuracy: 0.2318\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9164 - accuracy: 0.2812 - val_loss: 1.9130 - val_accuracy: 0.2824\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.8650 - accuracy: 0.3061 - val_loss: 1.8742 - val_accuracy: 0.3116\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8361 - accuracy: 0.3218 - val_loss: 1.9204 - val_accuracy: 0.2920\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7965 - accuracy: 0.3409 - val_loss: 1.8150 - val_accuracy: 0.3338\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7458 - accuracy: 0.3650 - val_loss: 1.7359 - val_accuracy: 0.3738\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7039 - accuracy: 0.3815 - val_loss: 1.6928 - val_accuracy: 0.3882\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6794 - accuracy: 0.3924 - val_loss: 1.6576 - val_accuracy: 0.4050\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6503 - accuracy: 0.4036 - val_loss: 1.6520 - val_accuracy: 0.4004\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6255 - accuracy: 0.4115 - val_loss: 1.6933 - val_accuracy: 0.3872\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6121 - accuracy: 0.4191 - val_loss: 1.6392 - val_accuracy: 0.4160\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5878 - accuracy: 0.4299 - val_loss: 1.6281 - val_accuracy: 0.4120\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5719 - accuracy: 0.4362 - val_loss: 1.5983 - val_accuracy: 0.4252\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5594 - accuracy: 0.4389 - val_loss: 1.5984 - val_accuracy: 0.4212\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5420 - accuracy: 0.4448 - val_loss: 1.6114 - val_accuracy: 0.4276\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5275 - accuracy: 0.4523 - val_loss: 1.6050 - val_accuracy: 0.4242\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5154 - accuracy: 0.4550 - val_loss: 1.5782 - val_accuracy: 0.4350\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5056 - accuracy: 0.4588 - val_loss: 1.6181 - val_accuracy: 0.4234\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4939 - accuracy: 0.4629 - val_loss: 1.5991 - val_accuracy: 0.4358\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4822 - accuracy: 0.4701 - val_loss: 1.5511 - val_accuracy: 0.4512\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4749 - accuracy: 0.4714 - val_loss: 1.5564 - val_accuracy: 0.4450\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4591 - accuracy: 0.4788 - val_loss: 1.5605 - val_accuracy: 0.4428\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4525 - accuracy: 0.4805 - val_loss: 1.5362 - val_accuracy: 0.4546\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4420 - accuracy: 0.4823 - val_loss: 1.5810 - val_accuracy: 0.4422\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4386 - accuracy: 0.4849 - val_loss: 1.5680 - val_accuracy: 0.4388\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4274 - accuracy: 0.4871 - val_loss: 1.5378 - val_accuracy: 0.4570\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4211 - accuracy: 0.4888 - val_loss: 1.5360 - val_accuracy: 0.4530\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4097 - accuracy: 0.4954 - val_loss: 1.5543 - val_accuracy: 0.4536\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4060 - accuracy: 0.4972 - val_loss: 1.5355 - val_accuracy: 0.4644\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3957 - accuracy: 0.4988 - val_loss: 1.5489 - val_accuracy: 0.4530\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3849 - accuracy: 0.5055 - val_loss: 1.5574 - val_accuracy: 0.4596\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3828 - accuracy: 0.5036 - val_loss: 1.5846 - val_accuracy: 0.4484\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3707 - accuracy: 0.5095 - val_loss: 1.5558 - val_accuracy: 0.4634\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3609 - accuracy: 0.5108 - val_loss: 1.5805 - val_accuracy: 0.4476\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3571 - accuracy: 0.5157 - val_loss: 1.5809 - val_accuracy: 0.4542\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3471 - accuracy: 0.5163 - val_loss: 1.5970 - val_accuracy: 0.4514\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3367 - accuracy: 0.5228 - val_loss: 1.5556 - val_accuracy: 0.4662\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3314 - accuracy: 0.5247 - val_loss: 1.5809 - val_accuracy: 0.4452\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3198 - accuracy: 0.5281 - val_loss: 1.5258 - val_accuracy: 0.4720\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3164 - accuracy: 0.5303 - val_loss: 1.5828 - val_accuracy: 0.4620\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3079 - accuracy: 0.5340 - val_loss: 1.5581 - val_accuracy: 0.4528\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3023 - accuracy: 0.5316 - val_loss: 1.5584 - val_accuracy: 0.4596\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2967 - accuracy: 0.5346 - val_loss: 1.5677 - val_accuracy: 0.4580\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2894 - accuracy: 0.5360 - val_loss: 1.5443 - val_accuracy: 0.4726\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2842 - accuracy: 0.5389 - val_loss: 1.5458 - val_accuracy: 0.4612\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2735 - accuracy: 0.5455 - val_loss: 1.5767 - val_accuracy: 0.4582\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2651 - accuracy: 0.5465 - val_loss: 1.5355 - val_accuracy: 0.4732\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2556 - accuracy: 0.5521 - val_loss: 1.5536 - val_accuracy: 0.4640\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2556 - accuracy: 0.5488 - val_loss: 1.5992 - val_accuracy: 0.4658\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2410 - accuracy: 0.5552 - val_loss: 1.6099 - val_accuracy: 0.4656\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2386 - accuracy: 0.5579 - val_loss: 1.5442 - val_accuracy: 0.4644\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2362 - accuracy: 0.5585 - val_loss: 1.5767 - val_accuracy: 0.4710\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2257 - accuracy: 0.5603 - val_loss: 1.6144 - val_accuracy: 0.4570\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2226 - accuracy: 0.5596 - val_loss: 1.5958 - val_accuracy: 0.4748\n",
      "Epoch 56/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2129 - accuracy: 0.5658 - val_loss: 1.5730 - val_accuracy: 0.4708\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2076 - accuracy: 0.5651 - val_loss: 1.5680 - val_accuracy: 0.4716\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2068 - accuracy: 0.5685 - val_loss: 1.5710 - val_accuracy: 0.4674\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.1984 - accuracy: 0.5688 - val_loss: 1.6206 - val_accuracy: 0.4676\n",
      "Epoch 60/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1861 - accuracy: 0.5761 - val_loss: 1.5790 - val_accuracy: 0.4686\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 100, validation_data = (x_valid, y_valid), callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5790 - accuracy: 0.4686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5790321826934814, 0.46860000491142273]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5602 - accuracy: 0.4689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5602147579193115, 0.46889999508857727]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd0206aae50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('CIFAR10_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5258 - accuracy: 0.4720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5257840156555176, 0.47200000286102295]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5075 - accuracy: 0.4742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5074900388717651, 0.4742000102996826]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that the model with the least validation_loss gives us am accuracy of 47% on the validation and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will be adding the batvh normalization layers in the net and check its performance variations.\n",
    "- Again as we changed the model architecture, we need to find the optimal learning rate by trial and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer = keras.initializers.he_normal()))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('elu'))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 520,498\n",
      "Trainable params: 510,354\n",
      "Non-trainable params: 10,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(lr = learning_rate), metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'BN', 'lr = {}'.format(learning_rate))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 7:03 - loss: 2.9106 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0179s vs `on_train_batch_end` time: 0.5836s). Check your callbacks.\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.8514 - accuracy: 0.3351 - val_loss: 1.7488 - val_accuracy: 0.3762\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.7044 - accuracy: 0.3926 - val_loss: 1.6794 - val_accuracy: 0.3950\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.6400 - accuracy: 0.4171 - val_loss: 1.6474 - val_accuracy: 0.4116\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.5878 - accuracy: 0.4350 - val_loss: 1.6109 - val_accuracy: 0.4320\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5416 - accuracy: 0.4529 - val_loss: 1.5223 - val_accuracy: 0.4540\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5039 - accuracy: 0.4670 - val_loss: 1.4697 - val_accuracy: 0.4698\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4666 - accuracy: 0.4794 - val_loss: 1.4893 - val_accuracy: 0.4736\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4346 - accuracy: 0.4920 - val_loss: 1.4309 - val_accuracy: 0.4852\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4133 - accuracy: 0.5032 - val_loss: 1.4155 - val_accuracy: 0.4990\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3865 - accuracy: 0.5094 - val_loss: 1.3645 - val_accuracy: 0.5188\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3616 - accuracy: 0.5222 - val_loss: 1.3474 - val_accuracy: 0.5280\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3380 - accuracy: 0.5302 - val_loss: 1.3894 - val_accuracy: 0.5094\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3187 - accuracy: 0.5348 - val_loss: 1.4025 - val_accuracy: 0.5072\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2980 - accuracy: 0.5441 - val_loss: 1.3652 - val_accuracy: 0.5234\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2749 - accuracy: 0.5521 - val_loss: 1.3748 - val_accuracy: 0.5222\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2628 - accuracy: 0.5581 - val_loss: 1.3527 - val_accuracy: 0.5256\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2399 - accuracy: 0.5637 - val_loss: 1.3515 - val_accuracy: 0.5306\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2238 - accuracy: 0.5709 - val_loss: 1.3480 - val_accuracy: 0.5214\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2071 - accuracy: 0.5767 - val_loss: 1.3954 - val_accuracy: 0.5088\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1952 - accuracy: 0.5837 - val_loss: 1.3511 - val_accuracy: 0.5364\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 20, validation_data = (x_valid, y_valid), callbacks = [tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After using different learning rates, it was found that the model having lr = 0.001 gives the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer = keras.initializers.he_normal()))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('elu'))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 520,498\n",
      "Trainable params: 510,354\n",
      "Non-trainable params: 10,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(learning_rate = optimal_lr), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('CIFAR10_BN_model', save_best_only = True, save_weights_only = True)\n",
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'BN', 'optimal_lr_model', 'lr = {}'.format(optimal_lr))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1407 [..............................] - ETA: 7:29 - loss: 2.9545 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0180s vs `on_train_batch_end` time: 0.6210s). Check your callbacks.\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.8374 - accuracy: 0.3410 - val_loss: 1.6944 - val_accuracy: 0.4008\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.6859 - accuracy: 0.3998 - val_loss: 1.6820 - val_accuracy: 0.3850\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.6192 - accuracy: 0.4231 - val_loss: 1.6028 - val_accuracy: 0.4250\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.5717 - accuracy: 0.4369 - val_loss: 1.5617 - val_accuracy: 0.4480\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5286 - accuracy: 0.4608 - val_loss: 1.4750 - val_accuracy: 0.4708\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4899 - accuracy: 0.4730 - val_loss: 1.4929 - val_accuracy: 0.4742\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.4539 - accuracy: 0.4841 - val_loss: 1.4742 - val_accuracy: 0.4694\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.4262 - accuracy: 0.4974 - val_loss: 1.4236 - val_accuracy: 0.4880\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3987 - accuracy: 0.5075 - val_loss: 1.4360 - val_accuracy: 0.4966\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.3739 - accuracy: 0.5157 - val_loss: 1.3685 - val_accuracy: 0.5222\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3558 - accuracy: 0.5216 - val_loss: 1.3487 - val_accuracy: 0.5174\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3275 - accuracy: 0.5332 - val_loss: 1.3995 - val_accuracy: 0.5044\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3099 - accuracy: 0.5385 - val_loss: 1.3863 - val_accuracy: 0.5120\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2898 - accuracy: 0.5475 - val_loss: 1.3638 - val_accuracy: 0.5280\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2677 - accuracy: 0.5532 - val_loss: 1.3788 - val_accuracy: 0.5132\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2558 - accuracy: 0.5580 - val_loss: 1.3443 - val_accuracy: 0.5376\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2358 - accuracy: 0.5645 - val_loss: 1.3359 - val_accuracy: 0.5348\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2192 - accuracy: 0.5705 - val_loss: 1.3512 - val_accuracy: 0.5396\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2059 - accuracy: 0.5767 - val_loss: 1.3877 - val_accuracy: 0.5216\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1962 - accuracy: 0.5808 - val_loss: 1.3433 - val_accuracy: 0.5428\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1752 - accuracy: 0.5890 - val_loss: 1.3990 - val_accuracy: 0.5252\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1626 - accuracy: 0.5927 - val_loss: 1.3276 - val_accuracy: 0.5452\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1493 - accuracy: 0.5974 - val_loss: 1.3185 - val_accuracy: 0.5530\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1351 - accuracy: 0.6028 - val_loss: 1.3257 - val_accuracy: 0.5398\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1271 - accuracy: 0.6064 - val_loss: 1.3468 - val_accuracy: 0.5466\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1080 - accuracy: 0.6114 - val_loss: 1.3523 - val_accuracy: 0.5468\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0962 - accuracy: 0.6155 - val_loss: 1.3475 - val_accuracy: 0.5366\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0872 - accuracy: 0.6216 - val_loss: 1.3529 - val_accuracy: 0.5334\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0813 - accuracy: 0.6214 - val_loss: 1.3307 - val_accuracy: 0.5452\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0621 - accuracy: 0.6288 - val_loss: 1.3573 - val_accuracy: 0.5394\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0546 - accuracy: 0.6296 - val_loss: 1.3592 - val_accuracy: 0.5492\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0455 - accuracy: 0.6343 - val_loss: 1.3805 - val_accuracy: 0.5376\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0292 - accuracy: 0.6395 - val_loss: 1.3270 - val_accuracy: 0.5594\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0210 - accuracy: 0.6437 - val_loss: 1.3622 - val_accuracy: 0.5488\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0111 - accuracy: 0.6480 - val_loss: 1.3527 - val_accuracy: 0.5430\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0039 - accuracy: 0.6487 - val_loss: 1.3727 - val_accuracy: 0.5484\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9844 - accuracy: 0.6548 - val_loss: 1.3452 - val_accuracy: 0.5492\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9847 - accuracy: 0.6560 - val_loss: 1.3862 - val_accuracy: 0.5428\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 0.9688 - accuracy: 0.6601 - val_loss: 1.3631 - val_accuracy: 0.5486\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9593 - accuracy: 0.6663 - val_loss: 1.3795 - val_accuracy: 0.5422\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9536 - accuracy: 0.6669 - val_loss: 1.3716 - val_accuracy: 0.5468\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9407 - accuracy: 0.6702 - val_loss: 1.3822 - val_accuracy: 0.5448\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 0.9391 - accuracy: 0.6716 - val_loss: 1.3898 - val_accuracy: 0.5472\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 100, validation_data = (x_valid, y_valid), callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.3898 - accuracy: 0.5472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.389768123626709, 0.5472000241279602]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3966 - accuracy: 0.5371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3966196775436401, 0.5371000170707703]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fcf9c37adc0>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('CIFAR10_BN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.3185 - accuracy: 0.5530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3185102939605713, 0.5529999732971191]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3248 - accuracy: 0.5398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3248482942581177, 0.5397999882698059]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that the model reached the lowest val_loss at 23 epochs when we added BN to the net.\n",
    "- Adding BN enabled us to use much larger lr which reduced the total training time.\n",
    "- The metrics of the model are also better with the validation and test accuracies being 55% and 53% respectively.\n",
    "- The only drawback is that the time taken to complete each epoch increased from 10s to 16s, but on overall the total training time is decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing BN with SELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We need to standardize the inputs in order to use the SELU activation func."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean(axis = 0, keepdims = True)\n",
    "x_std = x_train.std(axis = 0, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = (x_train - x_mean) / x_std\n",
    "x_valid_scaled = (x_valid - x_mean) / x_std\n",
    "x_test_scaled = (x_test - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = keras.activations.selu, kernel_initializer = keras.initializers.lecun_normal()))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(learning_rate), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'SELU', 'lr = {}'.format(learning_rate))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 2:58 - loss: 3.0571 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0076s vs `on_train_batch_end` time: 0.2454s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.9313 - accuracy: 0.3097 - val_loss: 1.8588 - val_accuracy: 0.3136\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7200 - accuracy: 0.3890 - val_loss: 1.7384 - val_accuracy: 0.3778\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6249 - accuracy: 0.4275 - val_loss: 1.7290 - val_accuracy: 0.3988\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5634 - accuracy: 0.4478 - val_loss: 1.6357 - val_accuracy: 0.4336\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5074 - accuracy: 0.4691 - val_loss: 1.5887 - val_accuracy: 0.4392\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4673 - accuracy: 0.4866 - val_loss: 1.5583 - val_accuracy: 0.4644\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4314 - accuracy: 0.5005 - val_loss: 1.5709 - val_accuracy: 0.4644\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3879 - accuracy: 0.5141 - val_loss: 1.4943 - val_accuracy: 0.4806\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3576 - accuracy: 0.5269 - val_loss: 1.5016 - val_accuracy: 0.4694\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3339 - accuracy: 0.5359 - val_loss: 1.4981 - val_accuracy: 0.4746\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3002 - accuracy: 0.5456 - val_loss: 1.5640 - val_accuracy: 0.4858\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2770 - accuracy: 0.5528 - val_loss: 1.5093 - val_accuracy: 0.4644\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2502 - accuracy: 0.5652 - val_loss: 1.4966 - val_accuracy: 0.4900\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2315 - accuracy: 0.5741 - val_loss: 1.4913 - val_accuracy: 0.4980\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2029 - accuracy: 0.5847 - val_loss: 1.5040 - val_accuracy: 0.4962\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1782 - accuracy: 0.5922 - val_loss: 1.5320 - val_accuracy: 0.4922\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1667 - accuracy: 0.5947 - val_loss: 1.5049 - val_accuracy: 0.4924\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1353 - accuracy: 0.6066 - val_loss: 1.4970 - val_accuracy: 0.5082\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1198 - accuracy: 0.6111 - val_loss: 1.4975 - val_accuracy: 0.5058\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1503 - accuracy: 0.6090 - val_loss: 1.5465 - val_accuracy: 0.4896\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 20, validation_data = (x_valid_scaled, y_valid), callbacks = [tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After changing the architecture we could find that the model performs at its best at lr = 0.0004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = keras.activations.selu, kernel_initializer = keras.initializers.lecun_normal()))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lr = 0.0004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(optimal_lr), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('CIFAR10_SELU_model', save_best_only = True, save_weights_only = True)\n",
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'SELU', 'optimal_model', 'lr = {}'.format(optimal_lr))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1407 [..............................] - ETA: 2:20 - loss: 2.9763 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0069s vs `on_train_batch_end` time: 0.1924s). Check your callbacks.\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.8783 - accuracy: 0.3294 - val_loss: 1.7889 - val_accuracy: 0.3518\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6694 - accuracy: 0.4085 - val_loss: 1.7444 - val_accuracy: 0.3730\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5651 - accuracy: 0.4500 - val_loss: 1.5895 - val_accuracy: 0.4310\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4906 - accuracy: 0.4757 - val_loss: 1.5508 - val_accuracy: 0.4604\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4261 - accuracy: 0.4994 - val_loss: 1.5326 - val_accuracy: 0.4566\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3760 - accuracy: 0.5150 - val_loss: 1.4838 - val_accuracy: 0.4800\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3262 - accuracy: 0.5373 - val_loss: 1.4950 - val_accuracy: 0.4838\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2808 - accuracy: 0.5492 - val_loss: 1.4441 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2378 - accuracy: 0.5706 - val_loss: 1.4800 - val_accuracy: 0.4890\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2034 - accuracy: 0.5829 - val_loss: 1.4828 - val_accuracy: 0.4990\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1686 - accuracy: 0.5956 - val_loss: 1.4911 - val_accuracy: 0.5016\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1321 - accuracy: 0.6078 - val_loss: 1.4539 - val_accuracy: 0.5060\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.1041 - accuracy: 0.6196 - val_loss: 1.4871 - val_accuracy: 0.5054\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0754 - accuracy: 0.6319 - val_loss: 1.4716 - val_accuracy: 0.5104\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0390 - accuracy: 0.6407 - val_loss: 1.4800 - val_accuracy: 0.5136\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0146 - accuracy: 0.6528 - val_loss: 1.5277 - val_accuracy: 0.5210\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9892 - accuracy: 0.6593 - val_loss: 1.5216 - val_accuracy: 0.5124\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9640 - accuracy: 0.6736 - val_loss: 1.5493 - val_accuracy: 0.5202\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9382 - accuracy: 0.6769 - val_loss: 1.5601 - val_accuracy: 0.5192\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9178 - accuracy: 0.6874 - val_loss: 1.5716 - val_accuracy: 0.5178\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8949 - accuracy: 0.6958 - val_loss: 1.6265 - val_accuracy: 0.5190\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8722 - accuracy: 0.7011 - val_loss: 1.6008 - val_accuracy: 0.5132\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8502 - accuracy: 0.7090 - val_loss: 1.6837 - val_accuracy: 0.4986\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8390 - accuracy: 0.7138 - val_loss: 1.5859 - val_accuracy: 0.5146\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8158 - accuracy: 0.7239 - val_loss: 1.6536 - val_accuracy: 0.5072\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8006 - accuracy: 0.7312 - val_loss: 1.6247 - val_accuracy: 0.5058\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.7830 - accuracy: 0.7374 - val_loss: 1.6342 - val_accuracy: 0.5168\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.7634 - accuracy: 0.7443 - val_loss: 1.6528 - val_accuracy: 0.5068\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 100, validation_data = (x_valid_scaled, y_valid), callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.6528 - accuracy: 0.5068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.652758240699768, 0.5067999958992004]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6576 - accuracy: 0.5017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.657639980316162, 0.5016999840736389]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd0744f53a0>"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('CIFAR10_SELU_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4441 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4440743923187256, 0.5]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4459 - accuracy: 0.4979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.445914626121521, 0.49790000915527344]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is the fastest model by far as the best model in terms of val_error was achieved in 8 epochs with 10s for each epoch.\n",
    "- But the drawback is the model performance which even though is better than the raw model is less than that of the model with BN layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
