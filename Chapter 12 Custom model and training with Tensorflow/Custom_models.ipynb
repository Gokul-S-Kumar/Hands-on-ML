{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating custom NN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ipynb.fs.full.Useful_funcs import data_pipeline, pre_model, create_huber # Custom funcs for data processing, modelling, compiling and training\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import selu, relu, elu\n",
    "from tensorflow.keras.initializers import lecun_normal, he_normal\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.losses import mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_train_scaled, x_valid, x_valid_scaled, x_test, x_test_scaled, y_train, y_valid, y_test = data_pipeline(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Residual Block layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will be creating the Residual Block which will be used multiple times in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_block(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, units, **kwargs):\n",
    "        super().__init__(**kwargs) # Initializing base class kwargs\n",
    "        self.hidden = [keras.layers.Dense(units, activation = elu, kernel_initializer = he_normal()) for _ in range(n_layers)]\n",
    "        # Creating the block of Dense layers\n",
    "    def call(self, x):\n",
    "        z = x\n",
    "        for layer in self.hidden:\n",
    "            z = layer(z) # Passing the inputs through the block of layers\n",
    "        return z + x # Adding the output with the layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above layer contains other layers. Keras automatically detects that the hidden attribute contains trackable objects, so their variables are automatically added to this layer's list of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now using the residual block we will be creating the custom model. We will be using the Subclassing API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_regressor(keras.models.Model):\n",
    "    def __init__(self, output_dims, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = Dense(30, activation = elu, kernel_initializer = he_normal()) # The initial Dense layer\n",
    "        self.block1 = Residual_block(2, 30) # The first residual-block\n",
    "        self.block2 = Residual_block(2, 30) # The second residual-block\n",
    "        self.out = Dense(output_dims) # The output layer\n",
    "    def call(self, inputs): # The training method\n",
    "        z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3): # Passing the data 3 times through the residual block \n",
    "            z = self.block1(z)\n",
    "        z = self.block2(z)\n",
    "        return self.out(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model()\n",
    "model = Residual_regressor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = mse, optimizer = Nadam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 9.1325\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 997us/step - loss: 1.0578\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8867\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 913us/step - loss: 0.5834\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.6456\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 646us/step - loss: 0.6500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6499764323234558"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Custom_models/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('Custom_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('Custom_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8016\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4849\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5577\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4681\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f01aead65e0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_scaled, y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can use the Sequential API to define the same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train_scaled.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation = elu, kernel_initializer = he_normal, input_shape = input_shape))\n",
    "for _ in range(4):\n",
    "    model.add(Residual_block(2, 30))\n",
    "model.add(Residual_block(2, 30))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "residual_block (Residual_blo (None, 30)                1860      \n",
      "_________________________________________________________________\n",
      "residual_block_1 (Residual_b (None, 30)                1860      \n",
      "_________________________________________________________________\n",
      "residual_block_2 (Residual_b (None, 30)                1860      \n",
      "_________________________________________________________________\n",
      "residual_block_3 (Residual_b (None, 30)                1860      \n",
      "_________________________________________________________________\n",
      "residual_block_4 (Residual_b (None, 30)                1860      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 9,601\n",
      "Trainable params: 9,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = mse, optimizer = Nadam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 5.3201 - val_loss: 88.8999\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.7475 - val_loss: 49.7316\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.1192 - val_loss: 19.1865\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8249 - val_loss: 197.0558\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.1027 - val_loss: 1382.3093\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 5, validation_data = (x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 683us/step - loss: 8.0084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.00838565826416"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses and metrics based on model internals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will be building a model having 5 hidden dense layers and an output layer. This model will also have an auxilliary output on top of the upper hidden layer.\n",
    "- The loss associated to this auxilliary output will be called the reconstruction loss, it is the mse between the reconstruction and the inputs.\n",
    "- By adding this reconstruction loss we will encourage the model to preserve as much information as possible through the hidden layers, even information that is not directly used for the regression task.\n",
    "- In practice this loss sometimes improves generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reconstructing_regressor(keras.models.Model):\n",
    "    def __init__(self, output_dims, **kwargs):\n",
    "        super().__init__(**kwargs) # Initializing kwargs\n",
    "        self.hidden = [Dense(30, activation = selu, kernel_initializer = lecun_normal()) for _ in range(5)] # Hidden layers\n",
    "        self.out = Dense(output_dims) # Output layer\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = Dense(n_inputs) # Reconstruction layer\n",
    "    def call(self, inputs, training = None):\n",
    "        z = inputs\n",
    "        for layer in self.hidden:\n",
    "            z = layer(z)\n",
    "        reconstruction = self.reconstruct(z) # Reconstruction output\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs)) # Calculating reconstruction loss \n",
    "        self.add_loss(0.05 * recon_loss) # Scaling down reconstruction loss\n",
    "        return self.out(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The reconstruction layer must be created in the build() method since its no. of units must be equal to the no. of inputs and this no. is unknown before the build method is called.\n",
    "- The call() method is used to find the reconstruction loss and add it to the list of lossed using the add_loss() method. We scale down the reconstruction loss by multiplying it with 0.05(this is a hyperparameter we can tune). This ensures that the reconstruction loss doesnt dominate the main loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Reconstructing_regressor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = mse, optimizer = Nadam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(x_train.shape) # While using subclassing API, we need to call the build method as a standalone method instead of building the model using real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.7885\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.4126\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 945us/step - loss: 0.3850\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.3650\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.3544\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 5) # TODO: Follow up on tensorflow issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_scaled, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
