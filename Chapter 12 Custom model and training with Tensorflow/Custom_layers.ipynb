{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating custom layers to use in NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ipynb.fs.full.Useful_funcs import data_pipeline, pre_model, create_huber # Custom funcs for data processing, modelling, compiling and training\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import selu, relu\n",
    "from tensorflow.keras.initializers import lecun_normal\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.losses import mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_train_scaled, x_valid, x_valid_scaled, x_test, x_test_scaled, y_train, y_valid, y_test = data_pipeline(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a custom layer without weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x : tf.exp(x)) \n",
    "# Creating a custom exponential layer where the units output the exponential value of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding an exponential layer to the output of a regression model can be useful is the output to be predicted is positive and of different scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation = relu, input_shape = input_shape))\n",
    "model.add(Dense(1))\n",
    "model.add(exponential_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = mse, optimizer = Nadam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 926us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 966us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 954us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 922us/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 5, validation_data = (x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 881us/step - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a custom layer with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_dense(keras.layers.Layer): \n",
    "    def __init__(self, units, activation = None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(name = 'kernel', shape = [batch_input_shape[-1], self.units], initializer = keras.initializers.glorot_normal)\n",
    "        # Forming the weight matrix and initializing it\n",
    "        self.bias = self.add_weight(name = 'bias', shape = [self.units], initializer = keras.initializers.zeros) # Forming the bias matrix\n",
    "        super().build(batch_input_shape) # To tell keras that the layer is built i.e., to set self.built = True\n",
    "    def call(self, x):\n",
    "        return self.activation(x @ self.kernel + self.bias) # Calculating the output of the layer\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config() # Getting the configs from the base class\n",
    "        return {**base_config, 'units' : self.units, 'activation' : keras.activations.get(self.activation)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can omit the compute_output_shape() method generally as tf.keras automatically infers the output shape except when the layer is dynamic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Custom_dense(30, activation = keras.activations.relu, input_shape = input_shape))\n",
    "model.add(Custom_dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "custom_dense (Custom_dense)  (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "custom_dense_1 (Custom_dense (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = mse, optimizer = Nadam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.2563 - val_loss: 0.9472\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.6485 - val_loss: 0.6219\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 955us/step - loss: 0.5051 - val_loss: 0.5421\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.4440 - val_loss: 0.3945\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 967us/step - loss: 0.4168 - val_loss: 0.3775\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 5, validation_data = (x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 647us/step - loss: 0.3981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3980771005153656"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Custom_dense_layer_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('Custom_dense_layer_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('Custom_dense_layer_model', custom_objects = {'Custom_dense' : Custom_dense})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi input and output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For a layer having multiple inputs, the argument to the call method sholud be a tuple containing the all the inputs and the argument to compute_call_method should be a tuple containing each input's batch shape.\n",
    "- To create a layer with multiple outputs, the call method should return the list of outputs and the compute_output_shape should return the list of batch output shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_layer(keras.layers.Layer):\n",
    "    def call(self, x):\n",
    "        x1, x2 = x\n",
    "        return x1 + x2, x1 * x2\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return batch_input_shape1, batch_input_shape2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1 = keras.layers.Input(shape = [2])\n",
    "inputs2 = keras.layers.Input(shape = [2])\n",
    "outputs1, outputs2 = Multi_layer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"multi_layer/add:0\", shape=(None, 2), dtype=float32) Tensor(\"multi_layer/mul:0\", shape=(None, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(outputs1, outputs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating layers with different behaviour during training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add_gaussian_noise(keras.layers.Layer):\n",
    "    def __init__(self, stdev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stdev = stdev\n",
    "    def call(self, x, training = None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(x), stddev = self.stdev)\n",
    "            return x + noise\n",
    "        else :\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
