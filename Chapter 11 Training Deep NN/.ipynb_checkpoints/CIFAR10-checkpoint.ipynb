{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a NN and training it using the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, x_train = x_train_full[:5000], x_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = keras.activations.relu, kernel_initializer = keras.initializers.he_normal()))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we need to find an optimal learning rate. To do this we will use a Nadam optimizer and train the model for 10 epochs with different learning rates.\n",
    "- We will be setting up a tensorboard environment using a tensorboard callback and check the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'optimal_lr_model', 'lr = {}'.format(learning_rate))\n",
    "tb_callback = keras.callbacks.TensorBoard(run_logdir)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('CIFAR10_model.h5', save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(learning_rate = learning_rate), metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/1407 [..............................] - ETA: 0s - loss: 165.7273 - accuracy: 0.0625WARNING:tensorflow:From /home/gokul/.local/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1407 [..............................] - ETA: 1:02 - loss: 129.1794 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0241s vs `on_train_batch_end` time: 0.0637s). Check your callbacks.\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.7819 - accuracy: 0.1722 - val_loss: 2.0820 - val_accuracy: 0.2038\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.9937 - accuracy: 0.2514 - val_loss: 2.1159 - val_accuracy: 0.2318\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.9164 - accuracy: 0.2812 - val_loss: 1.9130 - val_accuracy: 0.2824\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.8650 - accuracy: 0.3061 - val_loss: 1.8742 - val_accuracy: 0.3116\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.8361 - accuracy: 0.3218 - val_loss: 1.9204 - val_accuracy: 0.2920\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7965 - accuracy: 0.3409 - val_loss: 1.8150 - val_accuracy: 0.3338\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7458 - accuracy: 0.3650 - val_loss: 1.7359 - val_accuracy: 0.3738\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7039 - accuracy: 0.3815 - val_loss: 1.6928 - val_accuracy: 0.3882\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6794 - accuracy: 0.3924 - val_loss: 1.6576 - val_accuracy: 0.4050\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.6503 - accuracy: 0.4036 - val_loss: 1.6520 - val_accuracy: 0.4004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd0205f71f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 10, validation_data = (x_valid, y_valid), callbacks = [tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From multiple trial and error values for learning rate, it was found that the model performed the best at a learning rate of 0.00025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = keras.activations.relu, kernel_initializer = keras.initializers.he_normal()))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lr = 0.00025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(learning_rate = optimal_lr), metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('CIFAR10_model', save_best_only=True, save_weights_only = True)\n",
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'optimal_lr_model')\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1407 [..............................] - ETA: 3:01 - loss: 129.1794 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0084s vs `on_train_batch_end` time: 0.2490s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 2.7819 - accuracy: 0.1722 - val_loss: 2.0820 - val_accuracy: 0.2038\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9937 - accuracy: 0.2514 - val_loss: 2.1159 - val_accuracy: 0.2318\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9164 - accuracy: 0.2812 - val_loss: 1.9130 - val_accuracy: 0.2824\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.8650 - accuracy: 0.3061 - val_loss: 1.8742 - val_accuracy: 0.3116\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8361 - accuracy: 0.3218 - val_loss: 1.9204 - val_accuracy: 0.2920\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7965 - accuracy: 0.3409 - val_loss: 1.8150 - val_accuracy: 0.3338\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7458 - accuracy: 0.3650 - val_loss: 1.7359 - val_accuracy: 0.3738\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7039 - accuracy: 0.3815 - val_loss: 1.6928 - val_accuracy: 0.3882\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6794 - accuracy: 0.3924 - val_loss: 1.6576 - val_accuracy: 0.4050\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6503 - accuracy: 0.4036 - val_loss: 1.6520 - val_accuracy: 0.4004\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6255 - accuracy: 0.4115 - val_loss: 1.6933 - val_accuracy: 0.3872\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6121 - accuracy: 0.4191 - val_loss: 1.6392 - val_accuracy: 0.4160\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5878 - accuracy: 0.4299 - val_loss: 1.6281 - val_accuracy: 0.4120\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5719 - accuracy: 0.4362 - val_loss: 1.5983 - val_accuracy: 0.4252\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5594 - accuracy: 0.4389 - val_loss: 1.5984 - val_accuracy: 0.4212\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5420 - accuracy: 0.4448 - val_loss: 1.6114 - val_accuracy: 0.4276\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5275 - accuracy: 0.4523 - val_loss: 1.6050 - val_accuracy: 0.4242\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5154 - accuracy: 0.4550 - val_loss: 1.5782 - val_accuracy: 0.4350\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5056 - accuracy: 0.4588 - val_loss: 1.6181 - val_accuracy: 0.4234\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4939 - accuracy: 0.4629 - val_loss: 1.5991 - val_accuracy: 0.4358\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4822 - accuracy: 0.4701 - val_loss: 1.5511 - val_accuracy: 0.4512\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4749 - accuracy: 0.4714 - val_loss: 1.5564 - val_accuracy: 0.4450\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4591 - accuracy: 0.4788 - val_loss: 1.5605 - val_accuracy: 0.4428\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4525 - accuracy: 0.4805 - val_loss: 1.5362 - val_accuracy: 0.4546\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4420 - accuracy: 0.4823 - val_loss: 1.5810 - val_accuracy: 0.4422\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4386 - accuracy: 0.4849 - val_loss: 1.5680 - val_accuracy: 0.4388\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4274 - accuracy: 0.4871 - val_loss: 1.5378 - val_accuracy: 0.4570\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4211 - accuracy: 0.4888 - val_loss: 1.5360 - val_accuracy: 0.4530\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4097 - accuracy: 0.4954 - val_loss: 1.5543 - val_accuracy: 0.4536\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4060 - accuracy: 0.4972 - val_loss: 1.5355 - val_accuracy: 0.4644\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3957 - accuracy: 0.4988 - val_loss: 1.5489 - val_accuracy: 0.4530\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3849 - accuracy: 0.5055 - val_loss: 1.5574 - val_accuracy: 0.4596\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3828 - accuracy: 0.5036 - val_loss: 1.5846 - val_accuracy: 0.4484\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3707 - accuracy: 0.5095 - val_loss: 1.5558 - val_accuracy: 0.4634\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3609 - accuracy: 0.5108 - val_loss: 1.5805 - val_accuracy: 0.4476\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3571 - accuracy: 0.5157 - val_loss: 1.5809 - val_accuracy: 0.4542\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3471 - accuracy: 0.5163 - val_loss: 1.5970 - val_accuracy: 0.4514\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3367 - accuracy: 0.5228 - val_loss: 1.5556 - val_accuracy: 0.4662\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3314 - accuracy: 0.5247 - val_loss: 1.5809 - val_accuracy: 0.4452\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3198 - accuracy: 0.5281 - val_loss: 1.5258 - val_accuracy: 0.4720\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3164 - accuracy: 0.5303 - val_loss: 1.5828 - val_accuracy: 0.4620\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3079 - accuracy: 0.5340 - val_loss: 1.5581 - val_accuracy: 0.4528\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3023 - accuracy: 0.5316 - val_loss: 1.5584 - val_accuracy: 0.4596\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2967 - accuracy: 0.5346 - val_loss: 1.5677 - val_accuracy: 0.4580\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2894 - accuracy: 0.5360 - val_loss: 1.5443 - val_accuracy: 0.4726\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2842 - accuracy: 0.5389 - val_loss: 1.5458 - val_accuracy: 0.4612\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2735 - accuracy: 0.5455 - val_loss: 1.5767 - val_accuracy: 0.4582\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2651 - accuracy: 0.5465 - val_loss: 1.5355 - val_accuracy: 0.4732\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2556 - accuracy: 0.5521 - val_loss: 1.5536 - val_accuracy: 0.4640\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2556 - accuracy: 0.5488 - val_loss: 1.5992 - val_accuracy: 0.4658\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2410 - accuracy: 0.5552 - val_loss: 1.6099 - val_accuracy: 0.4656\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2386 - accuracy: 0.5579 - val_loss: 1.5442 - val_accuracy: 0.4644\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2362 - accuracy: 0.5585 - val_loss: 1.5767 - val_accuracy: 0.4710\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2257 - accuracy: 0.5603 - val_loss: 1.6144 - val_accuracy: 0.4570\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2226 - accuracy: 0.5596 - val_loss: 1.5958 - val_accuracy: 0.4748\n",
      "Epoch 56/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2129 - accuracy: 0.5658 - val_loss: 1.5730 - val_accuracy: 0.4708\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2076 - accuracy: 0.5651 - val_loss: 1.5680 - val_accuracy: 0.4716\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2068 - accuracy: 0.5685 - val_loss: 1.5710 - val_accuracy: 0.4674\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.1984 - accuracy: 0.5688 - val_loss: 1.6206 - val_accuracy: 0.4676\n",
      "Epoch 60/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1861 - accuracy: 0.5761 - val_loss: 1.5790 - val_accuracy: 0.4686\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 100, validation_data = (x_valid, y_valid), callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5790 - accuracy: 0.4686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5790321826934814, 0.46860000491142273]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5602 - accuracy: 0.4689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5602147579193115, 0.46889999508857727]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd0206aae50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('CIFAR10_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5258 - accuracy: 0.4720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5257840156555176, 0.47200000286102295]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5075 - accuracy: 0.4742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5074900388717651, 0.4742000102996826]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that the model with the least validation_loss gives us am accuracy of 47% on the validation and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will be adding the batvh normalization layers in the net and check its performance variations.\n",
    "- Again as we changed the model architecture, we need to find the optimal learning rate by trial and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer = keras.initializers.he_normal()))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('elu'))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 520,498\n",
      "Trainable params: 510,354\n",
      "Non-trainable params: 10,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(lr = learning_rate), metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'BN', 'lr = {}'.format(learning_rate))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 7:03 - loss: 2.9106 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0179s vs `on_train_batch_end` time: 0.5836s). Check your callbacks.\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.8514 - accuracy: 0.3351 - val_loss: 1.7488 - val_accuracy: 0.3762\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.7044 - accuracy: 0.3926 - val_loss: 1.6794 - val_accuracy: 0.3950\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.6400 - accuracy: 0.4171 - val_loss: 1.6474 - val_accuracy: 0.4116\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.5878 - accuracy: 0.4350 - val_loss: 1.6109 - val_accuracy: 0.4320\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5416 - accuracy: 0.4529 - val_loss: 1.5223 - val_accuracy: 0.4540\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5039 - accuracy: 0.4670 - val_loss: 1.4697 - val_accuracy: 0.4698\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4666 - accuracy: 0.4794 - val_loss: 1.4893 - val_accuracy: 0.4736\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4346 - accuracy: 0.4920 - val_loss: 1.4309 - val_accuracy: 0.4852\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4133 - accuracy: 0.5032 - val_loss: 1.4155 - val_accuracy: 0.4990\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3865 - accuracy: 0.5094 - val_loss: 1.3645 - val_accuracy: 0.5188\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3616 - accuracy: 0.5222 - val_loss: 1.3474 - val_accuracy: 0.5280\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3380 - accuracy: 0.5302 - val_loss: 1.3894 - val_accuracy: 0.5094\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3187 - accuracy: 0.5348 - val_loss: 1.4025 - val_accuracy: 0.5072\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2980 - accuracy: 0.5441 - val_loss: 1.3652 - val_accuracy: 0.5234\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2749 - accuracy: 0.5521 - val_loss: 1.3748 - val_accuracy: 0.5222\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2628 - accuracy: 0.5581 - val_loss: 1.3527 - val_accuracy: 0.5256\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2399 - accuracy: 0.5637 - val_loss: 1.3515 - val_accuracy: 0.5306\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2238 - accuracy: 0.5709 - val_loss: 1.3480 - val_accuracy: 0.5214\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2071 - accuracy: 0.5767 - val_loss: 1.3954 - val_accuracy: 0.5088\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1952 - accuracy: 0.5837 - val_loss: 1.3511 - val_accuracy: 0.5364\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 20, validation_data = (x_valid, y_valid), callbacks = [tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After using different learning rates, it was found that the model having lr = 0.001 gives the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer = keras.initializers.he_normal()))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('elu'))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 520,498\n",
      "Trainable params: 510,354\n",
      "Non-trainable params: 10,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(learning_rate = optimal_lr), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('CIFAR10_BN_model', save_best_only = True, save_weights_only = True)\n",
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'BN', 'optimal_lr_model', 'lr = {}'.format(optimal_lr))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1407 [..............................] - ETA: 7:29 - loss: 2.9545 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0180s vs `on_train_batch_end` time: 0.6210s). Check your callbacks.\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.8374 - accuracy: 0.3410 - val_loss: 1.6944 - val_accuracy: 0.4008\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.6859 - accuracy: 0.3998 - val_loss: 1.6820 - val_accuracy: 0.3850\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.6192 - accuracy: 0.4231 - val_loss: 1.6028 - val_accuracy: 0.4250\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.5717 - accuracy: 0.4369 - val_loss: 1.5617 - val_accuracy: 0.4480\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5286 - accuracy: 0.4608 - val_loss: 1.4750 - val_accuracy: 0.4708\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4899 - accuracy: 0.4730 - val_loss: 1.4929 - val_accuracy: 0.4742\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.4539 - accuracy: 0.4841 - val_loss: 1.4742 - val_accuracy: 0.4694\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.4262 - accuracy: 0.4974 - val_loss: 1.4236 - val_accuracy: 0.4880\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3987 - accuracy: 0.5075 - val_loss: 1.4360 - val_accuracy: 0.4966\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.3739 - accuracy: 0.5157 - val_loss: 1.3685 - val_accuracy: 0.5222\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3558 - accuracy: 0.5216 - val_loss: 1.3487 - val_accuracy: 0.5174\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3275 - accuracy: 0.5332 - val_loss: 1.3995 - val_accuracy: 0.5044\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3099 - accuracy: 0.5385 - val_loss: 1.3863 - val_accuracy: 0.5120\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2898 - accuracy: 0.5475 - val_loss: 1.3638 - val_accuracy: 0.5280\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2677 - accuracy: 0.5532 - val_loss: 1.3788 - val_accuracy: 0.5132\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2558 - accuracy: 0.5580 - val_loss: 1.3443 - val_accuracy: 0.5376\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2358 - accuracy: 0.5645 - val_loss: 1.3359 - val_accuracy: 0.5348\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2192 - accuracy: 0.5705 - val_loss: 1.3512 - val_accuracy: 0.5396\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2059 - accuracy: 0.5767 - val_loss: 1.3877 - val_accuracy: 0.5216\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1962 - accuracy: 0.5808 - val_loss: 1.3433 - val_accuracy: 0.5428\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1752 - accuracy: 0.5890 - val_loss: 1.3990 - val_accuracy: 0.5252\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1626 - accuracy: 0.5927 - val_loss: 1.3276 - val_accuracy: 0.5452\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1493 - accuracy: 0.5974 - val_loss: 1.3185 - val_accuracy: 0.5530\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1351 - accuracy: 0.6028 - val_loss: 1.3257 - val_accuracy: 0.5398\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1271 - accuracy: 0.6064 - val_loss: 1.3468 - val_accuracy: 0.5466\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1080 - accuracy: 0.6114 - val_loss: 1.3523 - val_accuracy: 0.5468\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0962 - accuracy: 0.6155 - val_loss: 1.3475 - val_accuracy: 0.5366\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0872 - accuracy: 0.6216 - val_loss: 1.3529 - val_accuracy: 0.5334\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0813 - accuracy: 0.6214 - val_loss: 1.3307 - val_accuracy: 0.5452\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0621 - accuracy: 0.6288 - val_loss: 1.3573 - val_accuracy: 0.5394\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0546 - accuracy: 0.6296 - val_loss: 1.3592 - val_accuracy: 0.5492\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0455 - accuracy: 0.6343 - val_loss: 1.3805 - val_accuracy: 0.5376\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0292 - accuracy: 0.6395 - val_loss: 1.3270 - val_accuracy: 0.5594\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0210 - accuracy: 0.6437 - val_loss: 1.3622 - val_accuracy: 0.5488\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0111 - accuracy: 0.6480 - val_loss: 1.3527 - val_accuracy: 0.5430\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0039 - accuracy: 0.6487 - val_loss: 1.3727 - val_accuracy: 0.5484\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9844 - accuracy: 0.6548 - val_loss: 1.3452 - val_accuracy: 0.5492\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9847 - accuracy: 0.6560 - val_loss: 1.3862 - val_accuracy: 0.5428\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 0.9688 - accuracy: 0.6601 - val_loss: 1.3631 - val_accuracy: 0.5486\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9593 - accuracy: 0.6663 - val_loss: 1.3795 - val_accuracy: 0.5422\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9536 - accuracy: 0.6669 - val_loss: 1.3716 - val_accuracy: 0.5468\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9407 - accuracy: 0.6702 - val_loss: 1.3822 - val_accuracy: 0.5448\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 0.9391 - accuracy: 0.6716 - val_loss: 1.3898 - val_accuracy: 0.5472\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 100, validation_data = (x_valid, y_valid), callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.3898 - accuracy: 0.5472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.389768123626709, 0.5472000241279602]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3966 - accuracy: 0.5371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3966196775436401, 0.5371000170707703]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fcf9c37adc0>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('CIFAR10_BN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.3185 - accuracy: 0.5530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3185102939605713, 0.5529999732971191]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3248 - accuracy: 0.5398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3248482942581177, 0.5397999882698059]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that the model reached the lowest val_loss at 23 epochs when we added BN to the net.\n",
    "- Adding BN enabled us to use much larger lr which reduced the total training time.\n",
    "- The metrics of the model are also better with the validation and test accuracies being 55% and 53% respectively.\n",
    "- The only drawback is that the time taken to complete each epoch increased from 10s to 16s, but on overall the total training time is decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing BN with SELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We need to standardize the inputs in order to use the SELU activation func."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean(axis = 0, keepdims = True)\n",
    "x_std = x_train.std(axis = 0, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = (x_train - x_mean) / x_std\n",
    "x_valid_scaled = (x_valid - x_mean) / x_std\n",
    "x_test_scaled = (x_test - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = keras.activations.selu, kernel_initializer = keras.initializers.lecun_normal()))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(learning_rate), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'SELU', 'lr = {}'.format(learning_rate))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 2:58 - loss: 3.0571 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0076s vs `on_train_batch_end` time: 0.2454s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.9313 - accuracy: 0.3097 - val_loss: 1.8588 - val_accuracy: 0.3136\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7200 - accuracy: 0.3890 - val_loss: 1.7384 - val_accuracy: 0.3778\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6249 - accuracy: 0.4275 - val_loss: 1.7290 - val_accuracy: 0.3988\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5634 - accuracy: 0.4478 - val_loss: 1.6357 - val_accuracy: 0.4336\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5074 - accuracy: 0.4691 - val_loss: 1.5887 - val_accuracy: 0.4392\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4673 - accuracy: 0.4866 - val_loss: 1.5583 - val_accuracy: 0.4644\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4314 - accuracy: 0.5005 - val_loss: 1.5709 - val_accuracy: 0.4644\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3879 - accuracy: 0.5141 - val_loss: 1.4943 - val_accuracy: 0.4806\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3576 - accuracy: 0.5269 - val_loss: 1.5016 - val_accuracy: 0.4694\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3339 - accuracy: 0.5359 - val_loss: 1.4981 - val_accuracy: 0.4746\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3002 - accuracy: 0.5456 - val_loss: 1.5640 - val_accuracy: 0.4858\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2770 - accuracy: 0.5528 - val_loss: 1.5093 - val_accuracy: 0.4644\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2502 - accuracy: 0.5652 - val_loss: 1.4966 - val_accuracy: 0.4900\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2315 - accuracy: 0.5741 - val_loss: 1.4913 - val_accuracy: 0.4980\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2029 - accuracy: 0.5847 - val_loss: 1.5040 - val_accuracy: 0.4962\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1782 - accuracy: 0.5922 - val_loss: 1.5320 - val_accuracy: 0.4922\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1667 - accuracy: 0.5947 - val_loss: 1.5049 - val_accuracy: 0.4924\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1353 - accuracy: 0.6066 - val_loss: 1.4970 - val_accuracy: 0.5082\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1198 - accuracy: 0.6111 - val_loss: 1.4975 - val_accuracy: 0.5058\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1503 - accuracy: 0.6090 - val_loss: 1.5465 - val_accuracy: 0.4896\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 20, validation_data = (x_valid_scaled, y_valid), callbacks = [tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After changing the architecture we could find that the model performs at its best at lr = 0.0004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = keras.activations.selu, kernel_initializer = keras.initializers.lecun_normal()))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lr = 0.0004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(optimal_lr), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('CIFAR10_SELU_model', save_best_only = True, save_weights_only = True)\n",
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'SELU', 'optimal_model', 'lr = {}'.format(optimal_lr))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1407 [..............................] - ETA: 2:20 - loss: 2.9763 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0069s vs `on_train_batch_end` time: 0.1924s). Check your callbacks.\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.8783 - accuracy: 0.3294 - val_loss: 1.7889 - val_accuracy: 0.3518\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6694 - accuracy: 0.4085 - val_loss: 1.7444 - val_accuracy: 0.3730\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5651 - accuracy: 0.4500 - val_loss: 1.5895 - val_accuracy: 0.4310\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4906 - accuracy: 0.4757 - val_loss: 1.5508 - val_accuracy: 0.4604\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4261 - accuracy: 0.4994 - val_loss: 1.5326 - val_accuracy: 0.4566\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3760 - accuracy: 0.5150 - val_loss: 1.4838 - val_accuracy: 0.4800\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3262 - accuracy: 0.5373 - val_loss: 1.4950 - val_accuracy: 0.4838\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2808 - accuracy: 0.5492 - val_loss: 1.4441 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2378 - accuracy: 0.5706 - val_loss: 1.4800 - val_accuracy: 0.4890\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2034 - accuracy: 0.5829 - val_loss: 1.4828 - val_accuracy: 0.4990\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1686 - accuracy: 0.5956 - val_loss: 1.4911 - val_accuracy: 0.5016\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1321 - accuracy: 0.6078 - val_loss: 1.4539 - val_accuracy: 0.5060\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.1041 - accuracy: 0.6196 - val_loss: 1.4871 - val_accuracy: 0.5054\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0754 - accuracy: 0.6319 - val_loss: 1.4716 - val_accuracy: 0.5104\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0390 - accuracy: 0.6407 - val_loss: 1.4800 - val_accuracy: 0.5136\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0146 - accuracy: 0.6528 - val_loss: 1.5277 - val_accuracy: 0.5210\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9892 - accuracy: 0.6593 - val_loss: 1.5216 - val_accuracy: 0.5124\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9640 - accuracy: 0.6736 - val_loss: 1.5493 - val_accuracy: 0.5202\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9382 - accuracy: 0.6769 - val_loss: 1.5601 - val_accuracy: 0.5192\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9178 - accuracy: 0.6874 - val_loss: 1.5716 - val_accuracy: 0.5178\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8949 - accuracy: 0.6958 - val_loss: 1.6265 - val_accuracy: 0.5190\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8722 - accuracy: 0.7011 - val_loss: 1.6008 - val_accuracy: 0.5132\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8502 - accuracy: 0.7090 - val_loss: 1.6837 - val_accuracy: 0.4986\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8390 - accuracy: 0.7138 - val_loss: 1.5859 - val_accuracy: 0.5146\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8158 - accuracy: 0.7239 - val_loss: 1.6536 - val_accuracy: 0.5072\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8006 - accuracy: 0.7312 - val_loss: 1.6247 - val_accuracy: 0.5058\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.7830 - accuracy: 0.7374 - val_loss: 1.6342 - val_accuracy: 0.5168\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.7634 - accuracy: 0.7443 - val_loss: 1.6528 - val_accuracy: 0.5068\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 100, validation_data = (x_valid_scaled, y_valid), callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.6528 - accuracy: 0.5068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.652758240699768, 0.5067999958992004]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6576 - accuracy: 0.5017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.657639980316162, 0.5016999840736389]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd0744f53a0>"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('CIFAR10_SELU_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4441 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4440743923187256, 0.5]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4459 - accuracy: 0.4979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.445914626121521, 0.49790000915527344]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is the fastest model by far as the best model in terms of val_error was achieved in 8 epochs with 10s for each epoch.\n",
    "- But the drawback is the model performance which even though is better than the raw model is less than that of the model with BN layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AlphaDropouts for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = keras.activations.selu, kernel_initializer = keras.initializers.lecun_normal()))\n",
    "model.add(keras.layers.AlphaDropout(rate = 0.1))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "alpha_dropout (AlphaDropout) (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'Dropout', 'Div_3_dropout')\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/1407 [..............................] - ETA: 0s - loss: 3.0241 - accuracy: 0.0938WARNING:tensorflow:From /home/gokul/.local/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1407 [..............................] - ETA: 1:37 - loss: 3.1068 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0225s vs `on_train_batch_end` time: 0.1146s). Check your callbacks.\n",
      " 383/1407 [=======>......................] - ETA: 5s - loss: 2.1534 - accuracy: 0.2321"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 20, validation_data = (x_valid_scaled, y_valid), callbacks = [tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After training the model we could see that the model performs the best when dropout is added after the last hidden layer.\n",
    "- Now we need to decide the dropout rate as well as the learning_rate for which we will be using Randomized Search CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dropout_rate = 0.1, learning_rate = 1e-3):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "    for _ in range(20):\n",
    "        model.add(keras.layers.Dense(100, activation = keras.activations.selu, kernel_initializer = keras.initializers.lecun_normal()))\n",
    "    model.add(keras.layers.AlphaDropout(rate = dropout_rate))\n",
    "    model.add(keras.layers.Dense(10, activation = keras.activations.softmax))\n",
    "    model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(lr = learning_rate), metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = keras.wrappers.scikit_learn.KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dropout_rate' : [0.03, 0.1], 'learning_rate' : [0.0001, 0.0003]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_search = RandomizedSearchCV(estimator = classifier, param_distributions = params, n_iter = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.0797 - accuracy: 0.2344 - val_loss: 1.8949 - val_accuracy: 0.2986\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8699 - accuracy: 0.3185 - val_loss: 1.7980 - val_accuracy: 0.3504\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7942 - accuracy: 0.3502 - val_loss: 1.7778 - val_accuracy: 0.3464\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7502 - accuracy: 0.3672 - val_loss: 1.7320 - val_accuracy: 0.3730\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7119 - accuracy: 0.3814 - val_loss: 1.7495 - val_accuracy: 0.3668\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6812 - accuracy: 0.3937 - val_loss: 1.6764 - val_accuracy: 0.3908\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6541 - accuracy: 0.4060 - val_loss: 1.6416 - val_accuracy: 0.4068\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6242 - accuracy: 0.4194 - val_loss: 1.6437 - val_accuracy: 0.4092\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5989 - accuracy: 0.4277 - val_loss: 1.6002 - val_accuracy: 0.4210\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5826 - accuracy: 0.4329 - val_loss: 1.6282 - val_accuracy: 0.4062\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5610 - accuracy: 0.4412 - val_loss: 1.6696 - val_accuracy: 0.4164\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5472 - accuracy: 0.4447 - val_loss: 1.5763 - val_accuracy: 0.4416\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5253 - accuracy: 0.4558 - val_loss: 1.5989 - val_accuracy: 0.4220\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5147 - accuracy: 0.4622 - val_loss: 1.6234 - val_accuracy: 0.4256\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4952 - accuracy: 0.4657 - val_loss: 1.5967 - val_accuracy: 0.4278\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4848 - accuracy: 0.4694 - val_loss: 1.5665 - val_accuracy: 0.4418\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4747 - accuracy: 0.4732 - val_loss: 1.5974 - val_accuracy: 0.4240\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4637 - accuracy: 0.4786 - val_loss: 1.5726 - val_accuracy: 0.4424\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4473 - accuracy: 0.4823 - val_loss: 1.5735 - val_accuracy: 0.4512\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4329 - accuracy: 0.4908 - val_loss: 1.5656 - val_accuracy: 0.4550\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4225 - accuracy: 0.4931 - val_loss: 1.6451 - val_accuracy: 0.4200\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4177 - accuracy: 0.4944 - val_loss: 1.5544 - val_accuracy: 0.4530\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4069 - accuracy: 0.4965 - val_loss: 1.6110 - val_accuracy: 0.4342\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3925 - accuracy: 0.5048 - val_loss: 1.5658 - val_accuracy: 0.4472\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3845 - accuracy: 0.5077 - val_loss: 1.6030 - val_accuracy: 0.4404\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3774 - accuracy: 0.5134 - val_loss: 1.5659 - val_accuracy: 0.4576\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3618 - accuracy: 0.5154 - val_loss: 1.5555 - val_accuracy: 0.4538\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3511 - accuracy: 0.5200 - val_loss: 1.5486 - val_accuracy: 0.4642\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3450 - accuracy: 0.5207 - val_loss: 1.5645 - val_accuracy: 0.4568\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3342 - accuracy: 0.5241 - val_loss: 1.5518 - val_accuracy: 0.4678\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3240 - accuracy: 0.5274 - val_loss: 1.5777 - val_accuracy: 0.4502\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3164 - accuracy: 0.5322 - val_loss: 1.5529 - val_accuracy: 0.4562\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3096 - accuracy: 0.5329 - val_loss: 1.6097 - val_accuracy: 0.4522\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3030 - accuracy: 0.5354 - val_loss: 1.5683 - val_accuracy: 0.4570\n",
      "Epoch 35/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2928 - accuracy: 0.5387 - val_loss: 1.5551 - val_accuracy: 0.4706\n",
      "Epoch 36/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2777 - accuracy: 0.5442 - val_loss: 1.6317 - val_accuracy: 0.4468\n",
      "Epoch 37/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2700 - accuracy: 0.5452 - val_loss: 1.6250 - val_accuracy: 0.4606\n",
      "Epoch 38/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2817 - accuracy: 0.5469 - val_loss: 1.6392 - val_accuracy: 0.4584\n",
      "Epoch 39/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2516 - accuracy: 0.5541 - val_loss: 1.5829 - val_accuracy: 0.4598\n",
      "Epoch 40/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2472 - accuracy: 0.5514 - val_loss: 1.5975 - val_accuracy: 0.4550\n",
      "Epoch 41/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4629 - accuracy: 0.4767 - val_loss: 1.7118 - val_accuracy: 0.3910\n",
      "Epoch 42/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5717 - accuracy: 0.4346 - val_loss: 1.6252 - val_accuracy: 0.4218\n",
      "Epoch 43/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3816 - accuracy: 0.5091 - val_loss: 1.6192 - val_accuracy: 0.4604\n",
      "Epoch 44/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2620 - accuracy: 0.5510 - val_loss: 1.5851 - val_accuracy: 0.4606\n",
      "Epoch 45/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2434 - accuracy: 0.5561 - val_loss: 1.6252 - val_accuracy: 0.4518\n",
      "Epoch 46/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2253 - accuracy: 0.5646 - val_loss: 1.6490 - val_accuracy: 0.4482\n",
      "Epoch 47/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2179 - accuracy: 0.5657 - val_loss: 1.5946 - val_accuracy: 0.4594\n",
      "Epoch 48/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2039 - accuracy: 0.5748 - val_loss: 1.6346 - val_accuracy: 0.4510\n",
      "282/282 [==============================] - 2s 6ms/step - loss: 1.5425 - accuracy: 0.4679\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0689 - accuracy: 0.2379 - val_loss: 1.8828 - val_accuracy: 0.3016\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8756 - accuracy: 0.3051 - val_loss: 1.8590 - val_accuracy: 0.3182\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8082 - accuracy: 0.3376 - val_loss: 1.7762 - val_accuracy: 0.3504\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7605 - accuracy: 0.3592 - val_loss: 1.7264 - val_accuracy: 0.3666\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7117 - accuracy: 0.3812 - val_loss: 1.7237 - val_accuracy: 0.3790\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6749 - accuracy: 0.3931 - val_loss: 1.7549 - val_accuracy: 0.3730\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6447 - accuracy: 0.4091 - val_loss: 1.6248 - val_accuracy: 0.4250\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6100 - accuracy: 0.4202 - val_loss: 1.6212 - val_accuracy: 0.4212\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5924 - accuracy: 0.4266 - val_loss: 1.7096 - val_accuracy: 0.3860\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5718 - accuracy: 0.4340 - val_loss: 1.6055 - val_accuracy: 0.4300\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5558 - accuracy: 0.4418 - val_loss: 1.6288 - val_accuracy: 0.4254\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5536 - accuracy: 0.4415 - val_loss: 1.6342 - val_accuracy: 0.4160\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5238 - accuracy: 0.4543 - val_loss: 1.6011 - val_accuracy: 0.4312\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5091 - accuracy: 0.4565 - val_loss: 1.6138 - val_accuracy: 0.4210\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4949 - accuracy: 0.4653 - val_loss: 1.5836 - val_accuracy: 0.4352\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4812 - accuracy: 0.4683 - val_loss: 1.5736 - val_accuracy: 0.4506\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4691 - accuracy: 0.4710 - val_loss: 1.5818 - val_accuracy: 0.4340\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4575 - accuracy: 0.4799 - val_loss: 1.5723 - val_accuracy: 0.4576\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4469 - accuracy: 0.4826 - val_loss: 1.5760 - val_accuracy: 0.4532\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4327 - accuracy: 0.4871 - val_loss: 1.5690 - val_accuracy: 0.4500\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4235 - accuracy: 0.4887 - val_loss: 1.5820 - val_accuracy: 0.4424\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4108 - accuracy: 0.4937 - val_loss: 1.5750 - val_accuracy: 0.4516\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4013 - accuracy: 0.4991 - val_loss: 1.5575 - val_accuracy: 0.4570\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3923 - accuracy: 0.5022 - val_loss: 1.5541 - val_accuracy: 0.4540\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3771 - accuracy: 0.5049 - val_loss: 1.6160 - val_accuracy: 0.4442\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3687 - accuracy: 0.5096 - val_loss: 1.6303 - val_accuracy: 0.4418\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3568 - accuracy: 0.5133 - val_loss: 1.6081 - val_accuracy: 0.4460\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3480 - accuracy: 0.5185 - val_loss: 1.6047 - val_accuracy: 0.4608\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3393 - accuracy: 0.5198 - val_loss: 1.6026 - val_accuracy: 0.4556\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3303 - accuracy: 0.5240 - val_loss: 1.6581 - val_accuracy: 0.4412\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3192 - accuracy: 0.5272 - val_loss: 1.6114 - val_accuracy: 0.4524\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3082 - accuracy: 0.5299 - val_loss: 1.6037 - val_accuracy: 0.4444\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2997 - accuracy: 0.5353 - val_loss: 1.6099 - val_accuracy: 0.4554\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2899 - accuracy: 0.5400 - val_loss: 1.5810 - val_accuracy: 0.4522\n",
      "Epoch 35/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2808 - accuracy: 0.5439 - val_loss: 1.5883 - val_accuracy: 0.4554\n",
      "Epoch 36/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2789 - accuracy: 0.5446 - val_loss: 1.5788 - val_accuracy: 0.4604\n",
      "Epoch 37/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3389 - accuracy: 0.5235 - val_loss: 1.6177 - val_accuracy: 0.4514\n",
      "Epoch 38/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2571 - accuracy: 0.5523 - val_loss: 1.6069 - val_accuracy: 0.4486\n",
      "Epoch 39/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2476 - accuracy: 0.5530 - val_loss: 1.5946 - val_accuracy: 0.4606\n",
      "Epoch 40/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2446 - accuracy: 0.5547 - val_loss: 1.5611 - val_accuracy: 0.4664\n",
      "Epoch 41/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2353 - accuracy: 0.5592 - val_loss: 1.6603 - val_accuracy: 0.4384\n",
      "Epoch 42/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2284 - accuracy: 0.5624 - val_loss: 1.6450 - val_accuracy: 0.4462\n",
      "Epoch 43/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2172 - accuracy: 0.5635 - val_loss: 1.6661 - val_accuracy: 0.4578\n",
      "Epoch 44/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2069 - accuracy: 0.5693 - val_loss: 1.5949 - val_accuracy: 0.4574\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5544 - accuracy: 0.4528\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.1054 - accuracy: 0.2250 - val_loss: 1.9194 - val_accuracy: 0.2908\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8891 - accuracy: 0.3022 - val_loss: 1.9271 - val_accuracy: 0.3230\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8182 - accuracy: 0.3331 - val_loss: 1.7943 - val_accuracy: 0.3364\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7670 - accuracy: 0.3562 - val_loss: 1.7302 - val_accuracy: 0.3634\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7223 - accuracy: 0.3759 - val_loss: 1.7249 - val_accuracy: 0.3630\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6840 - accuracy: 0.3907 - val_loss: 1.7556 - val_accuracy: 0.3824\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6534 - accuracy: 0.4007 - val_loss: 1.6650 - val_accuracy: 0.3942\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6279 - accuracy: 0.4156 - val_loss: 1.6370 - val_accuracy: 0.4118\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5992 - accuracy: 0.4280 - val_loss: 1.6274 - val_accuracy: 0.4170\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5782 - accuracy: 0.4324 - val_loss: 1.6038 - val_accuracy: 0.4270\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5632 - accuracy: 0.4395 - val_loss: 1.6002 - val_accuracy: 0.4314\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5471 - accuracy: 0.4393 - val_loss: 1.5902 - val_accuracy: 0.4290\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5262 - accuracy: 0.4518 - val_loss: 1.5664 - val_accuracy: 0.4264\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5165 - accuracy: 0.4561 - val_loss: 1.5718 - val_accuracy: 0.4360\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5021 - accuracy: 0.4638 - val_loss: 1.5656 - val_accuracy: 0.4316\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4979 - accuracy: 0.4646 - val_loss: 1.5643 - val_accuracy: 0.4476\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4745 - accuracy: 0.4736 - val_loss: 1.5473 - val_accuracy: 0.4416\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4616 - accuracy: 0.4755 - val_loss: 1.5664 - val_accuracy: 0.4462\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5565 - accuracy: 0.4406 - val_loss: 1.5598 - val_accuracy: 0.4526\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4650 - accuracy: 0.4748 - val_loss: 1.5562 - val_accuracy: 0.4358\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4512 - accuracy: 0.4816 - val_loss: 1.5648 - val_accuracy: 0.4468\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4383 - accuracy: 0.4876 - val_loss: 1.5810 - val_accuracy: 0.4434\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4402 - accuracy: 0.4860 - val_loss: 1.5742 - val_accuracy: 0.4494\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4078 - accuracy: 0.4977 - val_loss: 1.5812 - val_accuracy: 0.4358\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4045 - accuracy: 0.4972 - val_loss: 1.5572 - val_accuracy: 0.4536\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3973 - accuracy: 0.4991 - val_loss: 1.5471 - val_accuracy: 0.4534\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3846 - accuracy: 0.5061 - val_loss: 1.5549 - val_accuracy: 0.4574\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3727 - accuracy: 0.5113 - val_loss: 1.5701 - val_accuracy: 0.4530\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3654 - accuracy: 0.5133 - val_loss: 1.5498 - val_accuracy: 0.4482\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3597 - accuracy: 0.5149 - val_loss: 1.5735 - val_accuracy: 0.4462\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3401 - accuracy: 0.5218 - val_loss: 1.5757 - val_accuracy: 0.4600\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3309 - accuracy: 0.5257 - val_loss: 1.5569 - val_accuracy: 0.4654\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3211 - accuracy: 0.5297 - val_loss: 1.6104 - val_accuracy: 0.4342\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3195 - accuracy: 0.5263 - val_loss: 1.5638 - val_accuracy: 0.4614\n",
      "Epoch 35/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3145 - accuracy: 0.5298 - val_loss: 1.5839 - val_accuracy: 0.4558\n",
      "Epoch 36/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3068 - accuracy: 0.5332 - val_loss: 1.6175 - val_accuracy: 0.4456\n",
      "Epoch 37/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2893 - accuracy: 0.5382 - val_loss: 1.5995 - val_accuracy: 0.4546\n",
      "Epoch 38/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2856 - accuracy: 0.5415 - val_loss: 1.5651 - val_accuracy: 0.4580\n",
      "Epoch 39/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2773 - accuracy: 0.5429 - val_loss: 1.5818 - val_accuracy: 0.4586\n",
      "Epoch 40/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2673 - accuracy: 0.5475 - val_loss: 1.6217 - val_accuracy: 0.4628\n",
      "Epoch 41/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2647 - accuracy: 0.5452 - val_loss: 1.6278 - val_accuracy: 0.4602\n",
      "Epoch 42/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2552 - accuracy: 0.5488 - val_loss: 1.6323 - val_accuracy: 0.4566\n",
      "Epoch 43/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2433 - accuracy: 0.5546 - val_loss: 1.6184 - val_accuracy: 0.4602\n",
      "Epoch 44/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2429 - accuracy: 0.5552 - val_loss: 1.6096 - val_accuracy: 0.4576\n",
      "Epoch 45/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2249 - accuracy: 0.5641 - val_loss: 1.6338 - val_accuracy: 0.4602\n",
      "Epoch 46/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2186 - accuracy: 0.5633 - val_loss: 1.5993 - val_accuracy: 0.4678\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5526 - accuracy: 0.4502\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.1000 - accuracy: 0.2264 - val_loss: 1.8731 - val_accuracy: 0.3182\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8690 - accuracy: 0.3169 - val_loss: 1.8130 - val_accuracy: 0.3502\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7972 - accuracy: 0.3469 - val_loss: 1.7787 - val_accuracy: 0.3578\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7414 - accuracy: 0.3691 - val_loss: 1.7000 - val_accuracy: 0.3816\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6953 - accuracy: 0.3861 - val_loss: 1.6657 - val_accuracy: 0.3960\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6610 - accuracy: 0.4025 - val_loss: 1.7173 - val_accuracy: 0.3936\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6295 - accuracy: 0.4164 - val_loss: 1.6463 - val_accuracy: 0.4224\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6039 - accuracy: 0.4279 - val_loss: 1.6103 - val_accuracy: 0.4302\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5788 - accuracy: 0.4351 - val_loss: 1.6319 - val_accuracy: 0.4164\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5634 - accuracy: 0.4396 - val_loss: 1.6178 - val_accuracy: 0.4294\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5442 - accuracy: 0.4461 - val_loss: 1.6306 - val_accuracy: 0.4226\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5311 - accuracy: 0.4518 - val_loss: 1.5942 - val_accuracy: 0.4376\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5165 - accuracy: 0.4572 - val_loss: 1.6019 - val_accuracy: 0.4294\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 7s 7ms/step - loss: 1.4955 - accuracy: 0.4629 - val_loss: 1.6270 - val_accuracy: 0.4170\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4855 - accuracy: 0.4695 - val_loss: 1.5749 - val_accuracy: 0.4502\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4666 - accuracy: 0.4732 - val_loss: 1.6082 - val_accuracy: 0.4290\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4576 - accuracy: 0.4773 - val_loss: 1.5547 - val_accuracy: 0.4512\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4473 - accuracy: 0.4799 - val_loss: 1.5448 - val_accuracy: 0.4586\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4338 - accuracy: 0.4875 - val_loss: 1.5573 - val_accuracy: 0.4544\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4222 - accuracy: 0.4918 - val_loss: 1.5455 - val_accuracy: 0.4532\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4123 - accuracy: 0.4966 - val_loss: 1.6139 - val_accuracy: 0.4240\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3989 - accuracy: 0.4961 - val_loss: 1.5721 - val_accuracy: 0.4598\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3845 - accuracy: 0.5042 - val_loss: 1.5934 - val_accuracy: 0.4488\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3800 - accuracy: 0.5047 - val_loss: 1.5444 - val_accuracy: 0.4546\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3629 - accuracy: 0.5099 - val_loss: 1.5328 - val_accuracy: 0.4672\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3541 - accuracy: 0.5143 - val_loss: 1.5822 - val_accuracy: 0.4588\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3398 - accuracy: 0.5204 - val_loss: 1.5823 - val_accuracy: 0.4548\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3353 - accuracy: 0.5203 - val_loss: 1.6129 - val_accuracy: 0.4494\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3199 - accuracy: 0.5255 - val_loss: 1.5972 - val_accuracy: 0.4496\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3157 - accuracy: 0.5321 - val_loss: 1.5580 - val_accuracy: 0.4610\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3035 - accuracy: 0.5329 - val_loss: 1.5973 - val_accuracy: 0.4548\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2930 - accuracy: 0.5333 - val_loss: 1.5651 - val_accuracy: 0.4610\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2820 - accuracy: 0.5414 - val_loss: 1.6102 - val_accuracy: 0.4616\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2756 - accuracy: 0.5435 - val_loss: 1.5868 - val_accuracy: 0.4516\n",
      "Epoch 35/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2687 - accuracy: 0.5472 - val_loss: 1.5769 - val_accuracy: 0.4696\n",
      "Epoch 36/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2589 - accuracy: 0.5489 - val_loss: 1.6031 - val_accuracy: 0.4644\n",
      "Epoch 37/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2484 - accuracy: 0.5510 - val_loss: 1.6276 - val_accuracy: 0.4502\n",
      "Epoch 38/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2410 - accuracy: 0.5574 - val_loss: 1.5538 - val_accuracy: 0.4684\n",
      "Epoch 39/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2294 - accuracy: 0.5598 - val_loss: 1.6219 - val_accuracy: 0.4632\n",
      "Epoch 40/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2179 - accuracy: 0.5642 - val_loss: 1.6021 - val_accuracy: 0.4712\n",
      "Epoch 41/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2140 - accuracy: 0.5647 - val_loss: 1.6187 - val_accuracy: 0.4748\n",
      "Epoch 42/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2024 - accuracy: 0.5671 - val_loss: 1.6352 - val_accuracy: 0.4698\n",
      "Epoch 43/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.1936 - accuracy: 0.5690 - val_loss: 1.6276 - val_accuracy: 0.4570\n",
      "Epoch 44/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.1864 - accuracy: 0.5736 - val_loss: 1.6295 - val_accuracy: 0.4606\n",
      "Epoch 45/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.1775 - accuracy: 0.5777 - val_loss: 1.6385 - val_accuracy: 0.4634\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5469 - accuracy: 0.4638\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0862 - accuracy: 0.2294 - val_loss: 1.8634 - val_accuracy: 0.3204\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8723 - accuracy: 0.3134 - val_loss: 1.8729 - val_accuracy: 0.3296\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7996 - accuracy: 0.3457 - val_loss: 1.8401 - val_accuracy: 0.3504\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7431 - accuracy: 0.3639 - val_loss: 1.7343 - val_accuracy: 0.3800\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7031 - accuracy: 0.3825 - val_loss: 1.6816 - val_accuracy: 0.3956\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6655 - accuracy: 0.3984 - val_loss: 1.7431 - val_accuracy: 0.3778\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6369 - accuracy: 0.4113 - val_loss: 1.6420 - val_accuracy: 0.4186\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6084 - accuracy: 0.4231 - val_loss: 1.6355 - val_accuracy: 0.4012\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.6094 - accuracy: 0.4206 - val_loss: 1.6378 - val_accuracy: 0.4124\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.5681 - accuracy: 0.4345 - val_loss: 1.6364 - val_accuracy: 0.4174\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.5492 - accuracy: 0.4459 - val_loss: 1.6559 - val_accuracy: 0.4136\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5447 - accuracy: 0.4431 - val_loss: 1.6125 - val_accuracy: 0.4076\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5245 - accuracy: 0.4518 - val_loss: 1.5994 - val_accuracy: 0.4362\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5097 - accuracy: 0.4579 - val_loss: 1.6138 - val_accuracy: 0.4366\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4906 - accuracy: 0.4666 - val_loss: 1.5877 - val_accuracy: 0.4392\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4756 - accuracy: 0.4700 - val_loss: 1.5884 - val_accuracy: 0.4336\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4647 - accuracy: 0.4766 - val_loss: 1.5886 - val_accuracy: 0.4356\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4512 - accuracy: 0.4803 - val_loss: 1.5587 - val_accuracy: 0.4528\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4417 - accuracy: 0.4875 - val_loss: 1.5590 - val_accuracy: 0.4442\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4295 - accuracy: 0.4918 - val_loss: 1.6055 - val_accuracy: 0.4462\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4144 - accuracy: 0.4962 - val_loss: 1.6716 - val_accuracy: 0.4344\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3999 - accuracy: 0.4992 - val_loss: 1.6257 - val_accuracy: 0.4332\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3917 - accuracy: 0.5057 - val_loss: 1.5527 - val_accuracy: 0.4634\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3771 - accuracy: 0.5102 - val_loss: 1.5556 - val_accuracy: 0.4524\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4221 - accuracy: 0.4899 - val_loss: 1.6635 - val_accuracy: 0.3976\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4816 - accuracy: 0.4730 - val_loss: 1.5806 - val_accuracy: 0.4396\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3838 - accuracy: 0.5073 - val_loss: 1.5867 - val_accuracy: 0.4580\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3560 - accuracy: 0.5178 - val_loss: 1.5817 - val_accuracy: 0.4556\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3376 - accuracy: 0.5272 - val_loss: 1.5519 - val_accuracy: 0.4654\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3276 - accuracy: 0.5252 - val_loss: 1.5431 - val_accuracy: 0.4688\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3177 - accuracy: 0.5311 - val_loss: 1.6241 - val_accuracy: 0.4388\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3067 - accuracy: 0.5368 - val_loss: 1.5171 - val_accuracy: 0.4856\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2963 - accuracy: 0.5393 - val_loss: 1.6010 - val_accuracy: 0.4530\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2900 - accuracy: 0.5421 - val_loss: 1.5313 - val_accuracy: 0.4628\n",
      "Epoch 35/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5974 - accuracy: 0.4307 - val_loss: 1.7424 - val_accuracy: 0.3716\n",
      "Epoch 36/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6101 - accuracy: 0.4201 - val_loss: 1.6155 - val_accuracy: 0.4298\n",
      "Epoch 37/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5228 - accuracy: 0.4567 - val_loss: 1.5856 - val_accuracy: 0.4400\n",
      "Epoch 38/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4751 - accuracy: 0.4719 - val_loss: 1.5817 - val_accuracy: 0.4432\n",
      "Epoch 39/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4335 - accuracy: 0.4874 - val_loss: 1.5898 - val_accuracy: 0.4474\n",
      "Epoch 40/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3963 - accuracy: 0.5056 - val_loss: 1.5286 - val_accuracy: 0.4632\n",
      "Epoch 41/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3560 - accuracy: 0.5168 - val_loss: 1.5781 - val_accuracy: 0.4556\n",
      "Epoch 42/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3256 - accuracy: 0.5281 - val_loss: 1.5655 - val_accuracy: 0.4584\n",
      "Epoch 43/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3031 - accuracy: 0.5340 - val_loss: 1.5514 - val_accuracy: 0.4630\n",
      "Epoch 44/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2850 - accuracy: 0.5413 - val_loss: 1.5532 - val_accuracy: 0.4766\n",
      "Epoch 45/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2663 - accuracy: 0.5493 - val_loss: 1.5863 - val_accuracy: 0.4606\n",
      "Epoch 46/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2519 - accuracy: 0.5564 - val_loss: 1.5424 - val_accuracy: 0.4766\n",
      "Epoch 47/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2480 - accuracy: 0.5584 - val_loss: 1.5715 - val_accuracy: 0.4682\n",
      "Epoch 48/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2319 - accuracy: 0.5610 - val_loss: 1.5529 - val_accuracy: 0.4716\n",
      "Epoch 49/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2145 - accuracy: 0.5678 - val_loss: 1.6265 - val_accuracy: 0.4596\n",
      "Epoch 50/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2079 - accuracy: 0.5716 - val_loss: 1.6099 - val_accuracy: 0.4678\n",
      "Epoch 51/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.1994 - accuracy: 0.5754 - val_loss: 1.5919 - val_accuracy: 0.4736\n",
      "Epoch 52/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.1858 - accuracy: 0.5812 - val_loss: 1.6027 - val_accuracy: 0.4718\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5296 - accuracy: 0.4731\n",
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 2.0692 - accuracy: 0.2361 - val_loss: 1.9108 - val_accuracy: 0.2894\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.8561 - accuracy: 0.3177 - val_loss: 1.9661 - val_accuracy: 0.3100\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7837 - accuracy: 0.3539 - val_loss: 1.7882 - val_accuracy: 0.3424\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7302 - accuracy: 0.3738 - val_loss: 1.8133 - val_accuracy: 0.3552\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6891 - accuracy: 0.3940 - val_loss: 1.7475 - val_accuracy: 0.3620\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6516 - accuracy: 0.4081 - val_loss: 1.6577 - val_accuracy: 0.4094\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6215 - accuracy: 0.4200 - val_loss: 1.6849 - val_accuracy: 0.3938\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5945 - accuracy: 0.4298 - val_loss: 1.6135 - val_accuracy: 0.4190\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5762 - accuracy: 0.4349 - val_loss: 1.6252 - val_accuracy: 0.4156\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5543 - accuracy: 0.4434 - val_loss: 1.6071 - val_accuracy: 0.4200\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5401 - accuracy: 0.4495 - val_loss: 1.6650 - val_accuracy: 0.4176\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5268 - accuracy: 0.4553 - val_loss: 1.6205 - val_accuracy: 0.4236\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5138 - accuracy: 0.4600 - val_loss: 1.5894 - val_accuracy: 0.4302\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4965 - accuracy: 0.4638 - val_loss: 1.5518 - val_accuracy: 0.4584\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4884 - accuracy: 0.4689 - val_loss: 1.6421 - val_accuracy: 0.4172\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4726 - accuracy: 0.4737 - val_loss: 1.5587 - val_accuracy: 0.4522\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4612 - accuracy: 0.4798 - val_loss: 1.5883 - val_accuracy: 0.4402\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4534 - accuracy: 0.4832 - val_loss: 1.5631 - val_accuracy: 0.4452\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4377 - accuracy: 0.4846 - val_loss: 1.5787 - val_accuracy: 0.4460\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4288 - accuracy: 0.4881 - val_loss: 1.5492 - val_accuracy: 0.4558\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4185 - accuracy: 0.4927 - val_loss: 1.5322 - val_accuracy: 0.4528\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4058 - accuracy: 0.4961 - val_loss: 1.5578 - val_accuracy: 0.4522\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3998 - accuracy: 0.4996 - val_loss: 1.5702 - val_accuracy: 0.4412\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3881 - accuracy: 0.5005 - val_loss: 1.5759 - val_accuracy: 0.4536\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3796 - accuracy: 0.5040 - val_loss: 1.5329 - val_accuracy: 0.4622\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3699 - accuracy: 0.5097 - val_loss: 1.5415 - val_accuracy: 0.4444\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3574 - accuracy: 0.5155 - val_loss: 1.5001 - val_accuracy: 0.4744\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5449 - accuracy: 0.4463 - val_loss: 1.7733 - val_accuracy: 0.3534\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.6814 - accuracy: 0.3879 - val_loss: 1.6656 - val_accuracy: 0.3984\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.6160 - accuracy: 0.4153 - val_loss: 1.6812 - val_accuracy: 0.3868\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5886 - accuracy: 0.4249 - val_loss: 1.6398 - val_accuracy: 0.4050\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5729 - accuracy: 0.4336 - val_loss: 1.6019 - val_accuracy: 0.4198\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5399 - accuracy: 0.4465 - val_loss: 1.6299 - val_accuracy: 0.4322\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4937 - accuracy: 0.4666 - val_loss: 1.5977 - val_accuracy: 0.4400\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4580 - accuracy: 0.4766 - val_loss: 1.5749 - val_accuracy: 0.4468\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4315 - accuracy: 0.4872 - val_loss: 1.5681 - val_accuracy: 0.4458\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4004 - accuracy: 0.4981 - val_loss: 1.5211 - val_accuracy: 0.4706\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3791 - accuracy: 0.5053 - val_loss: 1.5358 - val_accuracy: 0.4562\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3662 - accuracy: 0.5117 - val_loss: 1.5396 - val_accuracy: 0.4668\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3485 - accuracy: 0.5187 - val_loss: 1.5665 - val_accuracy: 0.4656\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3352 - accuracy: 0.5214 - val_loss: 1.5186 - val_accuracy: 0.4738\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3249 - accuracy: 0.5291 - val_loss: 1.5086 - val_accuracy: 0.4662\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3137 - accuracy: 0.5331 - val_loss: 1.5557 - val_accuracy: 0.4670\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3009 - accuracy: 0.5366 - val_loss: 1.5481 - val_accuracy: 0.4670\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2978 - accuracy: 0.5393 - val_loss: 1.5101 - val_accuracy: 0.4742\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2857 - accuracy: 0.5415 - val_loss: 1.5410 - val_accuracy: 0.4680\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2768 - accuracy: 0.5437 - val_loss: 1.5550 - val_accuracy: 0.4580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fdf1402d5b0>,\n",
       "                   n_iter=1,\n",
       "                   param_distributions={'dropout_rate': [0.03, 0.1],\n",
       "                                        'learning_rate': [0.0001, 0.0003]})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.fit(x_train, y_train, epochs = 100, validation_data = (x_valid, y_valid), callbacks = keras.callbacks.EarlyStopping(patience = 20, restore_best_weights = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0003, 'dropout_rate': 0.03}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46155555844306945"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see the model performs better on a dropout rate of 0.03 and a lr of 0.0003. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-4\n",
    "dropout_rate = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = keras.activations.selu, kernel_initializer = keras.initializers.lecun_normal()))\n",
    "model.add(keras.layers.AlphaDropout(rate = dropout_rate))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "alpha_dropout (AlphaDropout) (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(lr = learning_rate), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 20, restore_best_weights = True)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('CIFAR10_Dropout_model', save_best_only = True, save_weights_only = True)\n",
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'Dropout', 'optimal_model', 'lr = {}'.format(learning_rate))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/1407 [..............................] - ETA: 0s - loss: 2.9325 - accuracy: 0.1562WARNING:tensorflow:From /home/gokul/.local/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1407 [..............................] - ETA: 1:57 - loss: 2.9073 - accuracy: 0.1875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0252s vs `on_train_batch_end` time: 0.1419s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.8803 - accuracy: 0.3300 - val_loss: 1.7047 - val_accuracy: 0.4004\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6275 - accuracy: 0.4248 - val_loss: 1.5999 - val_accuracy: 0.4342\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5197 - accuracy: 0.4628 - val_loss: 1.5673 - val_accuracy: 0.4450\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4527 - accuracy: 0.4902 - val_loss: 1.5385 - val_accuracy: 0.4620\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3878 - accuracy: 0.5100 - val_loss: 1.4937 - val_accuracy: 0.4764\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3323 - accuracy: 0.5324 - val_loss: 1.4472 - val_accuracy: 0.4972\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2866 - accuracy: 0.5495 - val_loss: 1.4855 - val_accuracy: 0.4906\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2433 - accuracy: 0.5637 - val_loss: 1.4497 - val_accuracy: 0.5042\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1989 - accuracy: 0.5805 - val_loss: 1.4759 - val_accuracy: 0.4996\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1630 - accuracy: 0.5941 - val_loss: 1.5034 - val_accuracy: 0.4998\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1256 - accuracy: 0.6079 - val_loss: 1.4670 - val_accuracy: 0.5106\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0908 - accuracy: 0.6184 - val_loss: 1.4762 - val_accuracy: 0.5088\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0581 - accuracy: 0.6304 - val_loss: 1.4950 - val_accuracy: 0.5092\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0288 - accuracy: 0.6421 - val_loss: 1.4859 - val_accuracy: 0.5198\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9993 - accuracy: 0.6504 - val_loss: 1.5271 - val_accuracy: 0.5098\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9741 - accuracy: 0.6581 - val_loss: 1.5503 - val_accuracy: 0.5152\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9419 - accuracy: 0.6719 - val_loss: 1.5433 - val_accuracy: 0.5092\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9110 - accuracy: 0.6816 - val_loss: 1.5869 - val_accuracy: 0.5054\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8893 - accuracy: 0.6936 - val_loss: 1.6390 - val_accuracy: 0.5146\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8661 - accuracy: 0.6984 - val_loss: 1.6319 - val_accuracy: 0.5036\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8454 - accuracy: 0.7050 - val_loss: 1.6356 - val_accuracy: 0.5094\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8249 - accuracy: 0.7144 - val_loss: 1.6629 - val_accuracy: 0.5092\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.7968 - accuracy: 0.7254 - val_loss: 1.6979 - val_accuracy: 0.5136\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.7768 - accuracy: 0.7332 - val_loss: 1.6852 - val_accuracy: 0.5094\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.7560 - accuracy: 0.7374 - val_loss: 1.7379 - val_accuracy: 0.5090\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.7400 - accuracy: 0.7437 - val_loss: 1.7818 - val_accuracy: 0.5064\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 100, validation_data = (x_valid_scaled, y_valid), callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4472 - accuracy: 0.4972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4472453594207764, 0.49720001220703125]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4cd473dc10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('CIFAR10_Dropout_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4472 - accuracy: 0.4972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4472453594207764, 0.49720001220703125]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4405 - accuracy: 0.4987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4404797554016113, 0.49869999289512634]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model achieved an accuracy of 49.8% which is less than that achieved by using Batch Normalization.\n",
    "- But this model converged the fastest, in 6 epochs with each epoch having a time period of 10s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MCAlphaDropout after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the MC AlphaDroput class\n",
    "class MC_Alpha_Dropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new model by replacing the AlphaDropout layers with the above custom layer class.\n",
    "mc_model = keras.models.Sequential()\n",
    "[mc_model.add(MC_Alpha_Dropout(layer.rate)) if isinstance(layer, keras.layers.AlphaDropout) else mc_model.add(layer) for layer in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc__alpha__dropout (MC_Alpha (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function for predicting the output probabilities of each class for n-samples. \n",
    "# Keep in mind that these samples wiil be different from each other due to the randomness of the dropout layer.\n",
    "def mc_dropout_predict_probas(mc_model, x, n_sample = 10):\n",
    "    y_prob = [mc_model.predict(x) for sample in range(n_sample)]\n",
    "    return np.mean(y_prob, axis = 0)\n",
    "# Using the above probability value to predict the class to which an image belongs.\n",
    "def mc_dropout_predict_class(mc_model, x, n_sample = 10):\n",
    "    y_prob = mc_dropout_predict_probas(mc_model, x, n_sample)\n",
    "    return np.argmax(y_prob, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the outputs for the validation dataset.\n",
    "y_pred = mc_dropout_predict_class(mc_model, x_valid_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4954\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy of the predictions\n",
    "accuracy = np.mean(y_pred == y_valid[:, 0])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that there is no change in the performance of the model after applying MCAlphaDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
