{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the function of Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(housing.data, columns = housing.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['target'] = pd.Series(housing.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will be splitting the data into train, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df_data.drop(columns = 'target', axis = 1))\n",
    "y = np.array(df_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full, x_test, y_train_full, y_test = train_test_split(x, y, random_state = 42)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_full, y_train_full, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scaling the data using Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_valid = scaler.transform(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The NN model will be having 2 hidden layers with 30 units each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(30, activation = 'relu', input_shape = [8]))\n",
    "model.add(keras.layers.Dense(30, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 1,231\n",
      "Trainable params: 1,231\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loss function is mean squared error.\n",
    "- Optimizer is SGD with a learning rate of 1e-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse', optimizer = keras.optimizers.SGD(lr = 1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining root log directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_log_dir = os.path.join(os.curdir, 'logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_log_dir():\n",
    "    run_id = time.strftime('run_%Y_%m_%d_%H_%M_%S')\n",
    "    return os.path.join(root_log_dir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_log_dir = current_log_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./logs/run_2020_09_01_13_26_43'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have defined the root log directory to save our logs.\n",
    "- Then we defined a function which updates the log calculated in different file, with the file names having the time details of the log.\n",
    "- This is then added in the root log directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The callback functoin will take care of creating the log directories and during training it will create event files and write summaries to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/363 [..............................] - ETA: 0s - loss: 3.9116WARNING:tensorflow:From /home/gokul/.local/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/363 [..............................] - ETA: 16s - loss: 4.8846WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0056s vs `on_train_batch_end` time: 0.0818s). Check your callbacks.\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.4961 - val_loss: 1.3095\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 890us/step - loss: 0.7685 - val_loss: 0.7242\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 888us/step - loss: 0.6604 - val_loss: 0.6066\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 892us/step - loss: 0.6002 - val_loss: 0.5627\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 886us/step - loss: 0.5568 - val_loss: 0.5168\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 845us/step - loss: 0.5242 - val_loss: 0.4864\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.4984 - val_loss: 0.4596\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 914us/step - loss: 0.4772 - val_loss: 0.4536\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 913us/step - loss: 0.4597 - val_loss: 0.4494\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 900us/step - loss: 0.4456 - val_loss: 0.4212\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.4337 - val_loss: 0.4170\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 928us/step - loss: 0.4236 - val_loss: 0.4202\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 938us/step - loss: 0.4158 - val_loss: 0.4146\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.4088 - val_loss: 0.4082\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 906us/step - loss: 0.4030 - val_loss: 0.4184\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 902us/step - loss: 0.3982 - val_loss: 0.4174\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 896us/step - loss: 0.3938 - val_loss: 0.3832\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 905us/step - loss: 0.3902 - val_loss: 0.3812\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 853us/step - loss: 0.3868 - val_loss: 0.3891\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.3842 - val_loss: 0.3871\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 893us/step - loss: 0.3814 - val_loss: 0.3815\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 925us/step - loss: 0.3794 - val_loss: 0.3723\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 903us/step - loss: 0.3769 - val_loss: 0.4037\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 897us/step - loss: 0.3752 - val_loss: 0.3623\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 940us/step - loss: 0.3734 - val_loss: 0.3804\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 914us/step - loss: 0.3717 - val_loss: 0.4029\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 897us/step - loss: 0.3703 - val_loss: 0.3634\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.3687 - val_loss: 0.3985\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 902us/step - loss: 0.3673 - val_loss: 0.3698\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 907us/step - loss: 0.3661 - val_loss: 0.4004\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 30, validation_data = (x_valid, y_valid), callbacks = [tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
