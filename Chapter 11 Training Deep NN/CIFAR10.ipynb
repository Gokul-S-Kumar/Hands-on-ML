{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a NN and training it using the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_gpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-6c21d6545e1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_gpu\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_gpu'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow_gpu as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                  Version      \n",
      "------------------------ -------------\n",
      "absl-py                  0.9.0        \n",
      "astunparse               1.6.3        \n",
      "attrs                    19.3.0       \n",
      "Automat                  0.8.0        \n",
      "backcall                 0.1.0        \n",
      "beautifulsoup4           4.9.1        \n",
      "bleach                   3.1.5        \n",
      "blinker                  1.4          \n",
      "bs4                      0.0.1        \n",
      "cachetools               4.1.0        \n",
      "certifi                  2019.11.28   \n",
      "chardet                  3.0.4        \n",
      "Click                    7.0          \n",
      "cloud-init               20.1         \n",
      "colorama                 0.4.3        \n",
      "command-not-found        0.3          \n",
      "configobj                5.0.6        \n",
      "constantly               15.1.0       \n",
      "cryptography             2.8          \n",
      "cvxopt                   1.2.5        \n",
      "cycler                   0.10.0       \n",
      "dbus-python              1.2.16       \n",
      "decorator                4.4.2        \n",
      "defusedxml               0.6.0        \n",
      "dill                     0.3.1.1      \n",
      "distro                   1.4.0        \n",
      "distro-info              0.23ubuntu1  \n",
      "entrypoints              0.3          \n",
      "fasttext                 0.9.2        \n",
      "future                   0.18.2       \n",
      "gast                     0.3.3        \n",
      "google-auth              1.17.0       \n",
      "google-auth-oauthlib     0.4.1        \n",
      "google-pasta             0.2.0        \n",
      "googleapis-common-protos 1.52.0       \n",
      "graphviz                 0.14.1       \n",
      "grpcio                   1.29.0       \n",
      "h5py                     2.10.0       \n",
      "html5lib                 1.0.1        \n",
      "httplib2                 0.14.0       \n",
      "hyperlink                19.0.0       \n",
      "idna                     2.8          \n",
      "import-ipynb             0.1.3        \n",
      "importlib-metadata       1.5.0        \n",
      "importlib-resources      3.0.0        \n",
      "incremental              16.10.1      \n",
      "inflection               0.4.0        \n",
      "ipykernel                5.2.1        \n",
      "ipython                  7.14.0       \n",
      "ipython-genutils         0.2.0        \n",
      "IPythonBell              0.10         \n",
      "ipywidgets               7.5.1        \n",
      "jedi                     0.17.0       \n",
      "Jinja2                   2.11.2       \n",
      "joblib                   0.15.1       \n",
      "json5                    0.9.5        \n",
      "jsonpatch                1.22         \n",
      "jsonpointer              2.0          \n",
      "jsonschema               3.2.0        \n",
      "jupyter                  1.0.0        \n",
      "jupyter-client           6.1.3        \n",
      "jupyter-console          6.1.0        \n",
      "jupyter-core             4.6.3        \n",
      "jupyterlab               2.1.4        \n",
      "jupyterlab-server        1.1.5        \n",
      "jupyternotify            0.1.15       \n",
      "jupyterplot              0.0.2        \n",
      "Keras-Preprocessing      1.1.2        \n",
      "keyring                  18.0.1       \n",
      "kiwisolver               1.2.0        \n",
      "lab                      6.0          \n",
      "language-selector        0.1          \n",
      "launchpadlib             1.10.13      \n",
      "lazr.restfulclient       0.14.2       \n",
      "lazr.uri                 1.0.3        \n",
      "lrcurve                  1.1.1        \n",
      "lxml                     4.5.1        \n",
      "Markdown                 3.2.2        \n",
      "MarkupSafe               1.1.0        \n",
      "matplotlib               3.3.0        \n",
      "mistune                  0.8.4        \n",
      "mlxtend                  0.17.2       \n",
      "more-itertools           4.2.0        \n",
      "mpl-finance              0.10.1       \n",
      "mpld3                    0.3          \n",
      "mplfinance               0.12.4a0     \n",
      "multitasking             0.0.9        \n",
      "nbconvert                5.6.1        \n",
      "nbformat                 5.0.6        \n",
      "netifaces                0.10.4       \n",
      "networkx                 2.4          \n",
      "nltk                     3.5          \n",
      "nodejs                   0.1.1        \n",
      "notebook                 6.0.3        \n",
      "numpy                    1.18.4       \n",
      "oauthlib                 3.1.0        \n",
      "opt-einsum               3.2.1        \n",
      "optional-django          0.1.0        \n",
      "packaging                20.3         \n",
      "pandas                   1.1.0rc0     \n",
      "pandocfilters            1.4.2        \n",
      "parso                    0.7.0        \n",
      "patsy                    0.5.1        \n",
      "pexpect                  4.8.0        \n",
      "pickleshare              0.7.5        \n",
      "Pillow                   7.2.0        \n",
      "pip                      20.0.2       \n",
      "plotly                   4.8.1        \n",
      "prometheus-client        0.7.1        \n",
      "promise                  2.3          \n",
      "prompt-toolkit           3.0.5        \n",
      "protobuf                 3.12.2       \n",
      "ptyprocess               0.6.0        \n",
      "pyasn1                   0.4.2        \n",
      "pyasn1-modules           0.2.1        \n",
      "pybind11                 2.5.0        \n",
      "pydot                    1.4.1        \n",
      "Pygments                 2.6.1        \n",
      "PyGObject                3.36.0       \n",
      "PyHamcrest               1.9.0        \n",
      "PyJWT                    1.7.1        \n",
      "pymacaroons              0.13.0       \n",
      "PyNaCl                   1.3.0        \n",
      "pyOpenSSL                19.0.0       \n",
      "pyparsing                2.4.7        \n",
      "pyrsistent               0.15.5       \n",
      "pyserial                 3.4          \n",
      "python-apt               2.0.0        \n",
      "python-dateutil          2.8.1        \n",
      "python-debian            0.1.36ubuntu1\n",
      "pytreebank               0.2.7        \n",
      "pytz                     2020.1       \n",
      "PyYAML                   5.3.1        \n",
      "pyzmq                    19.0.0       \n",
      "qtconsole                4.7.3        \n",
      "QtPy                     1.9.0        \n",
      "Quandl                   3.5.0        \n",
      "regex                    2020.6.8     \n",
      "requests                 2.22.0       \n",
      "requests-oauthlib        1.3.0        \n",
      "requests-unixsocket      0.2.0        \n",
      "retrying                 1.3.3        \n",
      "rsa                      4.1          \n",
      "scikit-learn             0.23.1       \n",
      "scipy                    1.4.1        \n",
      "seaborn                  0.10.1       \n",
      "SecretStorage            2.3.1        \n",
      "Send2Trash               1.5.0        \n",
      "service-identity         18.1.0       \n",
      "setuptools               45.2.0       \n",
      "simplejson               3.16.0       \n",
      "six                      1.14.0       \n",
      "sklearn                  0.0          \n",
      "soupsieve                2.0.1        \n",
      "ssh-import-id            5.10         \n",
      "statsmodels              0.11.1       \n",
      "sweetviz                 1.0a7        \n",
      "systemd-python           234          \n",
      "tensorboard              2.3.0        \n",
      "tensorboard-plugin-wit   1.6.0.post3  \n",
      "tensorflow-datasets      3.1.0        \n",
      "tensorflow-estimator     2.3.0        \n",
      "tensorflow-gpu           2.3.0        \n",
      "tensorflow-metadata      0.22.2       \n",
      "termcolor                1.1.0        \n",
      "terminado                0.8.3        \n",
      "testpath                 0.4.4        \n",
      "textblob                 0.15.3       \n",
      "threadpoolctl            2.0.0        \n",
      "tornado                  6.0.4        \n",
      "tqdm                     4.46.1       \n",
      "traitlets                4.3.3        \n",
      "Twisted                  18.9.0       \n",
      "txt2tags                 3.7          \n",
      "ubuntu-advantage-tools   20.3         \n",
      "ufw                      0.36         \n",
      "unattended-upgrades      0.1          \n",
      "urllib3                  1.25.8       \n",
      "wadllib                  1.3.3        \n",
      "wcwidth                  0.1.9        \n",
      "webencodings             0.5.1        \n",
      "Werkzeug                 1.0.1        \n",
      "wheel                    0.34.2       \n",
      "widgetsnbextension       3.5.1        \n",
      "wrapt                    1.12.1       \n",
      "xlrd                     1.2.0        \n",
      "yfinance                 0.1.54       \n",
      "zipp                     1.0.0        \n",
      "zope.interface           4.7.1        \n"
     ]
    }
   ],
   "source": [
    "!pip3 list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, x_train = x_train_full[:5000], x_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = keras.activations.relu, kernel_initializer = keras.initializers.he_normal()))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we need to find an optimal learning rate. To do this we will use a Nadam optimizer and train the model for 10 epochs with different learning rates.\n",
    "- We will be setting up a tensorboard environment using a tensorboard callback and check the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'optimal_lr_model', 'lr = {}'.format(learning_rate))\n",
    "tb_callback = keras.callbacks.TensorBoard(run_logdir)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('CIFAR10_model.h5', save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(learning_rate = learning_rate), metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/1407 [..............................] - ETA: 0s - loss: 165.7273 - accuracy: 0.0625WARNING:tensorflow:From /home/gokul/.local/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1407 [..............................] - ETA: 1:02 - loss: 129.1794 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0241s vs `on_train_batch_end` time: 0.0637s). Check your callbacks.\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.7819 - accuracy: 0.1722 - val_loss: 2.0820 - val_accuracy: 0.2038\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.9937 - accuracy: 0.2514 - val_loss: 2.1159 - val_accuracy: 0.2318\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.9164 - accuracy: 0.2812 - val_loss: 1.9130 - val_accuracy: 0.2824\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.8650 - accuracy: 0.3061 - val_loss: 1.8742 - val_accuracy: 0.3116\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.8361 - accuracy: 0.3218 - val_loss: 1.9204 - val_accuracy: 0.2920\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7965 - accuracy: 0.3409 - val_loss: 1.8150 - val_accuracy: 0.3338\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7458 - accuracy: 0.3650 - val_loss: 1.7359 - val_accuracy: 0.3738\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7039 - accuracy: 0.3815 - val_loss: 1.6928 - val_accuracy: 0.3882\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6794 - accuracy: 0.3924 - val_loss: 1.6576 - val_accuracy: 0.4050\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.6503 - accuracy: 0.4036 - val_loss: 1.6520 - val_accuracy: 0.4004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd0205f71f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 10, validation_data = (x_valid, y_valid), callbacks = [tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From multiple trial and error values for learning rate, it was found that the model performed the best at a learning rate of 0.00025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = keras.activations.relu, kernel_initializer = keras.initializers.he_normal()))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lr = 0.00025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(learning_rate = optimal_lr), metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('CIFAR10_model', save_best_only=True, save_weights_only = True)\n",
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'optimal_lr_model')\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1407 [..............................] - ETA: 3:01 - loss: 129.1794 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0084s vs `on_train_batch_end` time: 0.2490s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 2.7819 - accuracy: 0.1722 - val_loss: 2.0820 - val_accuracy: 0.2038\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9937 - accuracy: 0.2514 - val_loss: 2.1159 - val_accuracy: 0.2318\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9164 - accuracy: 0.2812 - val_loss: 1.9130 - val_accuracy: 0.2824\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.8650 - accuracy: 0.3061 - val_loss: 1.8742 - val_accuracy: 0.3116\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8361 - accuracy: 0.3218 - val_loss: 1.9204 - val_accuracy: 0.2920\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7965 - accuracy: 0.3409 - val_loss: 1.8150 - val_accuracy: 0.3338\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7458 - accuracy: 0.3650 - val_loss: 1.7359 - val_accuracy: 0.3738\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7039 - accuracy: 0.3815 - val_loss: 1.6928 - val_accuracy: 0.3882\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6794 - accuracy: 0.3924 - val_loss: 1.6576 - val_accuracy: 0.4050\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6503 - accuracy: 0.4036 - val_loss: 1.6520 - val_accuracy: 0.4004\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6255 - accuracy: 0.4115 - val_loss: 1.6933 - val_accuracy: 0.3872\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6121 - accuracy: 0.4191 - val_loss: 1.6392 - val_accuracy: 0.4160\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5878 - accuracy: 0.4299 - val_loss: 1.6281 - val_accuracy: 0.4120\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5719 - accuracy: 0.4362 - val_loss: 1.5983 - val_accuracy: 0.4252\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5594 - accuracy: 0.4389 - val_loss: 1.5984 - val_accuracy: 0.4212\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5420 - accuracy: 0.4448 - val_loss: 1.6114 - val_accuracy: 0.4276\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5275 - accuracy: 0.4523 - val_loss: 1.6050 - val_accuracy: 0.4242\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5154 - accuracy: 0.4550 - val_loss: 1.5782 - val_accuracy: 0.4350\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5056 - accuracy: 0.4588 - val_loss: 1.6181 - val_accuracy: 0.4234\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4939 - accuracy: 0.4629 - val_loss: 1.5991 - val_accuracy: 0.4358\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4822 - accuracy: 0.4701 - val_loss: 1.5511 - val_accuracy: 0.4512\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4749 - accuracy: 0.4714 - val_loss: 1.5564 - val_accuracy: 0.4450\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.4591 - accuracy: 0.4788 - val_loss: 1.5605 - val_accuracy: 0.4428\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4525 - accuracy: 0.4805 - val_loss: 1.5362 - val_accuracy: 0.4546\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4420 - accuracy: 0.4823 - val_loss: 1.5810 - val_accuracy: 0.4422\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4386 - accuracy: 0.4849 - val_loss: 1.5680 - val_accuracy: 0.4388\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4274 - accuracy: 0.4871 - val_loss: 1.5378 - val_accuracy: 0.4570\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4211 - accuracy: 0.4888 - val_loss: 1.5360 - val_accuracy: 0.4530\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.4097 - accuracy: 0.4954 - val_loss: 1.5543 - val_accuracy: 0.4536\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4060 - accuracy: 0.4972 - val_loss: 1.5355 - val_accuracy: 0.4644\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3957 - accuracy: 0.4988 - val_loss: 1.5489 - val_accuracy: 0.4530\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3849 - accuracy: 0.5055 - val_loss: 1.5574 - val_accuracy: 0.4596\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3828 - accuracy: 0.5036 - val_loss: 1.5846 - val_accuracy: 0.4484\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3707 - accuracy: 0.5095 - val_loss: 1.5558 - val_accuracy: 0.4634\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3609 - accuracy: 0.5108 - val_loss: 1.5805 - val_accuracy: 0.4476\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 8s 5ms/step - loss: 1.3571 - accuracy: 0.5157 - val_loss: 1.5809 - val_accuracy: 0.4542\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3471 - accuracy: 0.5163 - val_loss: 1.5970 - val_accuracy: 0.4514\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3367 - accuracy: 0.5228 - val_loss: 1.5556 - val_accuracy: 0.4662\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3314 - accuracy: 0.5247 - val_loss: 1.5809 - val_accuracy: 0.4452\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3198 - accuracy: 0.5281 - val_loss: 1.5258 - val_accuracy: 0.4720\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3164 - accuracy: 0.5303 - val_loss: 1.5828 - val_accuracy: 0.4620\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3079 - accuracy: 0.5340 - val_loss: 1.5581 - val_accuracy: 0.4528\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3023 - accuracy: 0.5316 - val_loss: 1.5584 - val_accuracy: 0.4596\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2967 - accuracy: 0.5346 - val_loss: 1.5677 - val_accuracy: 0.4580\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2894 - accuracy: 0.5360 - val_loss: 1.5443 - val_accuracy: 0.4726\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2842 - accuracy: 0.5389 - val_loss: 1.5458 - val_accuracy: 0.4612\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2735 - accuracy: 0.5455 - val_loss: 1.5767 - val_accuracy: 0.4582\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2651 - accuracy: 0.5465 - val_loss: 1.5355 - val_accuracy: 0.4732\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2556 - accuracy: 0.5521 - val_loss: 1.5536 - val_accuracy: 0.4640\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2556 - accuracy: 0.5488 - val_loss: 1.5992 - val_accuracy: 0.4658\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2410 - accuracy: 0.5552 - val_loss: 1.6099 - val_accuracy: 0.4656\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2386 - accuracy: 0.5579 - val_loss: 1.5442 - val_accuracy: 0.4644\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2362 - accuracy: 0.5585 - val_loss: 1.5767 - val_accuracy: 0.4710\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2257 - accuracy: 0.5603 - val_loss: 1.6144 - val_accuracy: 0.4570\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2226 - accuracy: 0.5596 - val_loss: 1.5958 - val_accuracy: 0.4748\n",
      "Epoch 56/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2129 - accuracy: 0.5658 - val_loss: 1.5730 - val_accuracy: 0.4708\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2076 - accuracy: 0.5651 - val_loss: 1.5680 - val_accuracy: 0.4716\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2068 - accuracy: 0.5685 - val_loss: 1.5710 - val_accuracy: 0.4674\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.1984 - accuracy: 0.5688 - val_loss: 1.6206 - val_accuracy: 0.4676\n",
      "Epoch 60/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1861 - accuracy: 0.5761 - val_loss: 1.5790 - val_accuracy: 0.4686\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 100, validation_data = (x_valid, y_valid), callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5790 - accuracy: 0.4686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5790321826934814, 0.46860000491142273]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5602 - accuracy: 0.4689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5602147579193115, 0.46889999508857727]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd0206aae50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('CIFAR10_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5258 - accuracy: 0.4720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5257840156555176, 0.47200000286102295]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5075 - accuracy: 0.4742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5074900388717651, 0.4742000102996826]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that the model with the least validation_loss gives us am accuracy of 47% on the validation and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will be adding the batvh normalization layers in the net and check its performance variations.\n",
    "- Again as we changed the model architecture, we need to find the optimal learning rate by trial and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer = keras.initializers.he_normal()))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('elu'))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 520,498\n",
      "Trainable params: 510,354\n",
      "Non-trainable params: 10,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(lr = learning_rate), metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'BN', 'lr = {}'.format(learning_rate))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 7:03 - loss: 2.9106 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0179s vs `on_train_batch_end` time: 0.5836s). Check your callbacks.\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.8514 - accuracy: 0.3351 - val_loss: 1.7488 - val_accuracy: 0.3762\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.7044 - accuracy: 0.3926 - val_loss: 1.6794 - val_accuracy: 0.3950\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.6400 - accuracy: 0.4171 - val_loss: 1.6474 - val_accuracy: 0.4116\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.5878 - accuracy: 0.4350 - val_loss: 1.6109 - val_accuracy: 0.4320\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5416 - accuracy: 0.4529 - val_loss: 1.5223 - val_accuracy: 0.4540\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5039 - accuracy: 0.4670 - val_loss: 1.4697 - val_accuracy: 0.4698\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4666 - accuracy: 0.4794 - val_loss: 1.4893 - val_accuracy: 0.4736\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4346 - accuracy: 0.4920 - val_loss: 1.4309 - val_accuracy: 0.4852\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4133 - accuracy: 0.5032 - val_loss: 1.4155 - val_accuracy: 0.4990\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3865 - accuracy: 0.5094 - val_loss: 1.3645 - val_accuracy: 0.5188\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3616 - accuracy: 0.5222 - val_loss: 1.3474 - val_accuracy: 0.5280\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3380 - accuracy: 0.5302 - val_loss: 1.3894 - val_accuracy: 0.5094\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3187 - accuracy: 0.5348 - val_loss: 1.4025 - val_accuracy: 0.5072\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2980 - accuracy: 0.5441 - val_loss: 1.3652 - val_accuracy: 0.5234\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2749 - accuracy: 0.5521 - val_loss: 1.3748 - val_accuracy: 0.5222\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2628 - accuracy: 0.5581 - val_loss: 1.3527 - val_accuracy: 0.5256\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2399 - accuracy: 0.5637 - val_loss: 1.3515 - val_accuracy: 0.5306\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2238 - accuracy: 0.5709 - val_loss: 1.3480 - val_accuracy: 0.5214\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2071 - accuracy: 0.5767 - val_loss: 1.3954 - val_accuracy: 0.5088\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1952 - accuracy: 0.5837 - val_loss: 1.3511 - val_accuracy: 0.5364\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 20, validation_data = (x_valid, y_valid), callbacks = [tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After using different learning rates, it was found that the model having lr = 0.001 gives the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer = keras.initializers.he_normal()))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('elu'))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 520,498\n",
      "Trainable params: 510,354\n",
      "Non-trainable params: 10,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(learning_rate = optimal_lr), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('CIFAR10_BN_model', save_best_only = True, save_weights_only = True)\n",
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'BN', 'optimal_lr_model', 'lr = {}'.format(optimal_lr))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1407 [..............................] - ETA: 7:29 - loss: 2.9545 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0180s vs `on_train_batch_end` time: 0.6210s). Check your callbacks.\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.8374 - accuracy: 0.3410 - val_loss: 1.6944 - val_accuracy: 0.4008\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.6859 - accuracy: 0.3998 - val_loss: 1.6820 - val_accuracy: 0.3850\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.6192 - accuracy: 0.4231 - val_loss: 1.6028 - val_accuracy: 0.4250\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.5717 - accuracy: 0.4369 - val_loss: 1.5617 - val_accuracy: 0.4480\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5286 - accuracy: 0.4608 - val_loss: 1.4750 - val_accuracy: 0.4708\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4899 - accuracy: 0.4730 - val_loss: 1.4929 - val_accuracy: 0.4742\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.4539 - accuracy: 0.4841 - val_loss: 1.4742 - val_accuracy: 0.4694\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.4262 - accuracy: 0.4974 - val_loss: 1.4236 - val_accuracy: 0.4880\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3987 - accuracy: 0.5075 - val_loss: 1.4360 - val_accuracy: 0.4966\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.3739 - accuracy: 0.5157 - val_loss: 1.3685 - val_accuracy: 0.5222\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3558 - accuracy: 0.5216 - val_loss: 1.3487 - val_accuracy: 0.5174\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3275 - accuracy: 0.5332 - val_loss: 1.3995 - val_accuracy: 0.5044\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3099 - accuracy: 0.5385 - val_loss: 1.3863 - val_accuracy: 0.5120\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2898 - accuracy: 0.5475 - val_loss: 1.3638 - val_accuracy: 0.5280\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2677 - accuracy: 0.5532 - val_loss: 1.3788 - val_accuracy: 0.5132\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2558 - accuracy: 0.5580 - val_loss: 1.3443 - val_accuracy: 0.5376\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2358 - accuracy: 0.5645 - val_loss: 1.3359 - val_accuracy: 0.5348\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2192 - accuracy: 0.5705 - val_loss: 1.3512 - val_accuracy: 0.5396\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2059 - accuracy: 0.5767 - val_loss: 1.3877 - val_accuracy: 0.5216\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1962 - accuracy: 0.5808 - val_loss: 1.3433 - val_accuracy: 0.5428\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1752 - accuracy: 0.5890 - val_loss: 1.3990 - val_accuracy: 0.5252\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1626 - accuracy: 0.5927 - val_loss: 1.3276 - val_accuracy: 0.5452\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1493 - accuracy: 0.5974 - val_loss: 1.3185 - val_accuracy: 0.5530\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1351 - accuracy: 0.6028 - val_loss: 1.3257 - val_accuracy: 0.5398\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1271 - accuracy: 0.6064 - val_loss: 1.3468 - val_accuracy: 0.5466\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1080 - accuracy: 0.6114 - val_loss: 1.3523 - val_accuracy: 0.5468\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0962 - accuracy: 0.6155 - val_loss: 1.3475 - val_accuracy: 0.5366\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0872 - accuracy: 0.6216 - val_loss: 1.3529 - val_accuracy: 0.5334\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0813 - accuracy: 0.6214 - val_loss: 1.3307 - val_accuracy: 0.5452\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0621 - accuracy: 0.6288 - val_loss: 1.3573 - val_accuracy: 0.5394\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0546 - accuracy: 0.6296 - val_loss: 1.3592 - val_accuracy: 0.5492\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0455 - accuracy: 0.6343 - val_loss: 1.3805 - val_accuracy: 0.5376\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0292 - accuracy: 0.6395 - val_loss: 1.3270 - val_accuracy: 0.5594\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0210 - accuracy: 0.6437 - val_loss: 1.3622 - val_accuracy: 0.5488\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0111 - accuracy: 0.6480 - val_loss: 1.3527 - val_accuracy: 0.5430\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0039 - accuracy: 0.6487 - val_loss: 1.3727 - val_accuracy: 0.5484\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9844 - accuracy: 0.6548 - val_loss: 1.3452 - val_accuracy: 0.5492\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9847 - accuracy: 0.6560 - val_loss: 1.3862 - val_accuracy: 0.5428\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 0.9688 - accuracy: 0.6601 - val_loss: 1.3631 - val_accuracy: 0.5486\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9593 - accuracy: 0.6663 - val_loss: 1.3795 - val_accuracy: 0.5422\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9536 - accuracy: 0.6669 - val_loss: 1.3716 - val_accuracy: 0.5468\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9407 - accuracy: 0.6702 - val_loss: 1.3822 - val_accuracy: 0.5448\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 0.9391 - accuracy: 0.6716 - val_loss: 1.3898 - val_accuracy: 0.5472\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 100, validation_data = (x_valid, y_valid), callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.3898 - accuracy: 0.5472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.389768123626709, 0.5472000241279602]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3966 - accuracy: 0.5371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3966196775436401, 0.5371000170707703]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fcf9c37adc0>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('CIFAR10_BN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.3185 - accuracy: 0.5530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3185102939605713, 0.5529999732971191]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3248 - accuracy: 0.5398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3248482942581177, 0.5397999882698059]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that the model reached the lowest val_loss at 23 epochs when we added BN to the net.\n",
    "- Adding BN enabled us to use much larger lr which reduced the total training time.\n",
    "- The metrics of the model are also better with the validation and test accuracies being 55% and 53% respectively.\n",
    "- The only drawback is that the time taken to complete each epoch increased from 10s to 16s, but on overall the total training time is decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing BN with SELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We need to standardize the inputs in order to use the SELU activation func."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean(axis = 0, keepdims = True)\n",
    "x_std = x_train.std(axis = 0, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = (x_train - x_mean) / x_std\n",
    "x_valid_scaled = (x_valid - x_mean) / x_std\n",
    "x_test_scaled = (x_test - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = keras.activations.selu, kernel_initializer = keras.initializers.lecun_normal()))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(learning_rate), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'SELU', 'lr = {}'.format(learning_rate))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 2:58 - loss: 3.0571 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0076s vs `on_train_batch_end` time: 0.2454s). Check your callbacks.\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.9313 - accuracy: 0.3097 - val_loss: 1.8588 - val_accuracy: 0.3136\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7200 - accuracy: 0.3890 - val_loss: 1.7384 - val_accuracy: 0.3778\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6249 - accuracy: 0.4275 - val_loss: 1.7290 - val_accuracy: 0.3988\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5634 - accuracy: 0.4478 - val_loss: 1.6357 - val_accuracy: 0.4336\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5074 - accuracy: 0.4691 - val_loss: 1.5887 - val_accuracy: 0.4392\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4673 - accuracy: 0.4866 - val_loss: 1.5583 - val_accuracy: 0.4644\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4314 - accuracy: 0.5005 - val_loss: 1.5709 - val_accuracy: 0.4644\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3879 - accuracy: 0.5141 - val_loss: 1.4943 - val_accuracy: 0.4806\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3576 - accuracy: 0.5269 - val_loss: 1.5016 - val_accuracy: 0.4694\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3339 - accuracy: 0.5359 - val_loss: 1.4981 - val_accuracy: 0.4746\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3002 - accuracy: 0.5456 - val_loss: 1.5640 - val_accuracy: 0.4858\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2770 - accuracy: 0.5528 - val_loss: 1.5093 - val_accuracy: 0.4644\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2502 - accuracy: 0.5652 - val_loss: 1.4966 - val_accuracy: 0.4900\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2315 - accuracy: 0.5741 - val_loss: 1.4913 - val_accuracy: 0.4980\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2029 - accuracy: 0.5847 - val_loss: 1.5040 - val_accuracy: 0.4962\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1782 - accuracy: 0.5922 - val_loss: 1.5320 - val_accuracy: 0.4922\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1667 - accuracy: 0.5947 - val_loss: 1.5049 - val_accuracy: 0.4924\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1353 - accuracy: 0.6066 - val_loss: 1.4970 - val_accuracy: 0.5082\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1198 - accuracy: 0.6111 - val_loss: 1.4975 - val_accuracy: 0.5058\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1503 - accuracy: 0.6090 - val_loss: 1.5465 - val_accuracy: 0.4896\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 20, validation_data = (x_valid_scaled, y_valid), callbacks = [tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After changing the architecture we could find that the model performs at its best at lr = 0.0004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = keras.activations.selu, kernel_initializer = keras.initializers.lecun_normal()))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lr = 0.0004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(optimal_lr), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint('CIFAR10_SELU_model', save_best_only = True, save_weights_only = True)\n",
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'SELU', 'optimal_model', 'lr = {}'.format(optimal_lr))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/1407 [..............................] - ETA: 2:20 - loss: 2.9763 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0069s vs `on_train_batch_end` time: 0.1924s). Check your callbacks.\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.8783 - accuracy: 0.3294 - val_loss: 1.7889 - val_accuracy: 0.3518\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6694 - accuracy: 0.4085 - val_loss: 1.7444 - val_accuracy: 0.3730\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5651 - accuracy: 0.4500 - val_loss: 1.5895 - val_accuracy: 0.4310\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4906 - accuracy: 0.4757 - val_loss: 1.5508 - val_accuracy: 0.4604\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4261 - accuracy: 0.4994 - val_loss: 1.5326 - val_accuracy: 0.4566\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3760 - accuracy: 0.5150 - val_loss: 1.4838 - val_accuracy: 0.4800\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3262 - accuracy: 0.5373 - val_loss: 1.4950 - val_accuracy: 0.4838\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2808 - accuracy: 0.5492 - val_loss: 1.4441 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2378 - accuracy: 0.5706 - val_loss: 1.4800 - val_accuracy: 0.4890\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2034 - accuracy: 0.5829 - val_loss: 1.4828 - val_accuracy: 0.4990\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1686 - accuracy: 0.5956 - val_loss: 1.4911 - val_accuracy: 0.5016\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1321 - accuracy: 0.6078 - val_loss: 1.4539 - val_accuracy: 0.5060\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.1041 - accuracy: 0.6196 - val_loss: 1.4871 - val_accuracy: 0.5054\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0754 - accuracy: 0.6319 - val_loss: 1.4716 - val_accuracy: 0.5104\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0390 - accuracy: 0.6407 - val_loss: 1.4800 - val_accuracy: 0.5136\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0146 - accuracy: 0.6528 - val_loss: 1.5277 - val_accuracy: 0.5210\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.9892 - accuracy: 0.6593 - val_loss: 1.5216 - val_accuracy: 0.5124\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9640 - accuracy: 0.6736 - val_loss: 1.5493 - val_accuracy: 0.5202\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9382 - accuracy: 0.6769 - val_loss: 1.5601 - val_accuracy: 0.5192\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9178 - accuracy: 0.6874 - val_loss: 1.5716 - val_accuracy: 0.5178\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8949 - accuracy: 0.6958 - val_loss: 1.6265 - val_accuracy: 0.5190\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8722 - accuracy: 0.7011 - val_loss: 1.6008 - val_accuracy: 0.5132\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8502 - accuracy: 0.7090 - val_loss: 1.6837 - val_accuracy: 0.4986\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8390 - accuracy: 0.7138 - val_loss: 1.5859 - val_accuracy: 0.5146\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.8158 - accuracy: 0.7239 - val_loss: 1.6536 - val_accuracy: 0.5072\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8006 - accuracy: 0.7312 - val_loss: 1.6247 - val_accuracy: 0.5058\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.7830 - accuracy: 0.7374 - val_loss: 1.6342 - val_accuracy: 0.5168\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.7634 - accuracy: 0.7443 - val_loss: 1.6528 - val_accuracy: 0.5068\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 100, validation_data = (x_valid_scaled, y_valid), callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.6528 - accuracy: 0.5068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.652758240699768, 0.5067999958992004]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6576 - accuracy: 0.5017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.657639980316162, 0.5016999840736389]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd0744f53a0>"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('CIFAR10_SELU_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4441 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4440743923187256, 0.5]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4459 - accuracy: 0.4979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.445914626121521, 0.49790000915527344]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is the fastest model by far as the best model in terms of val_error was achieved in 8 epochs with 10s for each epoch.\n",
    "- But the drawback is the model performance which even though is better than the raw model is less than that of the model with BN layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AlphaDropouts for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation = keras.activations.selu, kernel_initializer = keras.initializers.lecun_normal()))\n",
    "model.add(keras.layers.AlphaDropout(rate = 0.1))\n",
    "model.add(keras.layers.Dense(10, activation = keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout (AlphaDropout) (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "alpha_dropout_1 (AlphaDropou (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "alpha_dropout_2 (AlphaDropou (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "alpha_dropout_3 (AlphaDropou (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "alpha_dropout_4 (AlphaDropou (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "alpha_dropout_5 (AlphaDropou (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "alpha_dropout_6 (AlphaDropou (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "alpha_dropout_7 (AlphaDropou (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "alpha_dropout_8 (AlphaDropou (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = os.path.join(os.curdir, 'CIFAR10_logs', 'Dropout', 'Div_3_dropout')\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   2/1407 [..............................] - ETA: 3:18 - loss: 3.4093 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0117s vs `on_train_batch_end` time: 0.2690s). Check your callbacks.\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 2.0495 - accuracy: 0.2426 - val_loss: 2.1186 - val_accuracy: 0.3018\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.8852 - accuracy: 0.3040 - val_loss: 2.1627 - val_accuracy: 0.3038\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.8247 - accuracy: 0.3313 - val_loss: 2.4859 - val_accuracy: 0.3388\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7897 - accuracy: 0.3410 - val_loss: 2.2891 - val_accuracy: 0.3356\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.7680 - accuracy: 0.3544 - val_loss: 2.8053 - val_accuracy: 0.3532\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 1.7588 - accuracy: 0.3532 - val_loss: 2.3630 - val_accuracy: 0.3522\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.7349 - accuracy: 0.3613 - val_loss: 2.2733 - val_accuracy: 0.3528\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7583 - accuracy: 0.3610 - val_loss: 2.4815 - val_accuracy: 0.3466\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.7435 - accuracy: 0.3648 - val_loss: 2.2716 - val_accuracy: 0.3814\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.7144 - accuracy: 0.3757 - val_loss: 2.2717 - val_accuracy: 0.3882\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7238 - accuracy: 0.3725 - val_loss: 2.6285 - val_accuracy: 0.3266\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7099 - accuracy: 0.3792 - val_loss: 2.0635 - val_accuracy: 0.3772\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.7010 - accuracy: 0.3822 - val_loss: 2.2351 - val_accuracy: 0.3582\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7101 - accuracy: 0.3838 - val_loss: 2.5224 - val_accuracy: 0.3332\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.7298 - accuracy: 0.3739 - val_loss: 2.4509 - val_accuracy: 0.3720\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.7364 - accuracy: 0.3684 - val_loss: 2.1253 - val_accuracy: 0.3860\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7688 - accuracy: 0.3529 - val_loss: 2.4976 - val_accuracy: 0.3078\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7516 - accuracy: 0.3506 - val_loss: 2.4792 - val_accuracy: 0.3346\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7271 - accuracy: 0.3706 - val_loss: 2.3066 - val_accuracy: 0.3280\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.7118 - accuracy: 0.3692 - val_loss: 2.3770 - val_accuracy: 0.3348\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 20, validation_data = (x_valid_scaled, y_valid), callbacks = [tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After training the model we could see that the model performs the best when dropout is added after the last hidden layer.\n",
    "- Now we need to decide the dropout rate as well as the learning_rate for which we will be using Randomized Search CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dropout_rate = 0.1, learning_rate = 1e-3):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape = [32, 32, 3]))\n",
    "    for _ in range(20):\n",
    "        model.add(keras.layers.Dense(100, activation = keras.activations.selu, kernel_initializer = keras.initializers.lecun_normal()))\n",
    "    model.add(keras.layers.AlphaDropout(rate = dropout_rate))\n",
    "    model.add(keras.layers.Dense(10, activation = keras.activations.softmax))\n",
    "    model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer = keras.optimizers.Nadam(lr = learning_rate), metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = keras.wrappers.scikit_learn.KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dropout_rate' : [0.01, 0.03, 0.1, 0.3], 'learning_rate' : [0.00001, 0.00003, 0.0001, 0.0003, 0.001, 0.003, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_search = RandomizedSearchCV(estimator = classifier, param_distributions = params, n_iter = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0442 - accuracy: 0.2525 - val_loss: 1.8363 - val_accuracy: 0.3266\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8271 - accuracy: 0.3339 - val_loss: 1.7315 - val_accuracy: 0.3678\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7437 - accuracy: 0.3670 - val_loss: 1.7194 - val_accuracy: 0.3822\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6883 - accuracy: 0.3923 - val_loss: 1.6571 - val_accuracy: 0.4010\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6443 - accuracy: 0.4077 - val_loss: 1.6256 - val_accuracy: 0.4118\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6014 - accuracy: 0.4276 - val_loss: 1.6270 - val_accuracy: 0.4134\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5743 - accuracy: 0.4348 - val_loss: 1.5981 - val_accuracy: 0.4212\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5465 - accuracy: 0.4462 - val_loss: 1.5893 - val_accuracy: 0.4276\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5218 - accuracy: 0.4557 - val_loss: 1.5657 - val_accuracy: 0.4440\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5009 - accuracy: 0.4641 - val_loss: 1.5546 - val_accuracy: 0.4458\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4824 - accuracy: 0.4706 - val_loss: 1.5775 - val_accuracy: 0.4414\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4618 - accuracy: 0.4787 - val_loss: 1.5609 - val_accuracy: 0.4470\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4445 - accuracy: 0.4859 - val_loss: 1.5374 - val_accuracy: 0.4612\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4280 - accuracy: 0.4899 - val_loss: 1.5860 - val_accuracy: 0.4506\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4071 - accuracy: 0.4994 - val_loss: 1.5220 - val_accuracy: 0.4572\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3947 - accuracy: 0.5004 - val_loss: 1.5775 - val_accuracy: 0.4528\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3808 - accuracy: 0.5044 - val_loss: 1.5370 - val_accuracy: 0.4632\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3647 - accuracy: 0.5131 - val_loss: 1.5453 - val_accuracy: 0.4624\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3537 - accuracy: 0.5167 - val_loss: 1.5774 - val_accuracy: 0.4648\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3381 - accuracy: 0.5229 - val_loss: 1.5325 - val_accuracy: 0.4810\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 7s 7ms/step - loss: 1.3218 - accuracy: 0.5287 - val_loss: 1.5452 - val_accuracy: 0.4704\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3079 - accuracy: 0.5338 - val_loss: 1.5463 - val_accuracy: 0.4654\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2950 - accuracy: 0.5386 - val_loss: 1.5266 - val_accuracy: 0.4766\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2823 - accuracy: 0.5434 - val_loss: 1.5231 - val_accuracy: 0.4736\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2665 - accuracy: 0.5470 - val_loss: 1.5312 - val_accuracy: 0.4774\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5261 - accuracy: 0.4524\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0517 - accuracy: 0.2485 - val_loss: 1.8683 - val_accuracy: 0.3102\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8475 - accuracy: 0.3251 - val_loss: 1.7984 - val_accuracy: 0.3498\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7657 - accuracy: 0.3559 - val_loss: 1.7123 - val_accuracy: 0.3760\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7037 - accuracy: 0.3820 - val_loss: 1.6771 - val_accuracy: 0.3922\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6517 - accuracy: 0.4032 - val_loss: 1.6732 - val_accuracy: 0.4030\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6174 - accuracy: 0.4152 - val_loss: 1.6930 - val_accuracy: 0.3826\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.5857 - accuracy: 0.4279 - val_loss: 1.5942 - val_accuracy: 0.4304\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.5579 - accuracy: 0.4415 - val_loss: 1.6241 - val_accuracy: 0.4114\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5336 - accuracy: 0.4453 - val_loss: 1.5738 - val_accuracy: 0.4382\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5088 - accuracy: 0.4578 - val_loss: 1.5742 - val_accuracy: 0.4448\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4863 - accuracy: 0.4666 - val_loss: 1.5648 - val_accuracy: 0.4420\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.4666 - accuracy: 0.4727 - val_loss: 1.5834 - val_accuracy: 0.4452\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4529 - accuracy: 0.4775 - val_loss: 1.5771 - val_accuracy: 0.4284\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4357 - accuracy: 0.4852 - val_loss: 1.5233 - val_accuracy: 0.4548\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 7s 7ms/step - loss: 1.4144 - accuracy: 0.4908 - val_loss: 1.5377 - val_accuracy: 0.4478\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4038 - accuracy: 0.4963 - val_loss: 1.5218 - val_accuracy: 0.4676\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3857 - accuracy: 0.5004 - val_loss: 1.5218 - val_accuracy: 0.4544\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3740 - accuracy: 0.5050 - val_loss: 1.5259 - val_accuracy: 0.4700\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3552 - accuracy: 0.5113 - val_loss: 1.5376 - val_accuracy: 0.4618\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3427 - accuracy: 0.5171 - val_loss: 1.5304 - val_accuracy: 0.4688\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3240 - accuracy: 0.5233 - val_loss: 1.5545 - val_accuracy: 0.4602\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3107 - accuracy: 0.5298 - val_loss: 1.5597 - val_accuracy: 0.4548\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2976 - accuracy: 0.5314 - val_loss: 1.5444 - val_accuracy: 0.4624\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2868 - accuracy: 0.5389 - val_loss: 1.5458 - val_accuracy: 0.4520\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.2717 - accuracy: 0.5433 - val_loss: 1.5447 - val_accuracy: 0.4664\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2578 - accuracy: 0.5451 - val_loss: 1.5704 - val_accuracy: 0.4578\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5468 - accuracy: 0.4564\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0547 - accuracy: 0.2517 - val_loss: 1.8494 - val_accuracy: 0.3178\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8470 - accuracy: 0.3271 - val_loss: 1.8150 - val_accuracy: 0.3428\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7684 - accuracy: 0.3560 - val_loss: 1.7444 - val_accuracy: 0.3780\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7021 - accuracy: 0.3856 - val_loss: 1.6409 - val_accuracy: 0.4038\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6550 - accuracy: 0.4039 - val_loss: 1.6475 - val_accuracy: 0.4018\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6167 - accuracy: 0.4198 - val_loss: 1.6495 - val_accuracy: 0.4100\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5822 - accuracy: 0.4328 - val_loss: 1.5961 - val_accuracy: 0.4204\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.5587 - accuracy: 0.4423 - val_loss: 1.6167 - val_accuracy: 0.4228\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.5325 - accuracy: 0.4513 - val_loss: 1.5824 - val_accuracy: 0.4318\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5092 - accuracy: 0.4593 - val_loss: 1.5580 - val_accuracy: 0.4420\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4895 - accuracy: 0.4676 - val_loss: 1.5783 - val_accuracy: 0.4410\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.4706 - accuracy: 0.4720 - val_loss: 1.5559 - val_accuracy: 0.4426\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 7s 7ms/step - loss: 1.4502 - accuracy: 0.4798 - val_loss: 1.5296 - val_accuracy: 0.4540\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4319 - accuracy: 0.4861 - val_loss: 1.5297 - val_accuracy: 0.4572\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4176 - accuracy: 0.4957 - val_loss: 1.5068 - val_accuracy: 0.4688\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4017 - accuracy: 0.4993 - val_loss: 1.5293 - val_accuracy: 0.4622\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3786 - accuracy: 0.5075 - val_loss: 1.5025 - val_accuracy: 0.4632\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3674 - accuracy: 0.5125 - val_loss: 1.5226 - val_accuracy: 0.4732\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3548 - accuracy: 0.5155 - val_loss: 1.5824 - val_accuracy: 0.4612\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3380 - accuracy: 0.5223 - val_loss: 1.5194 - val_accuracy: 0.4648\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3258 - accuracy: 0.5231 - val_loss: 1.5257 - val_accuracy: 0.4660\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3128 - accuracy: 0.5285 - val_loss: 1.5156 - val_accuracy: 0.4746\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2992 - accuracy: 0.5357 - val_loss: 1.5853 - val_accuracy: 0.4562\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2814 - accuracy: 0.5417 - val_loss: 1.5415 - val_accuracy: 0.4678\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2691 - accuracy: 0.5452 - val_loss: 1.5254 - val_accuracy: 0.4720\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2540 - accuracy: 0.5485 - val_loss: 1.5311 - val_accuracy: 0.4650\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 7s 7ms/step - loss: 1.2417 - accuracy: 0.5524 - val_loss: 1.4874 - val_accuracy: 0.4832\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2343 - accuracy: 0.5575 - val_loss: 1.5482 - val_accuracy: 0.4708\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2167 - accuracy: 0.5599 - val_loss: 1.5201 - val_accuracy: 0.4794\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.2053 - accuracy: 0.5669 - val_loss: 1.5566 - val_accuracy: 0.4706\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.1968 - accuracy: 0.5707 - val_loss: 1.5849 - val_accuracy: 0.4764\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.1783 - accuracy: 0.5756 - val_loss: 1.5677 - val_accuracy: 0.4828\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.1679 - accuracy: 0.5788 - val_loss: 1.5284 - val_accuracy: 0.4804\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.1565 - accuracy: 0.5850 - val_loss: 1.5371 - val_accuracy: 0.4828\n",
      "Epoch 35/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.1456 - accuracy: 0.5870 - val_loss: 1.5633 - val_accuracy: 0.4856\n",
      "Epoch 36/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.1315 - accuracy: 0.5918 - val_loss: 1.5764 - val_accuracy: 0.4688\n",
      "Epoch 37/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.1225 - accuracy: 0.5958 - val_loss: 1.5891 - val_accuracy: 0.4838\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5070 - accuracy: 0.4793\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0403 - accuracy: 0.2539 - val_loss: 1.8239 - val_accuracy: 0.3426\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 7s 7ms/step - loss: 1.8178 - accuracy: 0.3386 - val_loss: 1.7302 - val_accuracy: 0.3782\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.7311 - accuracy: 0.3745 - val_loss: 1.7011 - val_accuracy: 0.3964\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.6649 - accuracy: 0.3989 - val_loss: 1.6398 - val_accuracy: 0.4014\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6251 - accuracy: 0.4121 - val_loss: 1.5997 - val_accuracy: 0.4228\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.5868 - accuracy: 0.4264 - val_loss: 1.6629 - val_accuracy: 0.4058\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.5597 - accuracy: 0.4392 - val_loss: 1.5846 - val_accuracy: 0.4272\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.5342 - accuracy: 0.4510 - val_loss: 1.5752 - val_accuracy: 0.4308\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 7s 7ms/step - loss: 1.5155 - accuracy: 0.4526 - val_loss: 1.5726 - val_accuracy: 0.4394\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4902 - accuracy: 0.4623 - val_loss: 1.5424 - val_accuracy: 0.4518\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.4734 - accuracy: 0.4711 - val_loss: 1.5677 - val_accuracy: 0.4436\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 9s 8ms/step - loss: 1.4552 - accuracy: 0.4759 - val_loss: 1.5321 - val_accuracy: 0.4532\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.4411 - accuracy: 0.4818 - val_loss: 1.5361 - val_accuracy: 0.4516\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 9s 8ms/step - loss: 1.4237 - accuracy: 0.4883 - val_loss: 1.5525 - val_accuracy: 0.4578\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.4089 - accuracy: 0.4919 - val_loss: 1.5247 - val_accuracy: 0.4620\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3924 - accuracy: 0.4986 - val_loss: 1.5598 - val_accuracy: 0.4514\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.3761 - accuracy: 0.5027 - val_loss: 1.5285 - val_accuracy: 0.4702\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3652 - accuracy: 0.5075 - val_loss: 1.5166 - val_accuracy: 0.4756\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3475 - accuracy: 0.5166 - val_loss: 1.5294 - val_accuracy: 0.4748\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3341 - accuracy: 0.5189 - val_loss: 1.5178 - val_accuracy: 0.4760\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.3180 - accuracy: 0.5262 - val_loss: 1.5644 - val_accuracy: 0.4600\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3069 - accuracy: 0.5279 - val_loss: 1.5238 - val_accuracy: 0.4762\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 7s 7ms/step - loss: 1.2905 - accuracy: 0.5343 - val_loss: 1.5462 - val_accuracy: 0.4712\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.2767 - accuracy: 0.5387 - val_loss: 1.5423 - val_accuracy: 0.4662\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2636 - accuracy: 0.5456 - val_loss: 1.5267 - val_accuracy: 0.4774\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2532 - accuracy: 0.5485 - val_loss: 1.5487 - val_accuracy: 0.4794\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2394 - accuracy: 0.5536 - val_loss: 1.5391 - val_accuracy: 0.4728\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2281 - accuracy: 0.5578 - val_loss: 1.5793 - val_accuracy: 0.4578\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 1.5539 - accuracy: 0.4620\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 8s 8ms/step - loss: 2.0419 - accuracy: 0.2581 - val_loss: 1.8086 - val_accuracy: 0.3494\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.8232 - accuracy: 0.3406 - val_loss: 1.8038 - val_accuracy: 0.3514\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 7s 7ms/step - loss: 1.7501 - accuracy: 0.3659 - val_loss: 1.8002 - val_accuracy: 0.3518\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 7s 7ms/step - loss: 1.6908 - accuracy: 0.3886 - val_loss: 1.6640 - val_accuracy: 0.3924\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6463 - accuracy: 0.4046 - val_loss: 1.6146 - val_accuracy: 0.4156\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6091 - accuracy: 0.4207 - val_loss: 1.6655 - val_accuracy: 0.4030\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 7s 7ms/step - loss: 1.5765 - accuracy: 0.4346 - val_loss: 1.6046 - val_accuracy: 0.4192\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.5472 - accuracy: 0.4469 - val_loss: 1.5795 - val_accuracy: 0.4304\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.5210 - accuracy: 0.4555 - val_loss: 1.6095 - val_accuracy: 0.4256\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.5017 - accuracy: 0.4599 - val_loss: 1.5499 - val_accuracy: 0.4486\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.4795 - accuracy: 0.4693 - val_loss: 1.5768 - val_accuracy: 0.4320\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.4612 - accuracy: 0.4756 - val_loss: 1.5331 - val_accuracy: 0.4452\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4455 - accuracy: 0.4809 - val_loss: 1.5230 - val_accuracy: 0.4544\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4244 - accuracy: 0.4886 - val_loss: 1.5367 - val_accuracy: 0.4534\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4051 - accuracy: 0.4964 - val_loss: 1.5588 - val_accuracy: 0.4496\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3925 - accuracy: 0.4997 - val_loss: 1.5339 - val_accuracy: 0.4486\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3773 - accuracy: 0.5076 - val_loss: 1.5208 - val_accuracy: 0.4682\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3638 - accuracy: 0.5113 - val_loss: 1.4951 - val_accuracy: 0.4720\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3447 - accuracy: 0.5176 - val_loss: 1.5257 - val_accuracy: 0.4582\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3313 - accuracy: 0.5235 - val_loss: 1.5348 - val_accuracy: 0.4710\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3131 - accuracy: 0.5293 - val_loss: 1.5615 - val_accuracy: 0.4484\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3015 - accuracy: 0.5337 - val_loss: 1.5424 - val_accuracy: 0.4708\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2880 - accuracy: 0.5389 - val_loss: 1.5481 - val_accuracy: 0.4710\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2729 - accuracy: 0.5440 - val_loss: 1.5545 - val_accuracy: 0.4628\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2606 - accuracy: 0.5474 - val_loss: 1.5156 - val_accuracy: 0.4694\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2487 - accuracy: 0.5516 - val_loss: 1.5495 - val_accuracy: 0.4620\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2374 - accuracy: 0.5566 - val_loss: 1.5876 - val_accuracy: 0.4506\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2240 - accuracy: 0.5607 - val_loss: 1.5651 - val_accuracy: 0.4658\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5104 - accuracy: 0.4719\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.1919 - accuracy: 0.1637 - val_loss: 2.0960 - val_accuracy: 0.1890\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.0878 - accuracy: 0.1824 - val_loss: 2.0697 - val_accuracy: 0.1980\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.0513 - accuracy: 0.1931 - val_loss: 2.1231 - val_accuracy: 0.1858\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.0396 - accuracy: 0.1922 - val_loss: 2.0657 - val_accuracy: 0.2084\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0254 - accuracy: 0.1945 - val_loss: 2.0996 - val_accuracy: 0.1968\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.0296 - accuracy: 0.1969 - val_loss: 2.0332 - val_accuracy: 0.2150\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0005 - accuracy: 0.2055 - val_loss: 2.0499 - val_accuracy: 0.2066\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9779 - accuracy: 0.2131 - val_loss: 2.0268 - val_accuracy: 0.2338\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9609 - accuracy: 0.2206 - val_loss: 2.1391 - val_accuracy: 0.2260\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9509 - accuracy: 0.2311 - val_loss: 2.0184 - val_accuracy: 0.2352\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9613 - accuracy: 0.2447 - val_loss: 1.9928 - val_accuracy: 0.2686\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9051 - accuracy: 0.2695 - val_loss: 1.9950 - val_accuracy: 0.2794\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8822 - accuracy: 0.2813 - val_loss: 1.9613 - val_accuracy: 0.2760\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9269 - accuracy: 0.2655 - val_loss: 2.0727 - val_accuracy: 0.2588\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8602 - accuracy: 0.2875 - val_loss: 1.8898 - val_accuracy: 0.2860\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8621 - accuracy: 0.2930 - val_loss: 1.9219 - val_accuracy: 0.3024\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 7s 7ms/step - loss: 1.8500 - accuracy: 0.2955 - val_loss: 1.9633 - val_accuracy: 0.2980\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8503 - accuracy: 0.2976 - val_loss: 1.8826 - val_accuracy: 0.3220\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8428 - accuracy: 0.3012 - val_loss: 1.9870 - val_accuracy: 0.3120\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8351 - accuracy: 0.3099 - val_loss: 1.9044 - val_accuracy: 0.3222\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.9250 - accuracy: 0.2869 - val_loss: 2.0063 - val_accuracy: 0.2694\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8683 - accuracy: 0.2844 - val_loss: 2.0298 - val_accuracy: 0.2948\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8287 - accuracy: 0.3019 - val_loss: 1.9780 - val_accuracy: 0.2892\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8192 - accuracy: 0.3096 - val_loss: 1.9635 - val_accuracy: 0.3014\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8347 - accuracy: 0.3104 - val_loss: 1.9777 - val_accuracy: 0.3122\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8183 - accuracy: 0.3079 - val_loss: 1.9256 - val_accuracy: 0.3186\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8024 - accuracy: 0.3192 - val_loss: 1.9597 - val_accuracy: 0.3116\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7916 - accuracy: 0.3271 - val_loss: 1.9087 - val_accuracy: 0.3228\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.8848 - accuracy: 0.3206\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.1781 - accuracy: 0.1684 - val_loss: 2.1185 - val_accuracy: 0.1950\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.0868 - accuracy: 0.1844 - val_loss: 2.0988 - val_accuracy: 0.2038\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.0694 - accuracy: 0.1926 - val_loss: 2.0655 - val_accuracy: 0.2196\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 7s 7ms/step - loss: 2.0470 - accuracy: 0.2002 - val_loss: 2.0833 - val_accuracy: 0.2230\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 7s 7ms/step - loss: 2.0579 - accuracy: 0.1964 - val_loss: 2.1188 - val_accuracy: 0.1892\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0870 - accuracy: 0.1850 - val_loss: 2.0988 - val_accuracy: 0.1816\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0554 - accuracy: 0.1943 - val_loss: 2.0805 - val_accuracy: 0.2030\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0351 - accuracy: 0.2010 - val_loss: 2.1260 - val_accuracy: 0.2092\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0270 - accuracy: 0.2069 - val_loss: 2.0788 - val_accuracy: 0.2028\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0169 - accuracy: 0.2122 - val_loss: 2.0998 - val_accuracy: 0.2136\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 2.0067 - accuracy: 0.2151 - val_loss: 2.1155 - val_accuracy: 0.2046\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0012 - accuracy: 0.2188 - val_loss: 2.1112 - val_accuracy: 0.2042\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0015 - accuracy: 0.2212 - val_loss: 2.1049 - val_accuracy: 0.2092\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.0541 - accuracy: 0.2152\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.1827 - accuracy: 0.1624 - val_loss: 2.1252 - val_accuracy: 0.1946\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0771 - accuracy: 0.1843 - val_loss: 2.0397 - val_accuracy: 0.1988\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0409 - accuracy: 0.2031 - val_loss: 2.0556 - val_accuracy: 0.2028\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.0137 - accuracy: 0.2074 - val_loss: 1.9837 - val_accuracy: 0.2348\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9765 - accuracy: 0.2303 - val_loss: 2.1510 - val_accuracy: 0.2400\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.9529 - accuracy: 0.2414 - val_loss: 2.0802 - val_accuracy: 0.2496\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9017 - accuracy: 0.2704 - val_loss: 1.9493 - val_accuracy: 0.2730\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8906 - accuracy: 0.2762 - val_loss: 1.9752 - val_accuracy: 0.3018\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8618 - accuracy: 0.2935 - val_loss: 1.9746 - val_accuracy: 0.2810\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8513 - accuracy: 0.3056 - val_loss: 1.9804 - val_accuracy: 0.3050\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8382 - accuracy: 0.3107 - val_loss: 1.9357 - val_accuracy: 0.3204\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8432 - accuracy: 0.3089 - val_loss: 1.9736 - val_accuracy: 0.2996\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8349 - accuracy: 0.3189 - val_loss: 1.8775 - val_accuracy: 0.3200\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8305 - accuracy: 0.3130 - val_loss: 2.0921 - val_accuracy: 0.3054\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8501 - accuracy: 0.3042 - val_loss: 1.9380 - val_accuracy: 0.3124\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8453 - accuracy: 0.3053 - val_loss: 1.9765 - val_accuracy: 0.2806\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8217 - accuracy: 0.3207 - val_loss: 1.8985 - val_accuracy: 0.3364\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8645 - accuracy: 0.2868 - val_loss: 1.8891 - val_accuracy: 0.3088\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8079 - accuracy: 0.3203 - val_loss: 1.9433 - val_accuracy: 0.3312\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7912 - accuracy: 0.3306 - val_loss: 1.9038 - val_accuracy: 0.3480\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8483 - accuracy: 0.2979 - val_loss: 1.9130 - val_accuracy: 0.3108\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8044 - accuracy: 0.3202 - val_loss: 1.9123 - val_accuracy: 0.3264\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 5.2685 - accuracy: 0.2952 - val_loss: 1.9154 - val_accuracy: 0.3184\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.8610 - accuracy: 0.3204\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 2.1891 - accuracy: 0.1604 - val_loss: 2.0745 - val_accuracy: 0.1878\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0851 - accuracy: 0.1754 - val_loss: 2.0768 - val_accuracy: 0.1784\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.0674 - accuracy: 0.1822 - val_loss: 2.1630 - val_accuracy: 0.1972\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.0383 - accuracy: 0.1946 - val_loss: 2.1033 - val_accuracy: 0.2018\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.0108 - accuracy: 0.2075 - val_loss: 2.0283 - val_accuracy: 0.2326\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9791 - accuracy: 0.2200 - val_loss: 2.0014 - val_accuracy: 0.2304\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9592 - accuracy: 0.2338 - val_loss: 2.0031 - val_accuracy: 0.2474\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.9435 - accuracy: 0.2422 - val_loss: 2.0704 - val_accuracy: 0.2476\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9451 - accuracy: 0.2424 - val_loss: 1.9599 - val_accuracy: 0.2464\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.2003 - accuracy: 0.2152 - val_loss: 2.0969 - val_accuracy: 0.1698\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.0228 - accuracy: 0.1937 - val_loss: 2.0514 - val_accuracy: 0.2188\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9823 - accuracy: 0.2210 - val_loss: 2.0453 - val_accuracy: 0.2308\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9646 - accuracy: 0.2284 - val_loss: 1.9955 - val_accuracy: 0.2472\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9562 - accuracy: 0.2366 - val_loss: 2.0724 - val_accuracy: 0.2378\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9601 - accuracy: 0.2342 - val_loss: 1.9674 - val_accuracy: 0.2512\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9838 - accuracy: 0.2236 - val_loss: 1.9967 - val_accuracy: 0.2326\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.9572 - accuracy: 0.2296 - val_loss: 2.0394 - val_accuracy: 0.2404\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9796 - accuracy: 0.2249 - val_loss: 2.3211 - val_accuracy: 0.2074\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.2992 - accuracy: 0.1070 - val_loss: 2.3203 - val_accuracy: 0.0978\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.9832 - accuracy: 0.2400\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.2232 - accuracy: 0.1518 - val_loss: 2.1378 - val_accuracy: 0.1792\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.0928 - accuracy: 0.1833 - val_loss: 2.1761 - val_accuracy: 0.1762\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.0302 - accuracy: 0.2164 - val_loss: 2.1902 - val_accuracy: 0.2334\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0510 - accuracy: 0.2054 - val_loss: 2.1079 - val_accuracy: 0.1948\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.0571 - accuracy: 0.1926 - val_loss: 2.0865 - val_accuracy: 0.2112\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.0398 - accuracy: 0.1946 - val_loss: 2.1172 - val_accuracy: 0.1802\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.0323 - accuracy: 0.2033 - val_loss: 2.0798 - val_accuracy: 0.1986\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.0124 - accuracy: 0.2094 - val_loss: 2.0398 - val_accuracy: 0.2212\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9996 - accuracy: 0.2214 - val_loss: 2.0722 - val_accuracy: 0.2276\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.9845 - accuracy: 0.2310 - val_loss: 2.0800 - val_accuracy: 0.2048\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.9816 - accuracy: 0.2356 - val_loss: 2.1248 - val_accuracy: 0.2434\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.9654 - accuracy: 0.2440 - val_loss: 2.1536 - val_accuracy: 0.2166\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.9977 - accuracy: 0.2230 - val_loss: 2.0946 - val_accuracy: 0.2084\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0117 - accuracy: 0.2172 - val_loss: 2.0433 - val_accuracy: 0.2336\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.9832 - accuracy: 0.2330 - val_loss: 2.0685 - val_accuracy: 0.2210\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.9771 - accuracy: 0.2356 - val_loss: 2.0671 - val_accuracy: 0.2264\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9732 - accuracy: 0.2342 - val_loss: 2.0748 - val_accuracy: 0.2398\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.9672 - accuracy: 0.2363 - val_loss: 2.0763 - val_accuracy: 0.2442\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.0410 - accuracy: 0.2249\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0505 - accuracy: 0.2467 - val_loss: 1.8280 - val_accuracy: 0.3286\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8449 - accuracy: 0.3280 - val_loss: 1.7264 - val_accuracy: 0.3664\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7605 - accuracy: 0.3629 - val_loss: 1.7055 - val_accuracy: 0.3782\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7061 - accuracy: 0.3828 - val_loss: 1.6525 - val_accuracy: 0.3992\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6579 - accuracy: 0.4015 - val_loss: 1.6663 - val_accuracy: 0.4024\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6204 - accuracy: 0.4166 - val_loss: 1.6473 - val_accuracy: 0.4054\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5899 - accuracy: 0.4252 - val_loss: 1.5835 - val_accuracy: 0.4274\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5567 - accuracy: 0.4378 - val_loss: 1.5711 - val_accuracy: 0.4304\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5319 - accuracy: 0.4489 - val_loss: 1.5453 - val_accuracy: 0.4378\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5057 - accuracy: 0.4597 - val_loss: 1.5510 - val_accuracy: 0.4388\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4859 - accuracy: 0.4664 - val_loss: 1.5517 - val_accuracy: 0.4412\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4681 - accuracy: 0.4724 - val_loss: 1.5294 - val_accuracy: 0.4510\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4476 - accuracy: 0.4786 - val_loss: 1.5295 - val_accuracy: 0.4524\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4277 - accuracy: 0.4871 - val_loss: 1.5274 - val_accuracy: 0.4560\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4123 - accuracy: 0.4896 - val_loss: 1.5363 - val_accuracy: 0.4494\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3974 - accuracy: 0.4984 - val_loss: 1.5156 - val_accuracy: 0.4514\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3836 - accuracy: 0.5013 - val_loss: 1.5104 - val_accuracy: 0.4606\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3666 - accuracy: 0.5092 - val_loss: 1.5268 - val_accuracy: 0.4620\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3562 - accuracy: 0.5108 - val_loss: 1.5020 - val_accuracy: 0.4702\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3379 - accuracy: 0.5195 - val_loss: 1.5145 - val_accuracy: 0.4646\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3258 - accuracy: 0.5211 - val_loss: 1.5268 - val_accuracy: 0.4600\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3153 - accuracy: 0.5287 - val_loss: 1.4837 - val_accuracy: 0.4748\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3047 - accuracy: 0.5315 - val_loss: 1.5297 - val_accuracy: 0.4670\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2927 - accuracy: 0.5344 - val_loss: 1.4990 - val_accuracy: 0.4748\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2790 - accuracy: 0.5384 - val_loss: 1.4976 - val_accuracy: 0.4766\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2651 - accuracy: 0.5447 - val_loss: 1.4848 - val_accuracy: 0.4888\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2530 - accuracy: 0.5501 - val_loss: 1.4896 - val_accuracy: 0.4782\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2448 - accuracy: 0.5510 - val_loss: 1.4990 - val_accuracy: 0.4798\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2342 - accuracy: 0.5556 - val_loss: 1.4982 - val_accuracy: 0.4796\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2207 - accuracy: 0.5594 - val_loss: 1.5714 - val_accuracy: 0.4628\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2094 - accuracy: 0.5634 - val_loss: 1.5073 - val_accuracy: 0.4802\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2030 - accuracy: 0.5664 - val_loss: 1.5214 - val_accuracy: 0.4682\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.4974 - accuracy: 0.4699\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0761 - accuracy: 0.2532 - val_loss: 1.8464 - val_accuracy: 0.3272\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8453 - accuracy: 0.3332 - val_loss: 1.7969 - val_accuracy: 0.3470\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7648 - accuracy: 0.3591 - val_loss: 1.6811 - val_accuracy: 0.3844\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7003 - accuracy: 0.3845 - val_loss: 1.6623 - val_accuracy: 0.3924\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6546 - accuracy: 0.4033 - val_loss: 1.6526 - val_accuracy: 0.4038\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6166 - accuracy: 0.4167 - val_loss: 1.6490 - val_accuracy: 0.4058\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5891 - accuracy: 0.4256 - val_loss: 1.5937 - val_accuracy: 0.4266\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5577 - accuracy: 0.4372 - val_loss: 1.5957 - val_accuracy: 0.4224\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5341 - accuracy: 0.4467 - val_loss: 1.5813 - val_accuracy: 0.4310\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5117 - accuracy: 0.4552 - val_loss: 1.5566 - val_accuracy: 0.4380\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4902 - accuracy: 0.4644 - val_loss: 1.5621 - val_accuracy: 0.4384\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4742 - accuracy: 0.4692 - val_loss: 1.5629 - val_accuracy: 0.4422\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4515 - accuracy: 0.4798 - val_loss: 1.5401 - val_accuracy: 0.4476\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4375 - accuracy: 0.4837 - val_loss: 1.5334 - val_accuracy: 0.4504\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4224 - accuracy: 0.4875 - val_loss: 1.5298 - val_accuracy: 0.4514\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4071 - accuracy: 0.4934 - val_loss: 1.5295 - val_accuracy: 0.4530\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3923 - accuracy: 0.5027 - val_loss: 1.5367 - val_accuracy: 0.4518\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3817 - accuracy: 0.5032 - val_loss: 1.5457 - val_accuracy: 0.4480\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3670 - accuracy: 0.5103 - val_loss: 1.5300 - val_accuracy: 0.4602\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3526 - accuracy: 0.5154 - val_loss: 1.5322 - val_accuracy: 0.4554\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3391 - accuracy: 0.5210 - val_loss: 1.5474 - val_accuracy: 0.4546\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3268 - accuracy: 0.5234 - val_loss: 1.5544 - val_accuracy: 0.4488\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3173 - accuracy: 0.5269 - val_loss: 1.5685 - val_accuracy: 0.4524\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3029 - accuracy: 0.5368 - val_loss: 1.5427 - val_accuracy: 0.4586\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2910 - accuracy: 0.5388 - val_loss: 1.5410 - val_accuracy: 0.4628\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2836 - accuracy: 0.5415 - val_loss: 1.5528 - val_accuracy: 0.4546\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5502 - accuracy: 0.4560\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.0837 - accuracy: 0.2449 - val_loss: 1.8479 - val_accuracy: 0.3176\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8644 - accuracy: 0.3273 - val_loss: 1.7727 - val_accuracy: 0.3636\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7772 - accuracy: 0.3549 - val_loss: 1.7248 - val_accuracy: 0.3718\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7151 - accuracy: 0.3786 - val_loss: 1.6447 - val_accuracy: 0.4072\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6678 - accuracy: 0.3965 - val_loss: 1.6731 - val_accuracy: 0.4008\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6252 - accuracy: 0.4149 - val_loss: 1.6431 - val_accuracy: 0.4046\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5893 - accuracy: 0.4272 - val_loss: 1.6006 - val_accuracy: 0.4206\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5617 - accuracy: 0.4370 - val_loss: 1.5852 - val_accuracy: 0.4212\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5377 - accuracy: 0.4477 - val_loss: 1.5771 - val_accuracy: 0.4298\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5140 - accuracy: 0.4564 - val_loss: 1.5653 - val_accuracy: 0.4368\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4959 - accuracy: 0.4622 - val_loss: 1.5882 - val_accuracy: 0.4316\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4799 - accuracy: 0.4692 - val_loss: 1.5613 - val_accuracy: 0.4422\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4546 - accuracy: 0.4779 - val_loss: 1.5669 - val_accuracy: 0.4382\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4390 - accuracy: 0.4819 - val_loss: 1.5615 - val_accuracy: 0.4460\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4218 - accuracy: 0.4900 - val_loss: 1.5455 - val_accuracy: 0.4480\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4076 - accuracy: 0.4957 - val_loss: 1.5389 - val_accuracy: 0.4564\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3917 - accuracy: 0.5009 - val_loss: 1.5180 - val_accuracy: 0.4492\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3754 - accuracy: 0.5065 - val_loss: 1.5278 - val_accuracy: 0.4584\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3625 - accuracy: 0.5136 - val_loss: 1.5349 - val_accuracy: 0.4566\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3439 - accuracy: 0.5175 - val_loss: 1.5530 - val_accuracy: 0.4532\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3319 - accuracy: 0.5222 - val_loss: 1.5345 - val_accuracy: 0.4592\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3208 - accuracy: 0.5268 - val_loss: 1.5483 - val_accuracy: 0.4598\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3053 - accuracy: 0.5300 - val_loss: 1.5326 - val_accuracy: 0.4600\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2931 - accuracy: 0.5363 - val_loss: 1.5623 - val_accuracy: 0.4596\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2806 - accuracy: 0.5412 - val_loss: 1.5157 - val_accuracy: 0.4694\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2711 - accuracy: 0.5449 - val_loss: 1.5414 - val_accuracy: 0.4628\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2562 - accuracy: 0.5517 - val_loss: 1.5241 - val_accuracy: 0.4712\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2441 - accuracy: 0.5557 - val_loss: 1.5769 - val_accuracy: 0.4598\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2330 - accuracy: 0.5567 - val_loss: 1.5215 - val_accuracy: 0.4742\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2211 - accuracy: 0.5617 - val_loss: 1.5442 - val_accuracy: 0.4604\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.2119 - accuracy: 0.5638 - val_loss: 1.5607 - val_accuracy: 0.4692\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.1973 - accuracy: 0.5699 - val_loss: 1.5386 - val_accuracy: 0.4664\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.1905 - accuracy: 0.5721 - val_loss: 1.5370 - val_accuracy: 0.4770\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.1791 - accuracy: 0.5774 - val_loss: 1.5460 - val_accuracy: 0.4654\n",
      "Epoch 35/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.1683 - accuracy: 0.5783 - val_loss: 1.5646 - val_accuracy: 0.4680\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.4990 - accuracy: 0.4722\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.0598 - accuracy: 0.2484 - val_loss: 1.8213 - val_accuracy: 0.3366\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8485 - accuracy: 0.3284 - val_loss: 1.7701 - val_accuracy: 0.3522\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7660 - accuracy: 0.3610 - val_loss: 1.7316 - val_accuracy: 0.3770\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7079 - accuracy: 0.3802 - val_loss: 1.6727 - val_accuracy: 0.3980\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6625 - accuracy: 0.3989 - val_loss: 1.6532 - val_accuracy: 0.4050\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6238 - accuracy: 0.4128 - val_loss: 1.6820 - val_accuracy: 0.3934\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5911 - accuracy: 0.4260 - val_loss: 1.6296 - val_accuracy: 0.4052\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5672 - accuracy: 0.4344 - val_loss: 1.5785 - val_accuracy: 0.4286\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5409 - accuracy: 0.4444 - val_loss: 1.5917 - val_accuracy: 0.4256\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5173 - accuracy: 0.4524 - val_loss: 1.5601 - val_accuracy: 0.4370\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4941 - accuracy: 0.4619 - val_loss: 1.5722 - val_accuracy: 0.4348\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4797 - accuracy: 0.4646 - val_loss: 1.5631 - val_accuracy: 0.4418\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4634 - accuracy: 0.4696 - val_loss: 1.5331 - val_accuracy: 0.4562\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4440 - accuracy: 0.4772 - val_loss: 1.5631 - val_accuracy: 0.4442\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4310 - accuracy: 0.4835 - val_loss: 1.5346 - val_accuracy: 0.4474\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4137 - accuracy: 0.4905 - val_loss: 1.5591 - val_accuracy: 0.4420\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4006 - accuracy: 0.4942 - val_loss: 1.5193 - val_accuracy: 0.4556\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3857 - accuracy: 0.5009 - val_loss: 1.5210 - val_accuracy: 0.4598\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3721 - accuracy: 0.5068 - val_loss: 1.5487 - val_accuracy: 0.4584\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3584 - accuracy: 0.5106 - val_loss: 1.5119 - val_accuracy: 0.4640\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3464 - accuracy: 0.5151 - val_loss: 1.5508 - val_accuracy: 0.4530\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3338 - accuracy: 0.5192 - val_loss: 1.5086 - val_accuracy: 0.4684\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3153 - accuracy: 0.5257 - val_loss: 1.5231 - val_accuracy: 0.4712\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3076 - accuracy: 0.5261 - val_loss: 1.5452 - val_accuracy: 0.4600\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2915 - accuracy: 0.5357 - val_loss: 1.5469 - val_accuracy: 0.4624\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2842 - accuracy: 0.5359 - val_loss: 1.4961 - val_accuracy: 0.4794\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2689 - accuracy: 0.5423 - val_loss: 1.5132 - val_accuracy: 0.4734\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2609 - accuracy: 0.5446 - val_loss: 1.5542 - val_accuracy: 0.4650\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2495 - accuracy: 0.5508 - val_loss: 1.5138 - val_accuracy: 0.4712\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2362 - accuracy: 0.5556 - val_loss: 1.5450 - val_accuracy: 0.4674\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2280 - accuracy: 0.5566 - val_loss: 1.5390 - val_accuracy: 0.4738\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2183 - accuracy: 0.5617 - val_loss: 1.5070 - val_accuracy: 0.4732\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2054 - accuracy: 0.5670 - val_loss: 1.5304 - val_accuracy: 0.4762\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.1945 - accuracy: 0.5674 - val_loss: 1.5772 - val_accuracy: 0.4574\n",
      "Epoch 35/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.1883 - accuracy: 0.5722 - val_loss: 1.5447 - val_accuracy: 0.4734\n",
      "Epoch 36/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.1770 - accuracy: 0.5773 - val_loss: 1.5338 - val_accuracy: 0.4762\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5315 - accuracy: 0.4651\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0807 - accuracy: 0.2451 - val_loss: 1.8313 - val_accuracy: 0.3328\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8640 - accuracy: 0.3224 - val_loss: 1.7740 - val_accuracy: 0.3628\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7772 - accuracy: 0.3534 - val_loss: 1.7396 - val_accuracy: 0.3764\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7180 - accuracy: 0.3770 - val_loss: 1.6848 - val_accuracy: 0.3894\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6716 - accuracy: 0.3947 - val_loss: 1.6378 - val_accuracy: 0.4120\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6335 - accuracy: 0.4116 - val_loss: 1.6518 - val_accuracy: 0.4098\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5977 - accuracy: 0.4236 - val_loss: 1.6256 - val_accuracy: 0.4176\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5707 - accuracy: 0.4338 - val_loss: 1.5901 - val_accuracy: 0.4254\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5467 - accuracy: 0.4442 - val_loss: 1.5726 - val_accuracy: 0.4340\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5283 - accuracy: 0.4509 - val_loss: 1.5637 - val_accuracy: 0.4332\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5033 - accuracy: 0.4608 - val_loss: 1.5683 - val_accuracy: 0.4408\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4859 - accuracy: 0.4663 - val_loss: 1.5420 - val_accuracy: 0.4492\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4670 - accuracy: 0.4726 - val_loss: 1.5384 - val_accuracy: 0.4520\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4485 - accuracy: 0.4765 - val_loss: 1.5739 - val_accuracy: 0.4374\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4339 - accuracy: 0.4848 - val_loss: 1.5337 - val_accuracy: 0.4534\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4158 - accuracy: 0.4921 - val_loss: 1.5593 - val_accuracy: 0.4426\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4013 - accuracy: 0.4975 - val_loss: 1.5156 - val_accuracy: 0.4630\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3882 - accuracy: 0.4998 - val_loss: 1.4979 - val_accuracy: 0.4712\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3774 - accuracy: 0.5029 - val_loss: 1.5220 - val_accuracy: 0.4666\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3606 - accuracy: 0.5138 - val_loss: 1.5115 - val_accuracy: 0.4698\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3469 - accuracy: 0.5172 - val_loss: 1.5772 - val_accuracy: 0.4424\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3321 - accuracy: 0.5206 - val_loss: 1.5343 - val_accuracy: 0.4604\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3222 - accuracy: 0.5251 - val_loss: 1.5517 - val_accuracy: 0.4620\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3075 - accuracy: 0.5310 - val_loss: 1.5160 - val_accuracy: 0.4684\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2964 - accuracy: 0.5350 - val_loss: 1.5269 - val_accuracy: 0.4682\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2887 - accuracy: 0.5396 - val_loss: 1.4981 - val_accuracy: 0.4754\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2734 - accuracy: 0.5412 - val_loss: 1.5548 - val_accuracy: 0.4648\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2655 - accuracy: 0.5457 - val_loss: 1.5264 - val_accuracy: 0.4740\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5062 - accuracy: 0.4672\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.4138 - accuracy: 0.1632 - val_loss: 1.9912 - val_accuracy: 0.2764\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.1299 - accuracy: 0.2285 - val_loss: 1.9071 - val_accuracy: 0.3124\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.0017 - accuracy: 0.2701 - val_loss: 1.8888 - val_accuracy: 0.3244\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9232 - accuracy: 0.2953 - val_loss: 1.8310 - val_accuracy: 0.3502\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8609 - accuracy: 0.3204 - val_loss: 1.8365 - val_accuracy: 0.3626\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8134 - accuracy: 0.3378 - val_loss: 1.7996 - val_accuracy: 0.3784\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7745 - accuracy: 0.3545 - val_loss: 1.7700 - val_accuracy: 0.3844\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7414 - accuracy: 0.3687 - val_loss: 1.7561 - val_accuracy: 0.3962\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7115 - accuracy: 0.3783 - val_loss: 1.7567 - val_accuracy: 0.3960\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6857 - accuracy: 0.3898 - val_loss: 1.7512 - val_accuracy: 0.4052\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6639 - accuracy: 0.4006 - val_loss: 1.7281 - val_accuracy: 0.4124\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6441 - accuracy: 0.4082 - val_loss: 1.7395 - val_accuracy: 0.4104\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6279 - accuracy: 0.4136 - val_loss: 1.7100 - val_accuracy: 0.4200\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6104 - accuracy: 0.4235 - val_loss: 1.7236 - val_accuracy: 0.4198\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5986 - accuracy: 0.4239 - val_loss: 1.6896 - val_accuracy: 0.4294\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5815 - accuracy: 0.4343 - val_loss: 1.7120 - val_accuracy: 0.4282\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5661 - accuracy: 0.4383 - val_loss: 1.7186 - val_accuracy: 0.4244\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5576 - accuracy: 0.4454 - val_loss: 1.7214 - val_accuracy: 0.4340\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5448 - accuracy: 0.4494 - val_loss: 1.7247 - val_accuracy: 0.4408\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5313 - accuracy: 0.4524 - val_loss: 1.7179 - val_accuracy: 0.4410\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5214 - accuracy: 0.4569 - val_loss: 1.7293 - val_accuracy: 0.4326\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5062 - accuracy: 0.4603 - val_loss: 1.7080 - val_accuracy: 0.4434\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4961 - accuracy: 0.4655 - val_loss: 1.7295 - val_accuracy: 0.4398\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4851 - accuracy: 0.4691 - val_loss: 1.7272 - val_accuracy: 0.4452\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4762 - accuracy: 0.4704 - val_loss: 1.7206 - val_accuracy: 0.4484\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.7178 - accuracy: 0.4209\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.4820 - accuracy: 0.1553 - val_loss: 2.0264 - val_accuracy: 0.2646\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.1359 - accuracy: 0.2262 - val_loss: 1.9096 - val_accuracy: 0.3162\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.0049 - accuracy: 0.2651 - val_loss: 1.8721 - val_accuracy: 0.3280\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9235 - accuracy: 0.2937 - val_loss: 1.8585 - val_accuracy: 0.3502\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8635 - accuracy: 0.3207 - val_loss: 1.8705 - val_accuracy: 0.3558\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8184 - accuracy: 0.3354 - val_loss: 1.8265 - val_accuracy: 0.3658\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7776 - accuracy: 0.3536 - val_loss: 1.8263 - val_accuracy: 0.3744\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7499 - accuracy: 0.3648 - val_loss: 1.7984 - val_accuracy: 0.3830\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7213 - accuracy: 0.3749 - val_loss: 1.8014 - val_accuracy: 0.3818\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6921 - accuracy: 0.3876 - val_loss: 1.7639 - val_accuracy: 0.4032\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6723 - accuracy: 0.3969 - val_loss: 1.7491 - val_accuracy: 0.4084\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6492 - accuracy: 0.4068 - val_loss: 1.7694 - val_accuracy: 0.4106\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6306 - accuracy: 0.4112 - val_loss: 1.7481 - val_accuracy: 0.4156\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6121 - accuracy: 0.4199 - val_loss: 1.7590 - val_accuracy: 0.4146\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5957 - accuracy: 0.4256 - val_loss: 1.7411 - val_accuracy: 0.4190\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5792 - accuracy: 0.4336 - val_loss: 1.7357 - val_accuracy: 0.4286\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5646 - accuracy: 0.4419 - val_loss: 1.7643 - val_accuracy: 0.4204\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5526 - accuracy: 0.4460 - val_loss: 1.7454 - val_accuracy: 0.4278\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5392 - accuracy: 0.4477 - val_loss: 1.7728 - val_accuracy: 0.4310\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5253 - accuracy: 0.4535 - val_loss: 1.7367 - val_accuracy: 0.4284\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5158 - accuracy: 0.4559 - val_loss: 1.7759 - val_accuracy: 0.4284\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5055 - accuracy: 0.4621 - val_loss: 1.7595 - val_accuracy: 0.4358\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4910 - accuracy: 0.4667 - val_loss: 1.7963 - val_accuracy: 0.4260\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4837 - accuracy: 0.4719 - val_loss: 1.7554 - val_accuracy: 0.4372\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4729 - accuracy: 0.4714 - val_loss: 1.7744 - val_accuracy: 0.4406\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4631 - accuracy: 0.4768 - val_loss: 1.7268 - val_accuracy: 0.4374\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4534 - accuracy: 0.4832 - val_loss: 1.7681 - val_accuracy: 0.4348\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4461 - accuracy: 0.4826 - val_loss: 1.7513 - val_accuracy: 0.4356\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4335 - accuracy: 0.4879 - val_loss: 1.7743 - val_accuracy: 0.4496\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4260 - accuracy: 0.4914 - val_loss: 1.8168 - val_accuracy: 0.4312\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4200 - accuracy: 0.4919 - val_loss: 1.8017 - val_accuracy: 0.4468\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4093 - accuracy: 0.4972 - val_loss: 1.7958 - val_accuracy: 0.4474\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4010 - accuracy: 0.5008 - val_loss: 1.8649 - val_accuracy: 0.4396\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3904 - accuracy: 0.5047 - val_loss: 1.8034 - val_accuracy: 0.4372\n",
      "Epoch 35/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3836 - accuracy: 0.5045 - val_loss: 1.8054 - val_accuracy: 0.4466\n",
      "Epoch 36/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3750 - accuracy: 0.5091 - val_loss: 1.8199 - val_accuracy: 0.4538\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.7479 - accuracy: 0.4331\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.4107 - accuracy: 0.1608 - val_loss: 1.9962 - val_accuracy: 0.2718\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.1305 - accuracy: 0.2262 - val_loss: 1.9012 - val_accuracy: 0.3156\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.0125 - accuracy: 0.2630 - val_loss: 1.8664 - val_accuracy: 0.3394\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9352 - accuracy: 0.2943 - val_loss: 1.8251 - val_accuracy: 0.3510\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8818 - accuracy: 0.3122 - val_loss: 1.8186 - val_accuracy: 0.3610\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8351 - accuracy: 0.3356 - val_loss: 1.8048 - val_accuracy: 0.3678\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8041 - accuracy: 0.3471 - val_loss: 1.7695 - val_accuracy: 0.3816\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7666 - accuracy: 0.3600 - val_loss: 1.7676 - val_accuracy: 0.3876\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7327 - accuracy: 0.3747 - val_loss: 1.7505 - val_accuracy: 0.4012\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7121 - accuracy: 0.3834 - val_loss: 1.7699 - val_accuracy: 0.4012\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6917 - accuracy: 0.3903 - val_loss: 1.7485 - val_accuracy: 0.4060\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6711 - accuracy: 0.3976 - val_loss: 1.7350 - val_accuracy: 0.4162\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6585 - accuracy: 0.4026 - val_loss: 1.7276 - val_accuracy: 0.4138\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6393 - accuracy: 0.4125 - val_loss: 1.7454 - val_accuracy: 0.4136\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6231 - accuracy: 0.4184 - val_loss: 1.7443 - val_accuracy: 0.4222\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6058 - accuracy: 0.4246 - val_loss: 1.7489 - val_accuracy: 0.4246\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5968 - accuracy: 0.4287 - val_loss: 1.7157 - val_accuracy: 0.4304\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5814 - accuracy: 0.4348 - val_loss: 1.7321 - val_accuracy: 0.4300\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5668 - accuracy: 0.4409 - val_loss: 1.7249 - val_accuracy: 0.4300\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5571 - accuracy: 0.4449 - val_loss: 1.7315 - val_accuracy: 0.4324\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5474 - accuracy: 0.4494 - val_loss: 1.7570 - val_accuracy: 0.4204\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5341 - accuracy: 0.4520 - val_loss: 1.7400 - val_accuracy: 0.4440\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5249 - accuracy: 0.4561 - val_loss: 1.7422 - val_accuracy: 0.4298\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5133 - accuracy: 0.4602 - val_loss: 1.7521 - val_accuracy: 0.4388\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5040 - accuracy: 0.4626 - val_loss: 1.7462 - val_accuracy: 0.4432\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4932 - accuracy: 0.4689 - val_loss: 1.7259 - val_accuracy: 0.4448\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4842 - accuracy: 0.4721 - val_loss: 1.7546 - val_accuracy: 0.4358\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.7105 - accuracy: 0.4258\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.4676 - accuracy: 0.1590 - val_loss: 1.9760 - val_accuracy: 0.2798\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.1248 - accuracy: 0.2300 - val_loss: 1.9287 - val_accuracy: 0.3136\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9956 - accuracy: 0.2693 - val_loss: 1.8968 - val_accuracy: 0.3324\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9155 - accuracy: 0.2984 - val_loss: 1.8571 - val_accuracy: 0.3378\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8538 - accuracy: 0.3224 - val_loss: 1.8303 - val_accuracy: 0.3534\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8135 - accuracy: 0.3402 - val_loss: 1.8071 - val_accuracy: 0.3666\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7763 - accuracy: 0.3491 - val_loss: 1.7947 - val_accuracy: 0.3786\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7433 - accuracy: 0.3687 - val_loss: 1.7810 - val_accuracy: 0.3838\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7137 - accuracy: 0.3809 - val_loss: 1.7361 - val_accuracy: 0.3956\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6874 - accuracy: 0.3877 - val_loss: 1.8053 - val_accuracy: 0.3896\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6690 - accuracy: 0.3949 - val_loss: 1.7322 - val_accuracy: 0.4050\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6480 - accuracy: 0.4054 - val_loss: 1.7455 - val_accuracy: 0.3982\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6317 - accuracy: 0.4118 - val_loss: 1.7416 - val_accuracy: 0.4106\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6117 - accuracy: 0.4168 - val_loss: 1.7420 - val_accuracy: 0.4130\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5965 - accuracy: 0.4247 - val_loss: 1.7123 - val_accuracy: 0.4186\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5819 - accuracy: 0.4307 - val_loss: 1.7171 - val_accuracy: 0.4238\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5666 - accuracy: 0.4345 - val_loss: 1.7450 - val_accuracy: 0.4256\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5546 - accuracy: 0.4386 - val_loss: 1.7010 - val_accuracy: 0.4236\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5402 - accuracy: 0.4442 - val_loss: 1.7355 - val_accuracy: 0.4280\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5292 - accuracy: 0.4496 - val_loss: 1.7262 - val_accuracy: 0.4296\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5157 - accuracy: 0.4563 - val_loss: 1.7611 - val_accuracy: 0.4230\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5100 - accuracy: 0.4557 - val_loss: 1.7092 - val_accuracy: 0.4370\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4914 - accuracy: 0.4645 - val_loss: 1.7076 - val_accuracy: 0.4398\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4859 - accuracy: 0.4653 - val_loss: 1.7123 - val_accuracy: 0.4372\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4732 - accuracy: 0.4718 - val_loss: 1.7364 - val_accuracy: 0.4350\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4681 - accuracy: 0.4725 - val_loss: 1.7313 - val_accuracy: 0.4440\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4581 - accuracy: 0.4794 - val_loss: 1.7285 - val_accuracy: 0.4376\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4502 - accuracy: 0.4813 - val_loss: 1.7387 - val_accuracy: 0.4398\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.7450 - accuracy: 0.4259\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.5019 - accuracy: 0.1552 - val_loss: 2.0059 - val_accuracy: 0.2556\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.1532 - accuracy: 0.2262 - val_loss: 1.9238 - val_accuracy: 0.3032\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.0257 - accuracy: 0.2621 - val_loss: 1.8912 - val_accuracy: 0.3220\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9404 - accuracy: 0.2919 - val_loss: 1.8809 - val_accuracy: 0.3438\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8912 - accuracy: 0.3101 - val_loss: 1.8194 - val_accuracy: 0.3680\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8446 - accuracy: 0.3263 - val_loss: 1.7984 - val_accuracy: 0.3702\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8015 - accuracy: 0.3473 - val_loss: 1.7948 - val_accuracy: 0.3782\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7725 - accuracy: 0.3536 - val_loss: 1.7559 - val_accuracy: 0.3850\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7375 - accuracy: 0.3702 - val_loss: 1.7716 - val_accuracy: 0.3902\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7128 - accuracy: 0.3770 - val_loss: 1.7677 - val_accuracy: 0.3936\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6934 - accuracy: 0.3850 - val_loss: 1.7567 - val_accuracy: 0.3994\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6693 - accuracy: 0.3979 - val_loss: 1.7470 - val_accuracy: 0.4012\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6510 - accuracy: 0.4030 - val_loss: 1.7406 - val_accuracy: 0.4082\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6329 - accuracy: 0.4110 - val_loss: 1.7519 - val_accuracy: 0.4106\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6179 - accuracy: 0.4176 - val_loss: 1.7670 - val_accuracy: 0.4100\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5963 - accuracy: 0.4239 - val_loss: 1.7798 - val_accuracy: 0.4176\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5843 - accuracy: 0.4301 - val_loss: 1.7721 - val_accuracy: 0.4170\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5727 - accuracy: 0.4349 - val_loss: 1.7315 - val_accuracy: 0.4282\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5599 - accuracy: 0.4421 - val_loss: 1.7565 - val_accuracy: 0.4296\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5461 - accuracy: 0.4447 - val_loss: 1.7740 - val_accuracy: 0.4216\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5332 - accuracy: 0.4493 - val_loss: 1.7672 - val_accuracy: 0.4230\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5281 - accuracy: 0.4517 - val_loss: 1.7587 - val_accuracy: 0.4302\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5109 - accuracy: 0.4614 - val_loss: 1.7596 - val_accuracy: 0.4332\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5023 - accuracy: 0.4614 - val_loss: 1.7445 - val_accuracy: 0.4332\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4929 - accuracy: 0.4664 - val_loss: 1.7576 - val_accuracy: 0.4350\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4825 - accuracy: 0.4706 - val_loss: 1.7425 - val_accuracy: 0.4396\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4684 - accuracy: 0.4714 - val_loss: 1.7574 - val_accuracy: 0.4396\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4647 - accuracy: 0.4742 - val_loss: 1.7908 - val_accuracy: 0.4376\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.7482 - accuracy: 0.4198\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.1246 - accuracy: 0.2262 - val_loss: 1.9203 - val_accuracy: 0.2992\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9083 - accuracy: 0.3005 - val_loss: 1.8270 - val_accuracy: 0.3356\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8293 - accuracy: 0.3307 - val_loss: 1.7898 - val_accuracy: 0.3446\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7842 - accuracy: 0.3535 - val_loss: 1.7459 - val_accuracy: 0.3658\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7407 - accuracy: 0.3669 - val_loss: 1.7235 - val_accuracy: 0.3770\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7066 - accuracy: 0.3819 - val_loss: 1.6907 - val_accuracy: 0.3854\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6755 - accuracy: 0.3954 - val_loss: 1.6648 - val_accuracy: 0.3994\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6486 - accuracy: 0.4069 - val_loss: 1.6626 - val_accuracy: 0.3952\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6237 - accuracy: 0.4155 - val_loss: 1.6409 - val_accuracy: 0.4096\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6043 - accuracy: 0.4224 - val_loss: 1.6289 - val_accuracy: 0.4120\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5816 - accuracy: 0.4293 - val_loss: 1.6347 - val_accuracy: 0.4218\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5660 - accuracy: 0.4372 - val_loss: 1.6160 - val_accuracy: 0.4192\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5502 - accuracy: 0.4424 - val_loss: 1.6014 - val_accuracy: 0.4208\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5354 - accuracy: 0.4497 - val_loss: 1.6056 - val_accuracy: 0.4278\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5205 - accuracy: 0.4553 - val_loss: 1.5871 - val_accuracy: 0.4316\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5099 - accuracy: 0.4560 - val_loss: 1.5740 - val_accuracy: 0.4390\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4938 - accuracy: 0.4648 - val_loss: 1.5716 - val_accuracy: 0.4348\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4813 - accuracy: 0.4671 - val_loss: 1.5941 - val_accuracy: 0.4302\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4718 - accuracy: 0.4696 - val_loss: 1.5730 - val_accuracy: 0.4406\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4596 - accuracy: 0.4769 - val_loss: 1.5669 - val_accuracy: 0.4390\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4513 - accuracy: 0.4776 - val_loss: 1.5801 - val_accuracy: 0.4392\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4385 - accuracy: 0.4836 - val_loss: 1.5562 - val_accuracy: 0.4456\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4269 - accuracy: 0.4882 - val_loss: 1.5782 - val_accuracy: 0.4398\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4164 - accuracy: 0.4931 - val_loss: 1.5456 - val_accuracy: 0.4510\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4047 - accuracy: 0.4961 - val_loss: 1.5510 - val_accuracy: 0.4524\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3989 - accuracy: 0.4996 - val_loss: 1.5538 - val_accuracy: 0.4484\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3868 - accuracy: 0.5061 - val_loss: 1.5504 - val_accuracy: 0.4570\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3787 - accuracy: 0.5077 - val_loss: 1.5411 - val_accuracy: 0.4550\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3726 - accuracy: 0.5080 - val_loss: 1.5450 - val_accuracy: 0.4540\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3616 - accuracy: 0.5110 - val_loss: 1.5627 - val_accuracy: 0.4502\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3519 - accuracy: 0.5177 - val_loss: 1.5394 - val_accuracy: 0.4570\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3444 - accuracy: 0.5177 - val_loss: 1.5779 - val_accuracy: 0.4442\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3387 - accuracy: 0.5221 - val_loss: 1.5457 - val_accuracy: 0.4542\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3297 - accuracy: 0.5244 - val_loss: 1.5437 - val_accuracy: 0.4570\n",
      "Epoch 35/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3220 - accuracy: 0.5279 - val_loss: 1.5428 - val_accuracy: 0.4560\n",
      "Epoch 36/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3149 - accuracy: 0.5324 - val_loss: 1.5494 - val_accuracy: 0.4596\n",
      "Epoch 37/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3062 - accuracy: 0.5332 - val_loss: 1.5423 - val_accuracy: 0.4646\n",
      "Epoch 38/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2964 - accuracy: 0.5373 - val_loss: 1.5344 - val_accuracy: 0.4618\n",
      "Epoch 39/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2887 - accuracy: 0.5423 - val_loss: 1.5402 - val_accuracy: 0.4550\n",
      "Epoch 40/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2847 - accuracy: 0.5421 - val_loss: 1.5611 - val_accuracy: 0.4570\n",
      "Epoch 41/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2753 - accuracy: 0.5425 - val_loss: 1.5469 - val_accuracy: 0.4592\n",
      "Epoch 42/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2660 - accuracy: 0.5489 - val_loss: 1.5875 - val_accuracy: 0.4588\n",
      "Epoch 43/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2623 - accuracy: 0.5506 - val_loss: 1.5630 - val_accuracy: 0.4648\n",
      "Epoch 44/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2501 - accuracy: 0.5527 - val_loss: 1.5496 - val_accuracy: 0.4636\n",
      "Epoch 45/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2477 - accuracy: 0.5546 - val_loss: 1.5480 - val_accuracy: 0.4612\n",
      "Epoch 46/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2393 - accuracy: 0.5592 - val_loss: 1.5517 - val_accuracy: 0.4570\n",
      "Epoch 47/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2330 - accuracy: 0.5592 - val_loss: 1.5615 - val_accuracy: 0.4550\n",
      "Epoch 48/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2252 - accuracy: 0.5635 - val_loss: 1.5614 - val_accuracy: 0.4628\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5254 - accuracy: 0.4649: 0s - loss: 1.4780 - \n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.1536 - accuracy: 0.2178 - val_loss: 1.9651 - val_accuracy: 0.2782\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9451 - accuracy: 0.2911 - val_loss: 1.8659 - val_accuracy: 0.3218\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8633 - accuracy: 0.3201 - val_loss: 1.7984 - val_accuracy: 0.3474\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8035 - accuracy: 0.3436 - val_loss: 1.7687 - val_accuracy: 0.3590\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7586 - accuracy: 0.3598 - val_loss: 1.7491 - val_accuracy: 0.3676\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7213 - accuracy: 0.3769 - val_loss: 1.7354 - val_accuracy: 0.3726\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6923 - accuracy: 0.3849 - val_loss: 1.6867 - val_accuracy: 0.3872\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6657 - accuracy: 0.3949 - val_loss: 1.6723 - val_accuracy: 0.3996\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6403 - accuracy: 0.4066 - val_loss: 1.6595 - val_accuracy: 0.4000\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6174 - accuracy: 0.4167 - val_loss: 1.6469 - val_accuracy: 0.4050\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5984 - accuracy: 0.4239 - val_loss: 1.6417 - val_accuracy: 0.4120\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5800 - accuracy: 0.4302 - val_loss: 1.6231 - val_accuracy: 0.4120\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5629 - accuracy: 0.4378 - val_loss: 1.6276 - val_accuracy: 0.4130\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5483 - accuracy: 0.4436 - val_loss: 1.6067 - val_accuracy: 0.4196\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5316 - accuracy: 0.4472 - val_loss: 1.5986 - val_accuracy: 0.4272\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5187 - accuracy: 0.4545 - val_loss: 1.6213 - val_accuracy: 0.4156\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5035 - accuracy: 0.4560 - val_loss: 1.5958 - val_accuracy: 0.4354\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4905 - accuracy: 0.4630 - val_loss: 1.5857 - val_accuracy: 0.4310\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4779 - accuracy: 0.4696 - val_loss: 1.5829 - val_accuracy: 0.4390\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4659 - accuracy: 0.4723 - val_loss: 1.5936 - val_accuracy: 0.4298\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4538 - accuracy: 0.4765 - val_loss: 1.5953 - val_accuracy: 0.4296\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4448 - accuracy: 0.4799 - val_loss: 1.5766 - val_accuracy: 0.4440\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4322 - accuracy: 0.4855 - val_loss: 1.5794 - val_accuracy: 0.4338\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4187 - accuracy: 0.4930 - val_loss: 1.5802 - val_accuracy: 0.4394\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4122 - accuracy: 0.4938 - val_loss: 1.5730 - val_accuracy: 0.4446\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4016 - accuracy: 0.4961 - val_loss: 1.5719 - val_accuracy: 0.4416\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3909 - accuracy: 0.4972 - val_loss: 1.5591 - val_accuracy: 0.4460\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3802 - accuracy: 0.5054 - val_loss: 1.5674 - val_accuracy: 0.4446\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3698 - accuracy: 0.5065 - val_loss: 1.5543 - val_accuracy: 0.4468\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3615 - accuracy: 0.5086 - val_loss: 1.5783 - val_accuracy: 0.4422\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3535 - accuracy: 0.5122 - val_loss: 1.5812 - val_accuracy: 0.4388\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3462 - accuracy: 0.5157 - val_loss: 1.5576 - val_accuracy: 0.4434\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3342 - accuracy: 0.5220 - val_loss: 1.6022 - val_accuracy: 0.4402\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3279 - accuracy: 0.5228 - val_loss: 1.5691 - val_accuracy: 0.4384\n",
      "Epoch 35/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3172 - accuracy: 0.5264 - val_loss: 1.5679 - val_accuracy: 0.4498\n",
      "Epoch 36/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3094 - accuracy: 0.5295 - val_loss: 1.5608 - val_accuracy: 0.4464\n",
      "Epoch 37/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3033 - accuracy: 0.5316 - val_loss: 1.5814 - val_accuracy: 0.4518\n",
      "Epoch 38/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2938 - accuracy: 0.5352 - val_loss: 1.5574 - val_accuracy: 0.4488\n",
      "Epoch 39/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2861 - accuracy: 0.5381 - val_loss: 1.5727 - val_accuracy: 0.4534\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5746 - accuracy: 0.4412\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.1714 - accuracy: 0.2039 - val_loss: 1.9446 - val_accuracy: 0.2838\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9305 - accuracy: 0.2905 - val_loss: 1.8462 - val_accuracy: 0.3210\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8476 - accuracy: 0.3272 - val_loss: 1.7867 - val_accuracy: 0.3418\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7913 - accuracy: 0.3500 - val_loss: 1.7559 - val_accuracy: 0.3554\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7505 - accuracy: 0.3684 - val_loss: 1.7293 - val_accuracy: 0.3694\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7162 - accuracy: 0.3823 - val_loss: 1.7124 - val_accuracy: 0.3752\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6879 - accuracy: 0.3915 - val_loss: 1.6854 - val_accuracy: 0.3850\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6603 - accuracy: 0.4021 - val_loss: 1.6718 - val_accuracy: 0.3932\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6380 - accuracy: 0.4090 - val_loss: 1.6549 - val_accuracy: 0.3988\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6156 - accuracy: 0.4195 - val_loss: 1.6421 - val_accuracy: 0.4062\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5974 - accuracy: 0.4250 - val_loss: 1.6397 - val_accuracy: 0.4002\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5789 - accuracy: 0.4335 - val_loss: 1.6289 - val_accuracy: 0.4116\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5630 - accuracy: 0.4394 - val_loss: 1.6233 - val_accuracy: 0.4112\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5485 - accuracy: 0.4441 - val_loss: 1.6087 - val_accuracy: 0.4164\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5316 - accuracy: 0.4499 - val_loss: 1.6036 - val_accuracy: 0.4204\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5187 - accuracy: 0.4564 - val_loss: 1.6188 - val_accuracy: 0.4118\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5049 - accuracy: 0.4615 - val_loss: 1.5891 - val_accuracy: 0.4260\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4927 - accuracy: 0.4651 - val_loss: 1.5867 - val_accuracy: 0.4270\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4810 - accuracy: 0.4693 - val_loss: 1.5827 - val_accuracy: 0.4282\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4698 - accuracy: 0.4738 - val_loss: 1.5805 - val_accuracy: 0.4300\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4587 - accuracy: 0.4758 - val_loss: 1.6096 - val_accuracy: 0.4300\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4485 - accuracy: 0.4804 - val_loss: 1.5655 - val_accuracy: 0.4360\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4356 - accuracy: 0.4823 - val_loss: 1.5804 - val_accuracy: 0.4302\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4260 - accuracy: 0.4908 - val_loss: 1.5822 - val_accuracy: 0.4364\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4151 - accuracy: 0.4945 - val_loss: 1.5584 - val_accuracy: 0.4434\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4092 - accuracy: 0.4956 - val_loss: 1.5620 - val_accuracy: 0.4356\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3980 - accuracy: 0.4999 - val_loss: 1.5530 - val_accuracy: 0.4426\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3867 - accuracy: 0.5048 - val_loss: 1.5730 - val_accuracy: 0.4386\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3788 - accuracy: 0.5050 - val_loss: 1.5450 - val_accuracy: 0.4474\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3725 - accuracy: 0.5086 - val_loss: 1.5534 - val_accuracy: 0.4458\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3636 - accuracy: 0.5121 - val_loss: 1.5716 - val_accuracy: 0.4386\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3529 - accuracy: 0.5171 - val_loss: 1.5716 - val_accuracy: 0.4412\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3428 - accuracy: 0.5189 - val_loss: 1.5903 - val_accuracy: 0.4374\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3377 - accuracy: 0.5184 - val_loss: 1.5697 - val_accuracy: 0.4466\n",
      "Epoch 35/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3310 - accuracy: 0.5229 - val_loss: 1.5610 - val_accuracy: 0.4458\n",
      "Epoch 36/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3207 - accuracy: 0.5272 - val_loss: 1.5512 - val_accuracy: 0.4446\n",
      "Epoch 37/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3135 - accuracy: 0.5321 - val_loss: 1.5739 - val_accuracy: 0.4466\n",
      "Epoch 38/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3049 - accuracy: 0.5346 - val_loss: 1.5502 - val_accuracy: 0.4514\n",
      "Epoch 39/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2965 - accuracy: 0.5370 - val_loss: 1.5667 - val_accuracy: 0.4470\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5481 - accuracy: 0.4524\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.0980 - accuracy: 0.2397 - val_loss: 1.9088 - val_accuracy: 0.3054\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9025 - accuracy: 0.3064 - val_loss: 1.8284 - val_accuracy: 0.3294\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8311 - accuracy: 0.3327 - val_loss: 1.7936 - val_accuracy: 0.3398\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7808 - accuracy: 0.3541 - val_loss: 1.7600 - val_accuracy: 0.3564\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7394 - accuracy: 0.3675 - val_loss: 1.7269 - val_accuracy: 0.3720\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7083 - accuracy: 0.3815 - val_loss: 1.7178 - val_accuracy: 0.3756\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6773 - accuracy: 0.3949 - val_loss: 1.6940 - val_accuracy: 0.3848\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6521 - accuracy: 0.4029 - val_loss: 1.6758 - val_accuracy: 0.3932\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6324 - accuracy: 0.4131 - val_loss: 1.6664 - val_accuracy: 0.4008\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6108 - accuracy: 0.4196 - val_loss: 1.6514 - val_accuracy: 0.3948\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5899 - accuracy: 0.4295 - val_loss: 1.6274 - val_accuracy: 0.4138\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5715 - accuracy: 0.4353 - val_loss: 1.6361 - val_accuracy: 0.4166\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5579 - accuracy: 0.4419 - val_loss: 1.6149 - val_accuracy: 0.4160\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5391 - accuracy: 0.4452 - val_loss: 1.6271 - val_accuracy: 0.4130\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5229 - accuracy: 0.4528 - val_loss: 1.5997 - val_accuracy: 0.4264\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5092 - accuracy: 0.4582 - val_loss: 1.5949 - val_accuracy: 0.4284\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4947 - accuracy: 0.4632 - val_loss: 1.5952 - val_accuracy: 0.4262\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4808 - accuracy: 0.4673 - val_loss: 1.5756 - val_accuracy: 0.4324\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4702 - accuracy: 0.4718 - val_loss: 1.5740 - val_accuracy: 0.4384\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.4535 - accuracy: 0.4771 - val_loss: 1.5641 - val_accuracy: 0.4400\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.4428 - accuracy: 0.4830 - val_loss: 1.6018 - val_accuracy: 0.4320\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4320 - accuracy: 0.4871 - val_loss: 1.5780 - val_accuracy: 0.4366\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4218 - accuracy: 0.4884 - val_loss: 1.5635 - val_accuracy: 0.4422\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4100 - accuracy: 0.4947 - val_loss: 1.5892 - val_accuracy: 0.4374\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 7s 7ms/step - loss: 1.3988 - accuracy: 0.4998 - val_loss: 1.5649 - val_accuracy: 0.4416\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3899 - accuracy: 0.5018 - val_loss: 1.5594 - val_accuracy: 0.4480\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3829 - accuracy: 0.5058 - val_loss: 1.5416 - val_accuracy: 0.4498\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3716 - accuracy: 0.5096 - val_loss: 1.5452 - val_accuracy: 0.4506\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3624 - accuracy: 0.5115 - val_loss: 1.5679 - val_accuracy: 0.4444\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3533 - accuracy: 0.5142 - val_loss: 1.5642 - val_accuracy: 0.4424\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3435 - accuracy: 0.5201 - val_loss: 1.5552 - val_accuracy: 0.4502\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3374 - accuracy: 0.5209 - val_loss: 1.5472 - val_accuracy: 0.4504\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3271 - accuracy: 0.5264 - val_loss: 1.5393 - val_accuracy: 0.4560\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3166 - accuracy: 0.5282 - val_loss: 1.5309 - val_accuracy: 0.4518\n",
      "Epoch 35/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3103 - accuracy: 0.5296 - val_loss: 1.5436 - val_accuracy: 0.4560\n",
      "Epoch 36/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3025 - accuracy: 0.5349 - val_loss: 1.5508 - val_accuracy: 0.4590\n",
      "Epoch 37/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2950 - accuracy: 0.5357 - val_loss: 1.5507 - val_accuracy: 0.4600\n",
      "Epoch 38/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2836 - accuracy: 0.5406 - val_loss: 1.5385 - val_accuracy: 0.4594\n",
      "Epoch 39/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2797 - accuracy: 0.5415 - val_loss: 1.5476 - val_accuracy: 0.4624\n",
      "Epoch 40/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2700 - accuracy: 0.5440 - val_loss: 1.5485 - val_accuracy: 0.4598\n",
      "Epoch 41/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2628 - accuracy: 0.5477 - val_loss: 1.5462 - val_accuracy: 0.4614\n",
      "Epoch 42/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2558 - accuracy: 0.5513 - val_loss: 1.5932 - val_accuracy: 0.4624\n",
      "Epoch 43/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2481 - accuracy: 0.5538 - val_loss: 1.5528 - val_accuracy: 0.4606\n",
      "Epoch 44/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2413 - accuracy: 0.5546 - val_loss: 1.5606 - val_accuracy: 0.4592\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5703 - accuracy: 0.4513\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.1265 - accuracy: 0.2221 - val_loss: 1.9307 - val_accuracy: 0.3000\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9252 - accuracy: 0.2976 - val_loss: 1.8444 - val_accuracy: 0.3306\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8453 - accuracy: 0.3301 - val_loss: 1.7960 - val_accuracy: 0.3514\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7938 - accuracy: 0.3517 - val_loss: 1.7680 - val_accuracy: 0.3582\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7545 - accuracy: 0.3685 - val_loss: 1.7396 - val_accuracy: 0.3768\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7211 - accuracy: 0.3809 - val_loss: 1.7159 - val_accuracy: 0.3792\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6901 - accuracy: 0.3910 - val_loss: 1.7041 - val_accuracy: 0.3860\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6686 - accuracy: 0.3988 - val_loss: 1.6925 - val_accuracy: 0.3812\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6436 - accuracy: 0.4085 - val_loss: 1.6688 - val_accuracy: 0.3940\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6223 - accuracy: 0.4149 - val_loss: 1.6655 - val_accuracy: 0.3958\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6026 - accuracy: 0.4229 - val_loss: 1.6596 - val_accuracy: 0.3986\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5876 - accuracy: 0.4281 - val_loss: 1.6308 - val_accuracy: 0.4116\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5682 - accuracy: 0.4357 - val_loss: 1.6164 - val_accuracy: 0.4178\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5510 - accuracy: 0.4411 - val_loss: 1.6386 - val_accuracy: 0.4110\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5393 - accuracy: 0.4464 - val_loss: 1.6071 - val_accuracy: 0.4178\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5215 - accuracy: 0.4509 - val_loss: 1.6102 - val_accuracy: 0.4188\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5144 - accuracy: 0.4566 - val_loss: 1.6028 - val_accuracy: 0.4190\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4989 - accuracy: 0.4592 - val_loss: 1.5952 - val_accuracy: 0.4272\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4860 - accuracy: 0.4672 - val_loss: 1.5897 - val_accuracy: 0.4252\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4754 - accuracy: 0.4706 - val_loss: 1.5931 - val_accuracy: 0.4330\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4615 - accuracy: 0.4744 - val_loss: 1.5965 - val_accuracy: 0.4300\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4550 - accuracy: 0.4778 - val_loss: 1.5915 - val_accuracy: 0.4298\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4422 - accuracy: 0.4845 - val_loss: 1.5798 - val_accuracy: 0.4340\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4311 - accuracy: 0.4876 - val_loss: 1.5743 - val_accuracy: 0.4408\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4202 - accuracy: 0.4919 - val_loss: 1.5758 - val_accuracy: 0.4468\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4128 - accuracy: 0.4940 - val_loss: 1.5731 - val_accuracy: 0.4388\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4003 - accuracy: 0.4992 - val_loss: 1.5949 - val_accuracy: 0.4330\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3902 - accuracy: 0.5010 - val_loss: 1.5641 - val_accuracy: 0.4468\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3798 - accuracy: 0.5076 - val_loss: 1.5820 - val_accuracy: 0.4368\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3696 - accuracy: 0.5101 - val_loss: 1.5771 - val_accuracy: 0.4404\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3631 - accuracy: 0.5102 - val_loss: 1.5724 - val_accuracy: 0.4476\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3550 - accuracy: 0.5162 - val_loss: 1.5742 - val_accuracy: 0.4460\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3424 - accuracy: 0.5207 - val_loss: 1.5619 - val_accuracy: 0.4500\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3383 - accuracy: 0.5204 - val_loss: 1.5624 - val_accuracy: 0.4472\n",
      "Epoch 35/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3273 - accuracy: 0.5257 - val_loss: 1.5724 - val_accuracy: 0.4496\n",
      "Epoch 36/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3157 - accuracy: 0.5319 - val_loss: 1.5817 - val_accuracy: 0.4482\n",
      "Epoch 37/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3115 - accuracy: 0.5285 - val_loss: 1.5723 - val_accuracy: 0.4492\n",
      "Epoch 38/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3012 - accuracy: 0.5328 - val_loss: 1.5768 - val_accuracy: 0.4478\n",
      "Epoch 39/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2892 - accuracy: 0.5385 - val_loss: 1.5708 - val_accuracy: 0.4584\n",
      "Epoch 40/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2836 - accuracy: 0.5401 - val_loss: 1.5669 - val_accuracy: 0.4544\n",
      "Epoch 41/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2754 - accuracy: 0.5450 - val_loss: 1.5701 - val_accuracy: 0.4528\n",
      "Epoch 42/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2685 - accuracy: 0.5462 - val_loss: 1.5966 - val_accuracy: 0.4478\n",
      "Epoch 43/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2589 - accuracy: 0.5521 - val_loss: 1.5775 - val_accuracy: 0.4492\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5575 - accuracy: 0.4557\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3554 - accuracy: 0.1422 - val_loss: 2.1889 - val_accuracy: 0.1760\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.1743 - accuracy: 0.1610 - val_loss: 2.1858 - val_accuracy: 0.1374\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.1541 - accuracy: 0.1672 - val_loss: 2.1574 - val_accuracy: 0.1552\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 5.6215 - accuracy: 0.1096 - val_loss: 2.3374 - val_accuracy: 0.0976\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3540 - accuracy: 0.0998 - val_loss: 2.3272 - val_accuracy: 0.1010\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3885 - accuracy: 0.0996 - val_loss: 2.3311 - val_accuracy: 0.0920\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3241 - accuracy: 0.0975 - val_loss: 2.3159 - val_accuracy: 0.0996\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3264 - accuracy: 0.0994 - val_loss: 2.3118 - val_accuracy: 0.0972\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3301 - accuracy: 0.0988 - val_loss: 2.3298 - val_accuracy: 0.1038\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3335 - accuracy: 0.0998 - val_loss: 2.3350 - val_accuracy: 0.1040\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3358 - accuracy: 0.1031 - val_loss: 2.3250 - val_accuracy: 0.0972\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 3.8092 - accuracy: 0.1010 - val_loss: 2.3297 - val_accuracy: 0.1040\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3348 - accuracy: 0.1008 - val_loss: 2.3390 - val_accuracy: 0.0976\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.1582 - accuracy: 0.1551\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.2595 - accuracy: 0.1580 - val_loss: 2.0932 - val_accuracy: 0.1980\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.1062 - accuracy: 0.1784 - val_loss: 2.1379 - val_accuracy: 0.1696\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.4438 - accuracy: 0.1451 - val_loss: 2.3548 - val_accuracy: 0.0972\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3367 - accuracy: 0.1006 - val_loss: 2.3296 - val_accuracy: 0.1038\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3362 - accuracy: 0.1014 - val_loss: 2.3471 - val_accuracy: 0.1040\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3383 - accuracy: 0.0969 - val_loss: 2.4014 - val_accuracy: 0.0972\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3385 - accuracy: 0.0996 - val_loss: 2.3271 - val_accuracy: 0.0976\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3382 - accuracy: 0.0989 - val_loss: 2.3324 - val_accuracy: 0.0972\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3383 - accuracy: 0.1011 - val_loss: 2.3505 - val_accuracy: 0.1040\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3391 - accuracy: 0.0987 - val_loss: 2.3203 - val_accuracy: 0.0996\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3402 - accuracy: 0.1035 - val_loss: 2.3389 - val_accuracy: 0.1010\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.1033 - accuracy: 0.1868\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.2913 - accuracy: 0.1554 - val_loss: 2.0858 - val_accuracy: 0.1950\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.1277 - accuracy: 0.1717 - val_loss: 2.1578 - val_accuracy: 0.1576\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 4.1523 - accuracy: 0.1655 - val_loss: 2.3885 - val_accuracy: 0.0972\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.6128 - accuracy: 0.1000 - val_loss: 2.3256 - val_accuracy: 0.1040\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3514 - accuracy: 0.0996 - val_loss: 2.3261 - val_accuracy: 0.0996\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3306 - accuracy: 0.0975 - val_loss: 2.3873 - val_accuracy: 0.0972\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3264 - accuracy: 0.1011 - val_loss: 2.3367 - val_accuracy: 0.0972\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3296 - accuracy: 0.0984 - val_loss: 2.3228 - val_accuracy: 0.1038\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3313 - accuracy: 0.1003 - val_loss: 2.3281 - val_accuracy: 0.1010\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3347 - accuracy: 0.1012 - val_loss: 2.3317 - val_accuracy: 0.1038\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3363 - accuracy: 0.1005 - val_loss: 2.3533 - val_accuracy: 0.0972\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.0887 - accuracy: 0.1907\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.3248 - accuracy: 0.1414 - val_loss: 2.0665 - val_accuracy: 0.1994\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.9989 - accuracy: 0.1217 - val_loss: 2.3230 - val_accuracy: 0.1038\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3284 - accuracy: 0.1007 - val_loss: 2.3450 - val_accuracy: 0.1040\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.6227 - accuracy: 0.1025 - val_loss: 2.3507 - val_accuracy: 0.1040\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3300 - accuracy: 0.1002 - val_loss: 2.3347 - val_accuracy: 0.0920\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3329 - accuracy: 0.0962 - val_loss: 2.3653 - val_accuracy: 0.0976\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3337 - accuracy: 0.0982 - val_loss: 2.3422 - val_accuracy: 0.1010\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3656 - accuracy: 0.0989 - val_loss: 2.3207 - val_accuracy: 0.1040\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3369 - accuracy: 0.0998 - val_loss: 2.3283 - val_accuracy: 0.1038\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3384 - accuracy: 0.1016 - val_loss: 2.3402 - val_accuracy: 0.0996\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3386 - accuracy: 0.0983 - val_loss: 2.3433 - val_accuracy: 0.1010\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.0645 - accuracy: 0.1930\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.2948 - accuracy: 0.1569 - val_loss: 2.1238 - val_accuracy: 0.1744\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.1509 - accuracy: 0.1637 - val_loss: 2.1077 - val_accuracy: 0.1728\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.1470 - accuracy: 0.1673 - val_loss: 2.1222 - val_accuracy: 0.1696\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 3.9218 - accuracy: 0.1461 - val_loss: 2.3620 - val_accuracy: 0.1040\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3240 - accuracy: 0.1007 - val_loss: 2.3190 - val_accuracy: 0.0972\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3247 - accuracy: 0.1001 - val_loss: 2.3307 - val_accuracy: 0.0972\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3265 - accuracy: 0.1028 - val_loss: 2.3314 - val_accuracy: 0.0920\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3306 - accuracy: 0.0966 - val_loss: 2.3175 - val_accuracy: 0.0920\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3313 - accuracy: 0.1020 - val_loss: 2.3448 - val_accuracy: 0.1010\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3347 - accuracy: 0.0977 - val_loss: 2.3414 - val_accuracy: 0.0976\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3352 - accuracy: 0.0999 - val_loss: 2.3578 - val_accuracy: 0.0920\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3390 - accuracy: 0.0986 - val_loss: 2.3179 - val_accuracy: 0.0972\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.1213 - accuracy: 0.1714\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0846 - accuracy: 0.2339 - val_loss: 1.9245 - val_accuracy: 0.2860\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8804 - accuracy: 0.3047 - val_loss: 1.8536 - val_accuracy: 0.3360\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8123 - accuracy: 0.3400 - val_loss: 1.7827 - val_accuracy: 0.3562\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7598 - accuracy: 0.3599 - val_loss: 1.7762 - val_accuracy: 0.3652\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7189 - accuracy: 0.3799 - val_loss: 1.6837 - val_accuracy: 0.3930\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6828 - accuracy: 0.3918 - val_loss: 1.6832 - val_accuracy: 0.4016\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6567 - accuracy: 0.4039 - val_loss: 1.6899 - val_accuracy: 0.3890\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6269 - accuracy: 0.4156 - val_loss: 1.6753 - val_accuracy: 0.4060\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6065 - accuracy: 0.4231 - val_loss: 1.6430 - val_accuracy: 0.4210\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5918 - accuracy: 0.4312 - val_loss: 1.6545 - val_accuracy: 0.4120\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5737 - accuracy: 0.4388 - val_loss: 1.7121 - val_accuracy: 0.4032\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5569 - accuracy: 0.4436 - val_loss: 1.6085 - val_accuracy: 0.4376\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5377 - accuracy: 0.4524 - val_loss: 1.5726 - val_accuracy: 0.4454\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5241 - accuracy: 0.4559 - val_loss: 1.6262 - val_accuracy: 0.4372\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5105 - accuracy: 0.4590 - val_loss: 1.5689 - val_accuracy: 0.4398\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4987 - accuracy: 0.4680 - val_loss: 1.5944 - val_accuracy: 0.4552\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4826 - accuracy: 0.4683 - val_loss: 1.6088 - val_accuracy: 0.4412\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4752 - accuracy: 0.4776 - val_loss: 1.6463 - val_accuracy: 0.4340\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4613 - accuracy: 0.4775 - val_loss: 1.6015 - val_accuracy: 0.4584\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4409 - accuracy: 0.4867 - val_loss: 1.6685 - val_accuracy: 0.4478\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4321 - accuracy: 0.4907 - val_loss: 1.6303 - val_accuracy: 0.4560\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4223 - accuracy: 0.4969 - val_loss: 1.5713 - val_accuracy: 0.4610\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4116 - accuracy: 0.4992 - val_loss: 1.7092 - val_accuracy: 0.4236\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4017 - accuracy: 0.5054 - val_loss: 1.5662 - val_accuracy: 0.4642\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3922 - accuracy: 0.5005 - val_loss: 1.5849 - val_accuracy: 0.4680\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3829 - accuracy: 0.5085 - val_loss: 1.6070 - val_accuracy: 0.4490\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3682 - accuracy: 0.5152 - val_loss: 1.5828 - val_accuracy: 0.4640\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3611 - accuracy: 0.5207 - val_loss: 1.5916 - val_accuracy: 0.4580\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3487 - accuracy: 0.5202 - val_loss: 1.5989 - val_accuracy: 0.4724\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3327 - accuracy: 0.5260 - val_loss: 1.6275 - val_accuracy: 0.4512\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3245 - accuracy: 0.5317 - val_loss: 1.5732 - val_accuracy: 0.4634\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3168 - accuracy: 0.5322 - val_loss: 1.5720 - val_accuracy: 0.4664\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3097 - accuracy: 0.5359 - val_loss: 1.6745 - val_accuracy: 0.4586\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2992 - accuracy: 0.5387 - val_loss: 1.6015 - val_accuracy: 0.4686\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5642 - accuracy: 0.4639\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.0969 - accuracy: 0.2270 - val_loss: 1.8891 - val_accuracy: 0.3148\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8690 - accuracy: 0.3162 - val_loss: 1.8041 - val_accuracy: 0.3498\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7914 - accuracy: 0.3490 - val_loss: 1.8048 - val_accuracy: 0.3638\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7390 - accuracy: 0.3734 - val_loss: 1.6987 - val_accuracy: 0.3798\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6956 - accuracy: 0.3914 - val_loss: 1.7225 - val_accuracy: 0.3822\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6587 - accuracy: 0.4070 - val_loss: 1.7197 - val_accuracy: 0.3960\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6273 - accuracy: 0.4181 - val_loss: 1.6681 - val_accuracy: 0.4106\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5996 - accuracy: 0.4259 - val_loss: 1.6873 - val_accuracy: 0.3972\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5771 - accuracy: 0.4341 - val_loss: 1.6688 - val_accuracy: 0.4202\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5567 - accuracy: 0.4425 - val_loss: 1.6207 - val_accuracy: 0.4294\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5388 - accuracy: 0.4501 - val_loss: 1.6538 - val_accuracy: 0.4326\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5260 - accuracy: 0.4547 - val_loss: 1.6279 - val_accuracy: 0.4290\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5084 - accuracy: 0.4653 - val_loss: 1.6171 - val_accuracy: 0.4322\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4963 - accuracy: 0.4683 - val_loss: 1.5886 - val_accuracy: 0.4426\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4765 - accuracy: 0.4729 - val_loss: 1.5871 - val_accuracy: 0.4344\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4680 - accuracy: 0.4783 - val_loss: 1.5757 - val_accuracy: 0.4536\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4524 - accuracy: 0.4830 - val_loss: 1.5931 - val_accuracy: 0.4400\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4407 - accuracy: 0.4849 - val_loss: 1.6419 - val_accuracy: 0.4428\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4287 - accuracy: 0.4930 - val_loss: 1.6406 - val_accuracy: 0.4446\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4159 - accuracy: 0.4967 - val_loss: 1.6109 - val_accuracy: 0.4410\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4054 - accuracy: 0.4983 - val_loss: 1.6007 - val_accuracy: 0.4530\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3928 - accuracy: 0.5077 - val_loss: 1.5816 - val_accuracy: 0.4576\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3826 - accuracy: 0.5092 - val_loss: 1.5987 - val_accuracy: 0.4472\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3714 - accuracy: 0.5138 - val_loss: 1.5800 - val_accuracy: 0.4542\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3611 - accuracy: 0.5173 - val_loss: 1.6284 - val_accuracy: 0.4518\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3581 - accuracy: 0.5180 - val_loss: 1.5791 - val_accuracy: 0.4564\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5780 - accuracy: 0.4530\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.1043 - accuracy: 0.2272 - val_loss: 1.9698 - val_accuracy: 0.2836\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8802 - accuracy: 0.3104 - val_loss: 1.9412 - val_accuracy: 0.3208\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8126 - accuracy: 0.3409 - val_loss: 1.7256 - val_accuracy: 0.3692\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7642 - accuracy: 0.3607 - val_loss: 1.7182 - val_accuracy: 0.3800\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7196 - accuracy: 0.3809 - val_loss: 1.8227 - val_accuracy: 0.3494\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6849 - accuracy: 0.3974 - val_loss: 1.7663 - val_accuracy: 0.3856\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6511 - accuracy: 0.4107 - val_loss: 1.6767 - val_accuracy: 0.3972\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6273 - accuracy: 0.4214 - val_loss: 1.6635 - val_accuracy: 0.4064\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6043 - accuracy: 0.4255 - val_loss: 1.6850 - val_accuracy: 0.4096\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5815 - accuracy: 0.4400 - val_loss: 1.6394 - val_accuracy: 0.4182\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5661 - accuracy: 0.4418 - val_loss: 1.6457 - val_accuracy: 0.4156\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5542 - accuracy: 0.4468 - val_loss: 1.6070 - val_accuracy: 0.4332\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5342 - accuracy: 0.4525 - val_loss: 1.6117 - val_accuracy: 0.4386\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5609 - accuracy: 0.4433 - val_loss: 1.6146 - val_accuracy: 0.4280\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5117 - accuracy: 0.4647 - val_loss: 1.6145 - val_accuracy: 0.4304\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4969 - accuracy: 0.4676 - val_loss: 1.6146 - val_accuracy: 0.4300\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4833 - accuracy: 0.4731 - val_loss: 1.5741 - val_accuracy: 0.4584\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5562 - accuracy: 0.4457 - val_loss: 1.5921 - val_accuracy: 0.4510\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5016 - accuracy: 0.4646 - val_loss: 1.6069 - val_accuracy: 0.4392\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4758 - accuracy: 0.4734 - val_loss: 1.5810 - val_accuracy: 0.4456\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4570 - accuracy: 0.4804 - val_loss: 1.6301 - val_accuracy: 0.4508\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4422 - accuracy: 0.4887 - val_loss: 1.6035 - val_accuracy: 0.4508\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4257 - accuracy: 0.4923 - val_loss: 1.6392 - val_accuracy: 0.4502\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4161 - accuracy: 0.4980 - val_loss: 1.5855 - val_accuracy: 0.4424\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4058 - accuracy: 0.5042 - val_loss: 1.6228 - val_accuracy: 0.4570\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3945 - accuracy: 0.5063 - val_loss: 1.5884 - val_accuracy: 0.4540\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3804 - accuracy: 0.5102 - val_loss: 1.6162 - val_accuracy: 0.4570\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5639 - accuracy: 0.4550\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0957 - accuracy: 0.2247 - val_loss: 1.8676 - val_accuracy: 0.3144\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8814 - accuracy: 0.3124 - val_loss: 1.8237 - val_accuracy: 0.3486\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8101 - accuracy: 0.3435 - val_loss: 1.9033 - val_accuracy: 0.3382\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7573 - accuracy: 0.3629 - val_loss: 1.7030 - val_accuracy: 0.3864\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7107 - accuracy: 0.3829 - val_loss: 1.6562 - val_accuracy: 0.3982\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6695 - accuracy: 0.4015 - val_loss: 1.7001 - val_accuracy: 0.4074\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6366 - accuracy: 0.4123 - val_loss: 1.6202 - val_accuracy: 0.4118\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6124 - accuracy: 0.4243 - val_loss: 1.6097 - val_accuracy: 0.4284\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5862 - accuracy: 0.4330 - val_loss: 1.5951 - val_accuracy: 0.4308\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5670 - accuracy: 0.4401 - val_loss: 1.6358 - val_accuracy: 0.4386\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5468 - accuracy: 0.4477 - val_loss: 1.6033 - val_accuracy: 0.4478\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5360 - accuracy: 0.4525 - val_loss: 1.5925 - val_accuracy: 0.4356\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5201 - accuracy: 0.4556 - val_loss: 1.5985 - val_accuracy: 0.4366\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5054 - accuracy: 0.4625 - val_loss: 1.6107 - val_accuracy: 0.4454\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4889 - accuracy: 0.4741 - val_loss: 1.5831 - val_accuracy: 0.4488\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4662 - accuracy: 0.4774 - val_loss: 1.6267 - val_accuracy: 0.4370\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4582 - accuracy: 0.4817 - val_loss: 1.6028 - val_accuracy: 0.4562\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4511 - accuracy: 0.4829 - val_loss: 1.5569 - val_accuracy: 0.4590\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4328 - accuracy: 0.4885 - val_loss: 1.5965 - val_accuracy: 0.4672\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4249 - accuracy: 0.4926 - val_loss: 1.5893 - val_accuracy: 0.4666\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4064 - accuracy: 0.5023 - val_loss: 1.6391 - val_accuracy: 0.4546\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4007 - accuracy: 0.5025 - val_loss: 1.6177 - val_accuracy: 0.4590\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3934 - accuracy: 0.5071 - val_loss: 1.6129 - val_accuracy: 0.4524\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3816 - accuracy: 0.5080 - val_loss: 1.5929 - val_accuracy: 0.4448\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3685 - accuracy: 0.5145 - val_loss: 1.5655 - val_accuracy: 0.4594\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3601 - accuracy: 0.5168 - val_loss: 1.5967 - val_accuracy: 0.4586\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3511 - accuracy: 0.5197 - val_loss: 1.6161 - val_accuracy: 0.4684\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3400 - accuracy: 0.5236 - val_loss: 1.6082 - val_accuracy: 0.4660\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5753 - accuracy: 0.4526\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.0957 - accuracy: 0.2311 - val_loss: 1.9045 - val_accuracy: 0.3062\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8902 - accuracy: 0.3070 - val_loss: 1.8387 - val_accuracy: 0.3432\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8101 - accuracy: 0.3442 - val_loss: 1.8750 - val_accuracy: 0.3322\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7513 - accuracy: 0.3721 - val_loss: 1.7576 - val_accuracy: 0.3874\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7113 - accuracy: 0.3868 - val_loss: 1.6785 - val_accuracy: 0.3946\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6748 - accuracy: 0.3983 - val_loss: 1.7287 - val_accuracy: 0.3898\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6479 - accuracy: 0.4116 - val_loss: 1.6643 - val_accuracy: 0.4148\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6217 - accuracy: 0.4214 - val_loss: 1.6488 - val_accuracy: 0.4176\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5986 - accuracy: 0.4298 - val_loss: 1.7120 - val_accuracy: 0.4052\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5760 - accuracy: 0.4387 - val_loss: 1.6190 - val_accuracy: 0.4256\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5820 - accuracy: 0.4351 - val_loss: 1.6437 - val_accuracy: 0.4206\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5478 - accuracy: 0.4498 - val_loss: 1.6269 - val_accuracy: 0.4234\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5575 - accuracy: 0.4449 - val_loss: 1.6478 - val_accuracy: 0.4256\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5366 - accuracy: 0.4523 - val_loss: 1.6671 - val_accuracy: 0.4238\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5116 - accuracy: 0.4621 - val_loss: 1.6435 - val_accuracy: 0.4418\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4929 - accuracy: 0.4721 - val_loss: 1.5859 - val_accuracy: 0.4464\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4872 - accuracy: 0.4718 - val_loss: 1.6047 - val_accuracy: 0.4422\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4757 - accuracy: 0.4786 - val_loss: 1.5916 - val_accuracy: 0.4466\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4596 - accuracy: 0.4806 - val_loss: 1.5946 - val_accuracy: 0.4496\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5013 - accuracy: 0.4646 - val_loss: 1.6205 - val_accuracy: 0.4456\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4463 - accuracy: 0.4850 - val_loss: 1.6954 - val_accuracy: 0.4352\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4294 - accuracy: 0.4941 - val_loss: 1.6204 - val_accuracy: 0.4432\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4215 - accuracy: 0.4961 - val_loss: 1.6124 - val_accuracy: 0.4584\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4101 - accuracy: 0.5018 - val_loss: 1.5870 - val_accuracy: 0.4590\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3941 - accuracy: 0.5069 - val_loss: 1.6081 - val_accuracy: 0.4502\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3854 - accuracy: 0.5062 - val_loss: 1.5343 - val_accuracy: 0.4716\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3740 - accuracy: 0.5148 - val_loss: 1.5593 - val_accuracy: 0.4640\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3635 - accuracy: 0.5154 - val_loss: 1.6922 - val_accuracy: 0.4404\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3508 - accuracy: 0.5211 - val_loss: 1.5828 - val_accuracy: 0.4810\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3405 - accuracy: 0.5240 - val_loss: 1.5570 - val_accuracy: 0.4730\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3318 - accuracy: 0.5270 - val_loss: 1.6248 - val_accuracy: 0.4668\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3222 - accuracy: 0.5343 - val_loss: 1.5973 - val_accuracy: 0.4692\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3100 - accuracy: 0.5342 - val_loss: 1.6193 - val_accuracy: 0.4636\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4040 - accuracy: 0.4957 - val_loss: 1.7570 - val_accuracy: 0.3806\n",
      "Epoch 35/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5849 - accuracy: 0.4333 - val_loss: 1.7136 - val_accuracy: 0.4048\n",
      "Epoch 36/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4133 - accuracy: 0.5007 - val_loss: 1.5720 - val_accuracy: 0.4578\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.5513 - accuracy: 0.4566\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.2151 - accuracy: 0.2129 - val_loss: 1.8984 - val_accuracy: 0.3186\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9348 - accuracy: 0.2924 - val_loss: 1.8419 - val_accuracy: 0.3560\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8441 - accuracy: 0.3350 - val_loss: 1.9045 - val_accuracy: 0.3518\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7765 - accuracy: 0.3542 - val_loss: 1.7607 - val_accuracy: 0.3856\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7295 - accuracy: 0.3756 - val_loss: 1.7874 - val_accuracy: 0.3914\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6918 - accuracy: 0.3893 - val_loss: 1.7793 - val_accuracy: 0.4034\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6556 - accuracy: 0.4046 - val_loss: 1.6958 - val_accuracy: 0.4230\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6202 - accuracy: 0.4214 - val_loss: 1.7669 - val_accuracy: 0.4140\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5969 - accuracy: 0.4237 - val_loss: 1.7326 - val_accuracy: 0.4150\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5745 - accuracy: 0.4376 - val_loss: 1.7003 - val_accuracy: 0.4314\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5517 - accuracy: 0.4425 - val_loss: 1.7594 - val_accuracy: 0.4214\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5325 - accuracy: 0.4496 - val_loss: 1.7288 - val_accuracy: 0.4432\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5119 - accuracy: 0.4585 - val_loss: 1.7115 - val_accuracy: 0.4314\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4958 - accuracy: 0.4640 - val_loss: 1.6914 - val_accuracy: 0.4420\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4794 - accuracy: 0.4741 - val_loss: 1.7058 - val_accuracy: 0.4360\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4649 - accuracy: 0.4782 - val_loss: 1.7518 - val_accuracy: 0.4406\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4534 - accuracy: 0.4832 - val_loss: 1.6891 - val_accuracy: 0.4456\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4322 - accuracy: 0.4897 - val_loss: 1.7491 - val_accuracy: 0.4442\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4230 - accuracy: 0.4929 - val_loss: 1.7369 - val_accuracy: 0.4566\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4061 - accuracy: 0.4966 - val_loss: 1.7040 - val_accuracy: 0.4570\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3958 - accuracy: 0.5005 - val_loss: 1.7764 - val_accuracy: 0.4418\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3848 - accuracy: 0.5070 - val_loss: 1.7052 - val_accuracy: 0.4586\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3689 - accuracy: 0.5098 - val_loss: 1.7877 - val_accuracy: 0.4456\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3579 - accuracy: 0.5166 - val_loss: 1.7314 - val_accuracy: 0.4592\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3410 - accuracy: 0.5213 - val_loss: 1.7510 - val_accuracy: 0.4610\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3330 - accuracy: 0.5237 - val_loss: 1.8019 - val_accuracy: 0.4600\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3193 - accuracy: 0.5278 - val_loss: 1.7757 - val_accuracy: 0.4678\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.6888 - accuracy: 0.4512\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.2115 - accuracy: 0.2058 - val_loss: 1.9099 - val_accuracy: 0.3140\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.9244 - accuracy: 0.2950 - val_loss: 1.8937 - val_accuracy: 0.3298\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8342 - accuracy: 0.3300 - val_loss: 1.7899 - val_accuracy: 0.3776\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7646 - accuracy: 0.3619 - val_loss: 1.7813 - val_accuracy: 0.3876\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7168 - accuracy: 0.3755 - val_loss: 1.7859 - val_accuracy: 0.3922\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6756 - accuracy: 0.3946 - val_loss: 1.8488 - val_accuracy: 0.3804\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.6442 - accuracy: 0.4044 - val_loss: 1.7380 - val_accuracy: 0.4082\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6116 - accuracy: 0.4185 - val_loss: 1.7435 - val_accuracy: 0.4206\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5922 - accuracy: 0.4251 - val_loss: 1.7343 - val_accuracy: 0.4308\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5715 - accuracy: 0.4358 - val_loss: 1.6885 - val_accuracy: 0.4286\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5492 - accuracy: 0.4425 - val_loss: 1.7241 - val_accuracy: 0.4298\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5332 - accuracy: 0.4496 - val_loss: 1.7455 - val_accuracy: 0.4414\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5149 - accuracy: 0.4550 - val_loss: 1.6646 - val_accuracy: 0.4396\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4994 - accuracy: 0.4626 - val_loss: 1.6797 - val_accuracy: 0.4386\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4841 - accuracy: 0.4685 - val_loss: 1.6683 - val_accuracy: 0.4392\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4659 - accuracy: 0.4736 - val_loss: 1.7219 - val_accuracy: 0.4534\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4549 - accuracy: 0.4773 - val_loss: 1.6952 - val_accuracy: 0.4518\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4360 - accuracy: 0.4852 - val_loss: 1.7115 - val_accuracy: 0.4540\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4248 - accuracy: 0.4896 - val_loss: 1.7405 - val_accuracy: 0.4508\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4112 - accuracy: 0.4945 - val_loss: 1.6874 - val_accuracy: 0.4514\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.3989 - accuracy: 0.4978 - val_loss: 1.6843 - val_accuracy: 0.4578\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3908 - accuracy: 0.5001 - val_loss: 1.6924 - val_accuracy: 0.4690\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3730 - accuracy: 0.5115 - val_loss: 1.7808 - val_accuracy: 0.4442\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.6810 - accuracy: 0.4379\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.2494 - accuracy: 0.1972 - val_loss: 1.9486 - val_accuracy: 0.3114\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9466 - accuracy: 0.2965 - val_loss: 1.9079 - val_accuracy: 0.3468\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8371 - accuracy: 0.3362 - val_loss: 1.8427 - val_accuracy: 0.3724\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7688 - accuracy: 0.3605 - val_loss: 1.7258 - val_accuracy: 0.3870\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7183 - accuracy: 0.3814 - val_loss: 1.8034 - val_accuracy: 0.3858\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6750 - accuracy: 0.3986 - val_loss: 1.7955 - val_accuracy: 0.3944\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6445 - accuracy: 0.4098 - val_loss: 1.7140 - val_accuracy: 0.4168\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6128 - accuracy: 0.4215 - val_loss: 1.6988 - val_accuracy: 0.4208\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5913 - accuracy: 0.4302 - val_loss: 1.7206 - val_accuracy: 0.4276\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5688 - accuracy: 0.4375 - val_loss: 1.6954 - val_accuracy: 0.4256\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5509 - accuracy: 0.4455 - val_loss: 1.6794 - val_accuracy: 0.4404\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5300 - accuracy: 0.4557 - val_loss: 1.7822 - val_accuracy: 0.4360\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5128 - accuracy: 0.4627 - val_loss: 1.6470 - val_accuracy: 0.4442\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4995 - accuracy: 0.4669 - val_loss: 1.6910 - val_accuracy: 0.4398\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4827 - accuracy: 0.4720 - val_loss: 1.6829 - val_accuracy: 0.4506\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4627 - accuracy: 0.4779 - val_loss: 1.6819 - val_accuracy: 0.4482\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4548 - accuracy: 0.4814 - val_loss: 1.6614 - val_accuracy: 0.4542\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4385 - accuracy: 0.4859 - val_loss: 1.7195 - val_accuracy: 0.4550\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4232 - accuracy: 0.4897 - val_loss: 1.7807 - val_accuracy: 0.4458\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4156 - accuracy: 0.4955 - val_loss: 1.7412 - val_accuracy: 0.4594\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4048 - accuracy: 0.4973 - val_loss: 1.7340 - val_accuracy: 0.4492\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3900 - accuracy: 0.5035 - val_loss: 1.7132 - val_accuracy: 0.4752\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3743 - accuracy: 0.5082 - val_loss: 1.7096 - val_accuracy: 0.4598\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.6539 - accuracy: 0.4512\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.2573 - accuracy: 0.1901 - val_loss: 1.9018 - val_accuracy: 0.3056\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9592 - accuracy: 0.2753 - val_loss: 1.8536 - val_accuracy: 0.3472\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8652 - accuracy: 0.3208 - val_loss: 1.8509 - val_accuracy: 0.3624\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8006 - accuracy: 0.3458 - val_loss: 1.7905 - val_accuracy: 0.3796\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.7446 - accuracy: 0.3684 - val_loss: 1.8079 - val_accuracy: 0.3790\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7006 - accuracy: 0.3836 - val_loss: 1.8136 - val_accuracy: 0.3920\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6613 - accuracy: 0.4022 - val_loss: 1.7014 - val_accuracy: 0.4094\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6299 - accuracy: 0.4126 - val_loss: 1.7180 - val_accuracy: 0.4066\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6010 - accuracy: 0.4241 - val_loss: 1.7069 - val_accuracy: 0.4314\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5779 - accuracy: 0.4338 - val_loss: 1.6977 - val_accuracy: 0.4384\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5561 - accuracy: 0.4431 - val_loss: 1.6823 - val_accuracy: 0.4408\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5377 - accuracy: 0.4489 - val_loss: 1.6984 - val_accuracy: 0.4448\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5183 - accuracy: 0.4572 - val_loss: 1.6481 - val_accuracy: 0.4440\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4987 - accuracy: 0.4640 - val_loss: 1.7293 - val_accuracy: 0.4432\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4856 - accuracy: 0.4703 - val_loss: 1.6925 - val_accuracy: 0.4484\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4685 - accuracy: 0.4741 - val_loss: 1.7002 - val_accuracy: 0.4526\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4499 - accuracy: 0.4852 - val_loss: 1.6790 - val_accuracy: 0.4542\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4384 - accuracy: 0.4831 - val_loss: 1.6805 - val_accuracy: 0.4544\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4287 - accuracy: 0.4876 - val_loss: 1.7014 - val_accuracy: 0.4628\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4119 - accuracy: 0.4986 - val_loss: 1.6762 - val_accuracy: 0.4668\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3949 - accuracy: 0.5028 - val_loss: 1.6953 - val_accuracy: 0.4570\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3847 - accuracy: 0.5084 - val_loss: 1.6464 - val_accuracy: 0.4622\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3736 - accuracy: 0.5103 - val_loss: 1.6967 - val_accuracy: 0.4620\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3597 - accuracy: 0.5153 - val_loss: 1.7329 - val_accuracy: 0.4592\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3499 - accuracy: 0.5165 - val_loss: 1.7484 - val_accuracy: 0.4690\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3396 - accuracy: 0.5227 - val_loss: 1.6437 - val_accuracy: 0.4792\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3255 - accuracy: 0.5293 - val_loss: 1.6975 - val_accuracy: 0.4784\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3168 - accuracy: 0.5325 - val_loss: 1.7030 - val_accuracy: 0.4702\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3043 - accuracy: 0.5370 - val_loss: 1.7484 - val_accuracy: 0.4632\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2914 - accuracy: 0.5374 - val_loss: 1.7010 - val_accuracy: 0.4692\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2817 - accuracy: 0.5452 - val_loss: 1.8604 - val_accuracy: 0.4646\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2712 - accuracy: 0.5469 - val_loss: 1.7495 - val_accuracy: 0.4694\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2611 - accuracy: 0.5532 - val_loss: 1.7572 - val_accuracy: 0.4784\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2510 - accuracy: 0.5540 - val_loss: 1.7138 - val_accuracy: 0.4798\n",
      "Epoch 35/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.2474 - accuracy: 0.5552 - val_loss: 1.7595 - val_accuracy: 0.4812\n",
      "Epoch 36/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2312 - accuracy: 0.5614 - val_loss: 1.7894 - val_accuracy: 0.4746\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.6806 - accuracy: 0.4734\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.2161 - accuracy: 0.2123 - val_loss: 1.9361 - val_accuracy: 0.3142\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9428 - accuracy: 0.2952 - val_loss: 1.8968 - val_accuracy: 0.3440\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8400 - accuracy: 0.3340 - val_loss: 1.9774 - val_accuracy: 0.3422\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7708 - accuracy: 0.3641 - val_loss: 1.9960 - val_accuracy: 0.3666\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7153 - accuracy: 0.3843 - val_loss: 1.7950 - val_accuracy: 0.4010\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.6779 - accuracy: 0.3967 - val_loss: 1.7410 - val_accuracy: 0.4108\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6454 - accuracy: 0.4097 - val_loss: 1.7907 - val_accuracy: 0.4144\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.6176 - accuracy: 0.4222 - val_loss: 1.6815 - val_accuracy: 0.4312\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5887 - accuracy: 0.4334 - val_loss: 1.7307 - val_accuracy: 0.4328\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.5651 - accuracy: 0.4415 - val_loss: 1.7338 - val_accuracy: 0.4332\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5433 - accuracy: 0.4474 - val_loss: 1.7070 - val_accuracy: 0.4436\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5277 - accuracy: 0.4548 - val_loss: 1.6778 - val_accuracy: 0.4518\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.5100 - accuracy: 0.4604 - val_loss: 1.6880 - val_accuracy: 0.4520\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4934 - accuracy: 0.4667 - val_loss: 1.7149 - val_accuracy: 0.4456\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4756 - accuracy: 0.4755 - val_loss: 1.7185 - val_accuracy: 0.4490\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4600 - accuracy: 0.4795 - val_loss: 1.6759 - val_accuracy: 0.4640\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4455 - accuracy: 0.4849 - val_loss: 1.6859 - val_accuracy: 0.4592\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.4289 - accuracy: 0.4857 - val_loss: 1.7035 - val_accuracy: 0.4626\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.4146 - accuracy: 0.4947 - val_loss: 1.7167 - val_accuracy: 0.4668\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.4030 - accuracy: 0.4981 - val_loss: 1.7372 - val_accuracy: 0.4576\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3896 - accuracy: 0.5048 - val_loss: 1.7417 - val_accuracy: 0.4560\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3755 - accuracy: 0.5114 - val_loss: 1.7501 - val_accuracy: 0.4608\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3630 - accuracy: 0.5142 - val_loss: 1.7963 - val_accuracy: 0.4636\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3497 - accuracy: 0.5182 - val_loss: 1.6750 - val_accuracy: 0.4688\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3400 - accuracy: 0.5204 - val_loss: 1.7051 - val_accuracy: 0.4620\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3279 - accuracy: 0.5226 - val_loss: 1.7013 - val_accuracy: 0.4756\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.3158 - accuracy: 0.5307 - val_loss: 1.7456 - val_accuracy: 0.4754\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.3025 - accuracy: 0.5369 - val_loss: 1.7474 - val_accuracy: 0.4812\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2928 - accuracy: 0.5394 - val_loss: 1.7891 - val_accuracy: 0.4690\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2801 - accuracy: 0.5418 - val_loss: 1.7999 - val_accuracy: 0.4726\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2653 - accuracy: 0.5468 - val_loss: 1.8177 - val_accuracy: 0.4724\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2570 - accuracy: 0.5507 - val_loss: 1.7704 - val_accuracy: 0.4734\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2488 - accuracy: 0.5513 - val_loss: 1.8203 - val_accuracy: 0.4794\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.2377 - accuracy: 0.5554 - val_loss: 1.7458 - val_accuracy: 0.4704\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.6897 - accuracy: 0.4648\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.1945 - accuracy: 0.1919 - val_loss: 1.9710 - val_accuracy: 0.2538\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9678 - accuracy: 0.2591 - val_loss: 1.9117 - val_accuracy: 0.2780\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9155 - accuracy: 0.2846 - val_loss: 1.8979 - val_accuracy: 0.3032\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8818 - accuracy: 0.2923 - val_loss: 1.8376 - val_accuracy: 0.3188\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8712 - accuracy: 0.3010 - val_loss: 1.8645 - val_accuracy: 0.3076\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9159 - accuracy: 0.2753 - val_loss: 1.9940 - val_accuracy: 0.2252\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9595 - accuracy: 0.2478 - val_loss: 1.9189 - val_accuracy: 0.2568\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.9103 - accuracy: 0.2641 - val_loss: 1.9107 - val_accuracy: 0.2692\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8883 - accuracy: 0.2770 - val_loss: 1.8638 - val_accuracy: 0.2906\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8709 - accuracy: 0.2889 - val_loss: 1.8675 - val_accuracy: 0.2764\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9313 - accuracy: 0.2577 - val_loss: 1.9922 - val_accuracy: 0.2426\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9453 - accuracy: 0.2507 - val_loss: 1.9093 - val_accuracy: 0.2762\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 3.7646 - accuracy: 0.2255 - val_loss: 2.0597 - val_accuracy: 0.1794\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.0348 - accuracy: 0.1916 - val_loss: 2.0156 - val_accuracy: 0.2068\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.8381 - accuracy: 0.3183\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.1628 - accuracy: 0.1958 - val_loss: 1.9649 - val_accuracy: 0.2522\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.9935 - accuracy: 0.2374 - val_loss: 2.0123 - val_accuracy: 0.2108\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9495 - accuracy: 0.2509 - val_loss: 1.9213 - val_accuracy: 0.2716\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9444 - accuracy: 0.2540 - val_loss: 1.9356 - val_accuracy: 0.2566\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9207 - accuracy: 0.2651 - val_loss: 1.8921 - val_accuracy: 0.2732\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9188 - accuracy: 0.2634 - val_loss: 1.9586 - val_accuracy: 0.2592\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8890 - accuracy: 0.2740 - val_loss: 1.8689 - val_accuracy: 0.2766\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8870 - accuracy: 0.2711 - val_loss: 1.8773 - val_accuracy: 0.2756\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8711 - accuracy: 0.2852 - val_loss: 1.9342 - val_accuracy: 0.2526\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8919 - accuracy: 0.2798 - val_loss: 1.9363 - val_accuracy: 0.2716\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9039 - accuracy: 0.2783 - val_loss: 1.9610 - val_accuracy: 0.2648\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9418 - accuracy: 0.2670 - val_loss: 1.9617 - val_accuracy: 0.2326\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8915 - accuracy: 0.2782 - val_loss: 1.8853 - val_accuracy: 0.2778\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8632 - accuracy: 0.2917 - val_loss: 1.8659 - val_accuracy: 0.2902\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.0553 - accuracy: 0.2899 - val_loss: 1.9311 - val_accuracy: 0.2640\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9080 - accuracy: 0.2885 - val_loss: 1.8880 - val_accuracy: 0.2984\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8791 - accuracy: 0.3003 - val_loss: 1.8684 - val_accuracy: 0.2946\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8591 - accuracy: 0.3072 - val_loss: 1.8373 - val_accuracy: 0.3104\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8527 - accuracy: 0.3094 - val_loss: 1.8789 - val_accuracy: 0.3118\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8684 - accuracy: 0.2971 - val_loss: 1.8381 - val_accuracy: 0.3108\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8496 - accuracy: 0.3054 - val_loss: 1.9469 - val_accuracy: 0.2434\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8623 - accuracy: 0.3026 - val_loss: 1.8655 - val_accuracy: 0.3050\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8939 - accuracy: 0.2906 - val_loss: 1.9853 - val_accuracy: 0.2690\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9145 - accuracy: 0.2711 - val_loss: 1.9998 - val_accuracy: 0.2400\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8861 - accuracy: 0.2852 - val_loss: 1.8807 - val_accuracy: 0.2840\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8745 - accuracy: 0.2957 - val_loss: 1.8544 - val_accuracy: 0.3084\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8918 - accuracy: 0.2839 - val_loss: 1.8928 - val_accuracy: 0.2820\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8675 - accuracy: 0.2939 - val_loss: 1.8568 - val_accuracy: 0.2900\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.8464 - accuracy: 0.3138\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.1800 - accuracy: 0.1908 - val_loss: 2.0168 - val_accuracy: 0.2230\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9985 - accuracy: 0.2380 - val_loss: 2.0046 - val_accuracy: 0.2208\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9629 - accuracy: 0.2521 - val_loss: 1.9596 - val_accuracy: 0.2640\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9469 - accuracy: 0.2556 - val_loss: 1.9247 - val_accuracy: 0.2674\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9404 - accuracy: 0.2554 - val_loss: 1.9338 - val_accuracy: 0.2568\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9353 - accuracy: 0.2542 - val_loss: 1.9616 - val_accuracy: 0.2414\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9559 - accuracy: 0.2510 - val_loss: 1.9225 - val_accuracy: 0.2476\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9303 - accuracy: 0.2582 - val_loss: 1.9806 - val_accuracy: 0.2616\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9113 - accuracy: 0.2677 - val_loss: 1.9440 - val_accuracy: 0.2534\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9952 - accuracy: 0.2245 - val_loss: 1.9557 - val_accuracy: 0.2042\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9735 - accuracy: 0.2310 - val_loss: 1.9857 - val_accuracy: 0.2502\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9228 - accuracy: 0.2511 - val_loss: 1.9088 - val_accuracy: 0.2540\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9182 - accuracy: 0.2553 - val_loss: 1.9072 - val_accuracy: 0.2654\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9421 - accuracy: 0.2434 - val_loss: 1.9854 - val_accuracy: 0.2074\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9822 - accuracy: 0.2304 - val_loss: 1.9285 - val_accuracy: 0.2690\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9829 - accuracy: 0.2383 - val_loss: 1.9284 - val_accuracy: 0.2532\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9467 - accuracy: 0.2481 - val_loss: 1.9243 - val_accuracy: 0.2740\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9538 - accuracy: 0.2534 - val_loss: 1.9182 - val_accuracy: 0.2632\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9769 - accuracy: 0.2334 - val_loss: 1.9474 - val_accuracy: 0.2626\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.2928 - accuracy: 0.1181 - val_loss: 2.2674 - val_accuracy: 0.1348\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.2498 - accuracy: 0.1294 - val_loss: 2.1968 - val_accuracy: 0.1582\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.1389 - accuracy: 0.1756 - val_loss: 2.1394 - val_accuracy: 0.1830\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.0964 - accuracy: 0.1960 - val_loss: 1.9834 - val_accuracy: 0.2334\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.8994 - accuracy: 0.2608\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.1871 - accuracy: 0.1942 - val_loss: 1.9866 - val_accuracy: 0.2502\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9848 - accuracy: 0.2511 - val_loss: 1.9257 - val_accuracy: 0.2800\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9375 - accuracy: 0.2743 - val_loss: 1.9181 - val_accuracy: 0.2872\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9180 - accuracy: 0.2844 - val_loss: 1.9110 - val_accuracy: 0.2936\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9920 - accuracy: 0.2599 - val_loss: 2.0606 - val_accuracy: 0.2400\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.0304 - accuracy: 0.2396 - val_loss: 2.0510 - val_accuracy: 0.2360\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9613 - accuracy: 0.2538 - val_loss: 1.9180 - val_accuracy: 0.2534\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9312 - accuracy: 0.2647 - val_loss: 1.8939 - val_accuracy: 0.2766\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9124 - accuracy: 0.2796 - val_loss: 1.8847 - val_accuracy: 0.2916\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9393 - accuracy: 0.2701 - val_loss: 1.9732 - val_accuracy: 0.2616\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9638 - accuracy: 0.2621 - val_loss: 1.9338 - val_accuracy: 0.2682\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9056 - accuracy: 0.2802 - val_loss: 2.0363 - val_accuracy: 0.2360\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9885 - accuracy: 0.2671 - val_loss: 1.9375 - val_accuracy: 0.2614\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9109 - accuracy: 0.2715 - val_loss: 1.8830 - val_accuracy: 0.2800\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8883 - accuracy: 0.2896 - val_loss: 1.8742 - val_accuracy: 0.2950\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8824 - accuracy: 0.2938 - val_loss: 1.8814 - val_accuracy: 0.2806\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8767 - accuracy: 0.3000 - val_loss: 1.8850 - val_accuracy: 0.3048\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9016 - accuracy: 0.2854 - val_loss: 1.8879 - val_accuracy: 0.2930\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9030 - accuracy: 0.2864 - val_loss: 1.8895 - val_accuracy: 0.2976\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8887 - accuracy: 0.2962 - val_loss: 1.8503 - val_accuracy: 0.3196\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.0051 - accuracy: 0.2889 - val_loss: 1.8963 - val_accuracy: 0.2758\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.9219 - accuracy: 0.2699 - val_loss: 1.8903 - val_accuracy: 0.2742\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9057 - accuracy: 0.2820 - val_loss: 1.8718 - val_accuracy: 0.3078\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9151 - accuracy: 0.2824 - val_loss: 2.0010 - val_accuracy: 0.2430\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8972 - accuracy: 0.2910 - val_loss: 1.8746 - val_accuracy: 0.2996\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8789 - accuracy: 0.2954 - val_loss: 1.8668 - val_accuracy: 0.2984\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8691 - accuracy: 0.3056 - val_loss: 1.8621 - val_accuracy: 0.3016\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8682 - accuracy: 0.3064 - val_loss: 1.8727 - val_accuracy: 0.3070\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8491 - accuracy: 0.3188 - val_loss: 1.8894 - val_accuracy: 0.3124\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 1.8548 - accuracy: 0.3227 - val_loss: 1.8824 - val_accuracy: 0.3216\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.8707 - accuracy: 0.3134\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.1717 - accuracy: 0.1979 - val_loss: 1.9412 - val_accuracy: 0.2636\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.9531 - accuracy: 0.2625 - val_loss: 1.9222 - val_accuracy: 0.2850\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9172 - accuracy: 0.2848 - val_loss: 2.0127 - val_accuracy: 0.2392\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.9135 - accuracy: 0.2842 - val_loss: 1.8824 - val_accuracy: 0.3062\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8675 - accuracy: 0.2998 - val_loss: 1.8212 - val_accuracy: 0.3148\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8469 - accuracy: 0.3093 - val_loss: 1.9313 - val_accuracy: 0.2846\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8331 - accuracy: 0.3137 - val_loss: 1.8196 - val_accuracy: 0.3184\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8878 - accuracy: 0.2873 - val_loss: 1.9486 - val_accuracy: 0.2442\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8264 - accuracy: 0.3136 - val_loss: 1.7777 - val_accuracy: 0.3346\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.7872 - accuracy: 0.3380 - val_loss: 1.8309 - val_accuracy: 0.3050\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7729 - accuracy: 0.3399 - val_loss: 1.7763 - val_accuracy: 0.3540\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7913 - accuracy: 0.3452 - val_loss: 2.0467 - val_accuracy: 0.2062\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8892 - accuracy: 0.2809 - val_loss: 1.8473 - val_accuracy: 0.2956\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8354 - accuracy: 0.3001 - val_loss: 1.8788 - val_accuracy: 0.3004\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8224 - accuracy: 0.3079 - val_loss: 1.8120 - val_accuracy: 0.3172\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8053 - accuracy: 0.3218 - val_loss: 1.8388 - val_accuracy: 0.3034\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8067 - accuracy: 0.3198 - val_loss: 1.9205 - val_accuracy: 0.2844\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7945 - accuracy: 0.3262 - val_loss: 1.8001 - val_accuracy: 0.3396\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.7821 - accuracy: 0.3346 - val_loss: 1.7849 - val_accuracy: 0.3254\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 1.8052 - accuracy: 0.3203 - val_loss: 1.8635 - val_accuracy: 0.3112\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1.8209 - accuracy: 0.3236 - val_loss: 1.8046 - val_accuracy: 0.3404\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 1.7708 - accuracy: 0.3437\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 1583477.2500 - accuracy: 0.1101 - val_loss: 2.3165 - val_accuracy: 0.1040\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3086 - accuracy: 0.0990 - val_loss: 2.3061 - val_accuracy: 0.1040\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3115 - accuracy: 0.0973 - val_loss: 2.3129 - val_accuracy: 0.1040\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3130 - accuracy: 0.1001 - val_loss: 2.3148 - val_accuracy: 0.1040\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.3145 - accuracy: 0.0988 - val_loss: 2.3202 - val_accuracy: 0.1010\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3155 - accuracy: 0.0972 - val_loss: 2.3150 - val_accuracy: 0.0920\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.3161 - accuracy: 0.1002 - val_loss: 2.3105 - val_accuracy: 0.1038\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3165 - accuracy: 0.0976 - val_loss: 2.3116 - val_accuracy: 0.1040\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3176 - accuracy: 0.0994 - val_loss: 2.3227 - val_accuracy: 0.1040\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3181 - accuracy: 0.1003 - val_loss: 2.3300 - val_accuracy: 0.1040\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3198 - accuracy: 0.0997 - val_loss: 2.3212 - val_accuracy: 0.1010\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.3211 - accuracy: 0.1032 - val_loss: 2.3308 - val_accuracy: 0.1038\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.3052 - accuracy: 0.1013\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 95.0317 - accuracy: 0.1008 - val_loss: 2.3409 - val_accuracy: 0.1038\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3305 - accuracy: 0.1011 - val_loss: 2.3743 - val_accuracy: 0.1038\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3432 - accuracy: 0.1017 - val_loss: 2.3742 - val_accuracy: 0.0972\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3505 - accuracy: 0.1006 - val_loss: 2.3351 - val_accuracy: 0.1038\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3557 - accuracy: 0.0992 - val_loss: 2.3887 - val_accuracy: 0.1040\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3638 - accuracy: 0.0959 - val_loss: 2.4689 - val_accuracy: 0.0972\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3690 - accuracy: 0.0984 - val_loss: 2.3520 - val_accuracy: 0.0976\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3711 - accuracy: 0.1019 - val_loss: 2.4090 - val_accuracy: 0.1038\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3757 - accuracy: 0.0979 - val_loss: 2.3569 - val_accuracy: 0.1038\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3800 - accuracy: 0.0979 - val_loss: 2.3871 - val_accuracy: 0.1040\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3835 - accuracy: 0.1007 - val_loss: 2.4130 - val_accuracy: 0.1010\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3838 - accuracy: 0.1006 - val_loss: 2.3507 - val_accuracy: 0.1040\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3863 - accuracy: 0.1019 - val_loss: 2.4021 - val_accuracy: 0.0976\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3898 - accuracy: 0.0999 - val_loss: 2.3663 - val_accuracy: 0.0996\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.3393 - accuracy: 0.0979\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.9812 - accuracy: 0.1018 - val_loss: 2.3968 - val_accuracy: 0.1038\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 2.4042 - accuracy: 0.0970 - val_loss: 2.5785 - val_accuracy: 0.1038\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.4055 - accuracy: 0.0988 - val_loss: 2.4285 - val_accuracy: 0.0972\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.4032 - accuracy: 0.1010 - val_loss: 2.3359 - val_accuracy: 0.1038\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 11193213.0000 - accuracy: 0.0988 - val_loss: 2.3248 - val_accuracy: 0.0996\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3160 - accuracy: 0.0973 - val_loss: 2.3321 - val_accuracy: 0.0972\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3193 - accuracy: 0.1019 - val_loss: 2.3300 - val_accuracy: 0.0972\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3239 - accuracy: 0.0981 - val_loss: 2.3302 - val_accuracy: 0.0920\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3273 - accuracy: 0.0990 - val_loss: 2.3272 - val_accuracy: 0.0972\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3322 - accuracy: 0.1025 - val_loss: 2.3368 - val_accuracy: 0.0996\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3358 - accuracy: 0.1010 - val_loss: 2.3577 - val_accuracy: 0.0972\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3384 - accuracy: 0.0986 - val_loss: 2.3319 - val_accuracy: 0.1040\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3393 - accuracy: 0.0976 - val_loss: 2.3434 - val_accuracy: 0.0972\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3411 - accuracy: 0.1015 - val_loss: 2.3432 - val_accuracy: 0.0920\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3402 - accuracy: 0.1004 - val_loss: 2.3385 - val_accuracy: 0.1038\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.3202 - accuracy: 0.1031\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 4828.0322 - accuracy: 0.1018 - val_loss: 2.3458 - val_accuracy: 0.1040\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.4942 - accuracy: 0.0991 - val_loss: 2.3669 - val_accuracy: 0.1038\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.4440 - accuracy: 0.0999 - val_loss: 2.4542 - val_accuracy: 0.0972\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3983 - accuracy: 0.1007 - val_loss: 2.3575 - val_accuracy: 0.1040\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3583 - accuracy: 0.1001 - val_loss: 2.3178 - val_accuracy: 0.0972\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3299 - accuracy: 0.0987 - val_loss: 2.3141 - val_accuracy: 0.1038\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3196 - accuracy: 0.0994 - val_loss: 2.3266 - val_accuracy: 0.0972\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3221 - accuracy: 0.0999 - val_loss: 2.3231 - val_accuracy: 0.1040\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3253 - accuracy: 0.0980 - val_loss: 2.3192 - val_accuracy: 0.1040\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3289 - accuracy: 0.1019 - val_loss: 2.3466 - val_accuracy: 0.0996\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3330 - accuracy: 0.1009 - val_loss: 2.3395 - val_accuracy: 0.1010\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3392 - accuracy: 0.0978 - val_loss: 2.3146 - val_accuracy: 0.0972\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3445 - accuracy: 0.0986 - val_loss: 2.3390 - val_accuracy: 0.0972\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3506 - accuracy: 0.0968 - val_loss: 2.3330 - val_accuracy: 0.0972\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3581 - accuracy: 0.1010 - val_loss: 2.3624 - val_accuracy: 0.0972\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3619 - accuracy: 0.0983 - val_loss: 2.3995 - val_accuracy: 0.0972\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.3136 - accuracy: 0.1004\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.7361 - accuracy: 0.0994 - val_loss: 2.3653 - val_accuracy: 0.1038\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 7674227.5000 - accuracy: 0.0969 - val_loss: 21.2410 - val_accuracy: 0.1038\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 72235.3672 - accuracy: 0.1009 - val_loss: 8.8953 - val_accuracy: 0.1038\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 3.5447 - accuracy: 0.0999 - val_loss: 2.4419 - val_accuracy: 0.1038\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3045 - accuracy: 0.0975 - val_loss: 2.4234 - val_accuracy: 0.1038\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3051 - accuracy: 0.0993 - val_loss: 2.4387 - val_accuracy: 0.1038\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3055 - accuracy: 0.1042 - val_loss: 2.4296 - val_accuracy: 0.1038\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 7s 6ms/step - loss: 2.3057 - accuracy: 0.1000 - val_loss: 2.4406 - val_accuracy: 0.1038\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 6s 5ms/step - loss: 2.3061 - accuracy: 0.1015 - val_loss: 2.4536 - val_accuracy: 0.1038\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3065 - accuracy: 0.0985 - val_loss: 2.4429 - val_accuracy: 0.1038\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 6s 6ms/step - loss: 2.3071 - accuracy: 0.0990 - val_loss: 2.4568 - val_accuracy: 0.1038\n",
      "282/282 [==============================] - 1s 2ms/step - loss: 2.3744 - accuracy: 0.0989\n",
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 2.0164 - accuracy: 0.2654 - val_loss: 1.8167 - val_accuracy: 0.3478\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8215 - accuracy: 0.3368 - val_loss: 1.7624 - val_accuracy: 0.3526\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7391 - accuracy: 0.3694 - val_loss: 1.7328 - val_accuracy: 0.3800\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6771 - accuracy: 0.3946 - val_loss: 1.7211 - val_accuracy: 0.3916\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6297 - accuracy: 0.4099 - val_loss: 1.6395 - val_accuracy: 0.4118\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5928 - accuracy: 0.4264 - val_loss: 1.5890 - val_accuracy: 0.4268\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5592 - accuracy: 0.4360 - val_loss: 1.5830 - val_accuracy: 0.4216\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5315 - accuracy: 0.4471 - val_loss: 1.5468 - val_accuracy: 0.4474\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5079 - accuracy: 0.4560 - val_loss: 1.5781 - val_accuracy: 0.4386\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4906 - accuracy: 0.4623 - val_loss: 1.5555 - val_accuracy: 0.4372\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4658 - accuracy: 0.4717 - val_loss: 1.5754 - val_accuracy: 0.4412\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4476 - accuracy: 0.4803 - val_loss: 1.5412 - val_accuracy: 0.4554\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4293 - accuracy: 0.4847 - val_loss: 1.5328 - val_accuracy: 0.4502\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4123 - accuracy: 0.4936 - val_loss: 1.5084 - val_accuracy: 0.4600\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3998 - accuracy: 0.4957 - val_loss: 1.5269 - val_accuracy: 0.4522\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3831 - accuracy: 0.5027 - val_loss: 1.5090 - val_accuracy: 0.4682\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3694 - accuracy: 0.5072 - val_loss: 1.4922 - val_accuracy: 0.4750\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3556 - accuracy: 0.5133 - val_loss: 1.4957 - val_accuracy: 0.4708\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3436 - accuracy: 0.5145 - val_loss: 1.5180 - val_accuracy: 0.4634\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3272 - accuracy: 0.5215 - val_loss: 1.5096 - val_accuracy: 0.4740\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3181 - accuracy: 0.5252 - val_loss: 1.5562 - val_accuracy: 0.4566\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3056 - accuracy: 0.5323 - val_loss: 1.4864 - val_accuracy: 0.4832\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2921 - accuracy: 0.5375 - val_loss: 1.5218 - val_accuracy: 0.4756\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2811 - accuracy: 0.5375 - val_loss: 1.4983 - val_accuracy: 0.4804\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2676 - accuracy: 0.5436 - val_loss: 1.5044 - val_accuracy: 0.4828\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2585 - accuracy: 0.5469 - val_loss: 1.4871 - val_accuracy: 0.4788\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2420 - accuracy: 0.5545 - val_loss: 1.4829 - val_accuracy: 0.4834\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2360 - accuracy: 0.5557 - val_loss: 1.4869 - val_accuracy: 0.4822\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2252 - accuracy: 0.5608 - val_loss: 1.5120 - val_accuracy: 0.4696\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2149 - accuracy: 0.5602 - val_loss: 1.5234 - val_accuracy: 0.4790\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.2050 - accuracy: 0.5679 - val_loss: 1.4969 - val_accuracy: 0.4860\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1953 - accuracy: 0.5684 - val_loss: 1.5232 - val_accuracy: 0.4906\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1882 - accuracy: 0.5729 - val_loss: 1.5582 - val_accuracy: 0.4820\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1762 - accuracy: 0.5778 - val_loss: 1.5122 - val_accuracy: 0.4870\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1648 - accuracy: 0.5827 - val_loss: 1.5126 - val_accuracy: 0.4776\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1553 - accuracy: 0.5831 - val_loss: 1.5382 - val_accuracy: 0.4888\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1455 - accuracy: 0.5878 - val_loss: 1.5343 - val_accuracy: 0.4954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f1b35a9aca0>,\n",
       "                   param_distributions={'dropout_rate': [0.01, 0.03, 0.1, 0.3],\n",
       "                                        'learning_rate': [1e-05, 3e-05, 0.0001,\n",
       "                                                          0.0003, 0.001, 0.003,\n",
       "                                                          0.01]})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.fit(x_train, y_train, epochs = 100, validation_data = (x_valid, y_valid), callbacks = keras.callbacks.EarlyStopping(patience = 10, restore_best_weights = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 3e-05, 'dropout_rate': 0.03}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46608888506889345"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
